{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Udacity Project - Recommendations with IBM\n",
    "\n",
    "#### Table of Contents\n",
    "- I. [Exploratory Data Analysis](#Exploratory-Data-Analysis)<br>\n",
    "- II. [Rank Based Recommendations](#Rank)<br>\n",
    "- III. [User-User Based Collaborative Filtering](#User-User)<br>\n",
    "- IV. [Content Based Recommendations (EXTRA - NOT REQUIRED)](#Content-Recs)<br>\n",
    "- V. [Matrix Factorization](#Matrix-Fact)<br>\n",
    "- VI. [Extras & Concluding](#conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lemsf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lemsf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lemsf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lemsf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import project_tests as t\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import tools\n",
    "import matplotlib as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger','stopwords'])\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "\n",
    "df = pd.read_csv('data/user-item-interactions.csv')\n",
    "df_content = pd.read_csv('data/articles_community.csv')\n",
    "\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier data analysis and experimentation</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  \\\n",
       "0      1430.0   \n",
       "1      1314.0   \n",
       "2      1429.0   \n",
       "3      1338.0   \n",
       "4      1276.0   \n",
       "\n",
       "                                                                              title  \\\n",
       "0  using pixiedust for fast, flexible, and easier data analysis and experimentation   \n",
       "1                                      healthcare python streaming application demo   \n",
       "2                                        use deep learning for image classification   \n",
       "3                                         ml optimization using cognitive assistant   \n",
       "4                                         deploy your python model as a restful api   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df to get an idea of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45993 entries, 0 to 45992\n",
      "Data columns (total 3 columns):\n",
      "article_id    45993 non-null float64\n",
      "title         45993 non-null object\n",
      "email         45976 non-null object\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Show data layout\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VIDEO IS UNAVAILABLE.\\r\\nWATCH QUEUE\\r\\nQUEUE\\r\\nWatch Queue Queue * Remove all\\r\\n * Disconnect\\r\\n\\r\\nThe next ...</td>\n",
       "      <td>Detect bad readings in real time using Python and Streaming Analytics.</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streaming Analytics</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data science: A guide to presenting your work 4COMMUNICATING DATA SCIENCE: A GUIDE TO PRESENTING YOUR WORK\\r\\nMegan ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the challenge in both performing and presenting an analysis. As data scientists, analysts, and machine learning engineers faced with fulfilling business obj…</td>\n",
       "      <td>Communicating data science: A guide to presenting your work</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * Partner Courses\\r\\n   \\r\\n   \\r\\n * Badges * Our Badges\\r\\n    * BDU Badge Program\\r\\n   \\r\\n   \\r\\n * Watson ...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Big Data.</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDISTRIBUTED DATABASE\\r\\nShare on Twitter Share on Facebook Share on Google+ Vote on Hacker News Published Dec 29...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of scaling persistent storage, but introduce latency as data size increases and become I/O bound.</td>\n",
       "      <td>DataLayer Conference: Boost the performance of your distributed database</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VIDEO IS UNAVAILABLE.\\r\\nWATCH QUEUE\\r\\nQUEUE\\r\\nWatch Queue Queue * Remove all\\r\\n * Disconnect\\r\\n\\r\\nThe next ...</td>\n",
       "      <td>This video demonstrates the power of IBM DataScience Experience using a simple New York State Restaurant Inspections data scenario.</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                  doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VIDEO IS UNAVAILABLE.\\r\\nWATCH QUEUE\\r\\nQUEUE\\r\\nWatch Queue Queue * Remove all\\r\\n * Disconnect\\r\\n\\r\\nThe next ...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n * kaggle.com\\r\\n\\r\\nCommunicating data science: A guide to presenting your work 4COMMUNICATING DATA SCIENCE: A GUIDE TO PRESENTING YOUR WORK\\r\\nMegan ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Paths\\r\\n * Courses * Our Courses\\r\\n    * Partner Courses\\r\\n   \\r\\n   \\r\\n * Badges * Our Badges\\r\\n    * BDU Badge Program\\r\\n   \\r\\n   \\r\\n * Watson ...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCALE - BOOST THE PERFORMANCE OF YOUR\\r\\nDISTRIBUTED DATABASE\\r\\nShare on Twitter Share on Facebook Share on Google+ Vote on Hacker News Published Dec 29...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r\\nClose Yeah, keep it Undo CloseTHIS VIDEO IS UNAVAILABLE.\\r\\nWATCH QUEUE\\r\\nQUEUE\\r\\nWatch Queue Queue * Remove all\\r\\n * Disconnect\\r\\n\\r\\nThe next ...   \n",
       "\n",
       "                                                                                                                                                                                          doc_description  \\\n",
       "0                                                                                                                                  Detect bad readings in real time using Python and Streaming Analytics.   \n",
       "1  See the forest, see the trees. Here lies the challenge in both performing and presenting an analysis. As data scientists, analysts, and machine learning engineers faced with fulfilling business obj…   \n",
       "2                                                                                                                                                   Here’s this week’s news in Data Science and Big Data.   \n",
       "3                                                           Learn how distributed DBs solve the problem of scaling persistent storage, but introduce latency as data size increases and become I/O bound.   \n",
       "4                                                                    This video demonstrates the power of IBM DataScience Experience using a simple New York State Restaurant Inspections data scenario.    \n",
       "\n",
       "                                                              doc_full_name  \\\n",
       "0                Detect Malfunctioning IoT Sensors with Streaming Analytics   \n",
       "1               Communicating data science: A guide to presenting your work   \n",
       "2                                This Week in Data Science (April 18, 2017)   \n",
       "3  DataLayer Conference: Boost the performance of your distributed database   \n",
       "4                             Analyze NY Restaurant data using Spark in DSX   \n",
       "\n",
       "  doc_status  article_id  \n",
       "0       Live           0  \n",
       "1       Live           1  \n",
       "2       Live           2  \n",
       "3       Live           3  \n",
       "4       Live           4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show df_content to get an idea of the data\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1056 entries, 0 to 1055\n",
      "Data columns (total 5 columns):\n",
      "doc_body           1042 non-null object\n",
      "doc_description    1053 non-null object\n",
      "doc_full_name      1056 non-null object\n",
      "doc_status         1056 non-null object\n",
      "article_id         1056 non-null int64\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 41.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Show data layout\n",
    "df_content.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Exploratory-Data-Analysis\">Part I : Exploratory Data Analysis</a>\n",
    "\n",
    "\n",
    "`1.` What is the distribution of how many articles a user interacts with in the dataset?  Provide a visual and descriptive statistics to assist with giving a look at the number of times each user interacts with an article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of viewers per article\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      64.392157\n",
       "std      109.161462\n",
       "min        1.000000\n",
       "25%        8.000000\n",
       "50%       25.000000\n",
       "75%       69.000000\n",
       "max      937.000000\n",
       "Name: readers, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# How many viewers for each article ?\n",
    "\n",
    "article_read = df.groupby('article_id').email.count().reset_index()\n",
    "article_read.rename(columns={'email': 'readers'}, inplace=True)\n",
    "\n",
    "print('Summary of viewers per article')\n",
    "print('------------------------------------------------------')\n",
    "display(article_read['readers'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of articles viewed per user\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5148.000000\n",
       "mean        8.930847\n",
       "std        16.802267\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         3.000000\n",
       "75%         9.000000\n",
       "max       364.000000\n",
       "Name: articles, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many articles a user reads ?\n",
    "\n",
    "user_read = df.groupby('email').article_id.count().reset_index()\n",
    "user_read.rename(columns={'article_id': 'articles'}, inplace=True)\n",
    "\n",
    "print('Distribution of articles viewed per user')\n",
    "print('------------------------------------------------------')\n",
    "display(user_read['articles'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "red"
         },
         "name": "Views per Article",
         "opacity": 0.75,
         "type": "histogram",
         "x": [
          14,
          58,
          13,
          85,
          10,
          157,
          89,
          26,
          61,
          78,
          248,
          15,
          89,
          42,
          75,
          17,
          64,
          141,
          93,
          18,
          68,
          70,
          300,
          11,
          89,
          124,
          115,
          20,
          140,
          11,
          13,
          16,
          20,
          55,
          29,
          57,
          69,
          57,
          11,
          57,
          19,
          24,
          12,
          18,
          24,
          38,
          7,
          152,
          9,
          89,
          29,
          78,
          28,
          189,
          198,
          64,
          68,
          20,
          28,
          16,
          160,
          10,
          130,
          110,
          300,
          127,
          54,
          75,
          44,
          10,
          37,
          75,
          42,
          26,
          22,
          33,
          300,
          59,
          85,
          13,
          38,
          149,
          222,
          91,
          12,
          16,
          9,
          40,
          7,
          78,
          33,
          124,
          115,
          21,
          89,
          63,
          53,
          113,
          21,
          113,
          85,
          41,
          31,
          33,
          68,
          16,
          20,
          41,
          198,
          33,
          48,
          169,
          37,
          155,
          42,
          23,
          46,
          59,
          10,
          15,
          222,
          44,
          20,
          146,
          16,
          24,
          14,
          60,
          45,
          24,
          38,
          18,
          41,
          28,
          18,
          23,
          34,
          10,
          84,
          34,
          15,
          51,
          60,
          90,
          15,
          18,
          18,
          65,
          9,
          85,
          34,
          19,
          25,
          22,
          23,
          85,
          43,
          6,
          19,
          67,
          5,
          13,
          33,
          80,
          3,
          2,
          11,
          24,
          93,
          11,
          9,
          2,
          73,
          29,
          44,
          10,
          2,
          4,
          270,
          3,
          21,
          12,
          10,
          7,
          134,
          35,
          13,
          151,
          2,
          1,
          4,
          47,
          15,
          32,
          10,
          4,
          2,
          10,
          40,
          2,
          54,
          8,
          49,
          23,
          20,
          98,
          11,
          56,
          48,
          22,
          60,
          9,
          5,
          19,
          91,
          17,
          16,
          160,
          50,
          77,
          48,
          12,
          48,
          68,
          2,
          12,
          6,
          2,
          60,
          113,
          8,
          8,
          4,
          17,
          22,
          85,
          32,
          10,
          8,
          179,
          14,
          54,
          4,
          4,
          14,
          56,
          30,
          5,
          42,
          8,
          18,
          2,
          23,
          26,
          2,
          6,
          128,
          21,
          209,
          32,
          46,
          43,
          4,
          21,
          64,
          20,
          21,
          10,
          3,
          18,
          38,
          2,
          124,
          2,
          102,
          54,
          108,
          1,
          9,
          19,
          83,
          22,
          1,
          39,
          28,
          12,
          84,
          16,
          107,
          1,
          2,
          13,
          6,
          18,
          220,
          73,
          107,
          18,
          67,
          36,
          58,
          4,
          32,
          2,
          6,
          12,
          18,
          31,
          21,
          95,
          1,
          41,
          32,
          121,
          143,
          239,
          25,
          4,
          46,
          52,
          10,
          2,
          2,
          12,
          7,
          56,
          6,
          46,
          64,
          28,
          2,
          10,
          29,
          25,
          18,
          68,
          37,
          111,
          4,
          5,
          108,
          151,
          40,
          84,
          41,
          101,
          44,
          99,
          34,
          15,
          35,
          8,
          29,
          27,
          12,
          36,
          123,
          32,
          2,
          38,
          19,
          41,
          104,
          11,
          18,
          4,
          45,
          34,
          23,
          10,
          63,
          54,
          24,
          7,
          125,
          52,
          10,
          10,
          26,
          44,
          11,
          105,
          14,
          30,
          135,
          2,
          6,
          126,
          2,
          10,
          11,
          28,
          25,
          35,
          100,
          83,
          65,
          2,
          51,
          27,
          45,
          26,
          139,
          2,
          9,
          1,
          74,
          36,
          130,
          1,
          4,
          13,
          26,
          19,
          62,
          4,
          16,
          7,
          14,
          17,
          116,
          5,
          80,
          234,
          66,
          74,
          182,
          51,
          8,
          18,
          8,
          45,
          4,
          52,
          137,
          108,
          87,
          42,
          300,
          215,
          219,
          103,
          58,
          79,
          22,
          66,
          57,
          22,
          8,
          6,
          3,
          9,
          5,
          2,
          4,
          2,
          6,
          4,
          1,
          5,
          9,
          2,
          9,
          3,
          8,
          5,
          2,
          4,
          5,
          2,
          2,
          2,
          1,
          8,
          2,
          3,
          3,
          2,
          1,
          8,
          4,
          1,
          8,
          2,
          2,
          6,
          9,
          8,
          1,
          3,
          2,
          2,
          2,
          2,
          26,
          6,
          6,
          11,
          9,
          12,
          2,
          12,
          8,
          4,
          8,
          14,
          23,
          8,
          16,
          10,
          14,
          26,
          2,
          42,
          55,
          37,
          300,
          24,
          300,
          290,
          253,
          300,
          192,
          2,
          28,
          57,
          300,
          213,
          300,
          32,
          212,
          55,
          171,
          21,
          38,
          6,
          78,
          116,
          168,
          73,
          300,
          145,
          6,
          2,
          32,
          16,
          10,
          8,
          2,
          2,
          2,
          23,
          5,
          1,
          1,
          2,
          3,
          2,
          2,
          23,
          8,
          30,
          2,
          2,
          5,
          2,
          12,
          1,
          4,
          2,
          1,
          2,
          4,
          2,
          5,
          7,
          6,
          6,
          8,
          12,
          32,
          1,
          4,
          300,
          24,
          204,
          300,
          74,
          104,
          30,
          25,
          18,
          191,
          2,
          3,
          30,
          13,
          39,
          7,
          15,
          300,
          4,
          10,
          193,
          4,
          61,
          40,
          2,
          300,
          300,
          8,
          4,
          4,
          47,
          300,
          4,
          95,
          6,
          6,
          160,
          58,
          183,
          2,
          148,
          40,
          300,
          29,
          206,
          8,
          2,
          2,
          300,
          37,
          300,
          2,
          293,
          1,
          2,
          7,
          24,
          43,
          300,
          300,
          3,
          41,
          123,
          19,
          13,
          214,
          12,
          16,
          22,
          300,
          2,
          69,
          185,
          300,
          10,
          4,
          2,
          11,
          2,
          189,
          26,
          2,
          191,
          300,
          182,
          122,
          206,
          24,
          300,
          279,
          7,
          52,
          69,
          50,
          136,
          58,
          22,
          16,
          54,
          109,
          42,
          25,
          4,
          11,
          102,
          43,
          6,
          113,
          3,
          163,
          155,
          131,
          71,
          138,
          300,
          120,
          300,
          300,
          300,
          300,
          108,
          42,
          120,
          300,
          218,
          59,
          10,
          8,
          4,
          22,
          5
         ],
         "xaxis": "x1",
         "xbins": {
          "end": 300,
          "size": 5,
          "start": 0
         },
         "yaxis": "y1"
        },
        {
         "marker": {
          "color": "darkblue"
         },
         "name": "Articles per User",
         "opacity": 0.75,
         "type": "histogram",
         "x": [
          13,
          4,
          3,
          6,
          2,
          2,
          3,
          10,
          1,
          13,
          1,
          4,
          3,
          4,
          3,
          11,
          3,
          1,
          2,
          4,
          9,
          1,
          35,
          11,
          15,
          3,
          7,
          2,
          1,
          11,
          101,
          20,
          2,
          2,
          10,
          4,
          3,
          1,
          1,
          14,
          40,
          3,
          13,
          7,
          4,
          11,
          1,
          9,
          3,
          5,
          1,
          10,
          2,
          3,
          8,
          83,
          18,
          6,
          3,
          5,
          2,
          1,
          6,
          1,
          1,
          1,
          3,
          1,
          1,
          5,
          11,
          3,
          8,
          3,
          6,
          2,
          5,
          3,
          9,
          1,
          6,
          40,
          26,
          2,
          1,
          1,
          2,
          24,
          3,
          8,
          2,
          1,
          2,
          25,
          1,
          3,
          12,
          1,
          3,
          6,
          1,
          6,
          4,
          1,
          4,
          3,
          9,
          35,
          7,
          6,
          4,
          1,
          2,
          33,
          3,
          29,
          4,
          7,
          1,
          9,
          4,
          1,
          9,
          12,
          5,
          4,
          1,
          1,
          19,
          5,
          2,
          3,
          3,
          45,
          2,
          2,
          12,
          1,
          16,
          1,
          5,
          1,
          2,
          1,
          2,
          8,
          5,
          4,
          26,
          26,
          2,
          1,
          2,
          1,
          15,
          3,
          14,
          3,
          4,
          49,
          4,
          3,
          13,
          3,
          1,
          1,
          3,
          24,
          1,
          4,
          1,
          5,
          5,
          1,
          14,
          11,
          3,
          2,
          26,
          7,
          18,
          2,
          3,
          3,
          1,
          1,
          41,
          1,
          2,
          6,
          1,
          9,
          29,
          11,
          1,
          17,
          10,
          12,
          12,
          1,
          1,
          2,
          3,
          6,
          1,
          1,
          1,
          1,
          12,
          7,
          1,
          10,
          48,
          9,
          1,
          2,
          3,
          1,
          4,
          1,
          1,
          5,
          1,
          3,
          1,
          1,
          1,
          1,
          5,
          1,
          5,
          1,
          1,
          17,
          3,
          1,
          1,
          12,
          4,
          2,
          1,
          20,
          11,
          2,
          4,
          3,
          13,
          5,
          20,
          9,
          14,
          29,
          3,
          6,
          39,
          2,
          3,
          1,
          8,
          8,
          5,
          4,
          6,
          13,
          3,
          6,
          7,
          1,
          2,
          6,
          1,
          66,
          1,
          1,
          16,
          1,
          1,
          6,
          2,
          2,
          1,
          3,
          2,
          102,
          4,
          8,
          6,
          6,
          41,
          23,
          7,
          2,
          4,
          17,
          2,
          8,
          4,
          5,
          1,
          3,
          1,
          9,
          1,
          79,
          33,
          1,
          1,
          1,
          2,
          72,
          2,
          5,
          1,
          14,
          2,
          3,
          6,
          5,
          2,
          1,
          1,
          1,
          1,
          15,
          1,
          5,
          1,
          25,
          1,
          5,
          24,
          2,
          31,
          1,
          1,
          16,
          4,
          8,
          1,
          1,
          15,
          17,
          3,
          1,
          2,
          1,
          10,
          1,
          1,
          1,
          5,
          8,
          1,
          4,
          64,
          3,
          1,
          4,
          2,
          7,
          10,
          4,
          4,
          4,
          48,
          41,
          14,
          4,
          2,
          91,
          17,
          19,
          4,
          1,
          1,
          4,
          1,
          6,
          1,
          2,
          62,
          1,
          4,
          3,
          1,
          4,
          1,
          24,
          2,
          2,
          14,
          1,
          2,
          6,
          32,
          1,
          5,
          9,
          75,
          4,
          7,
          104,
          6,
          14,
          15,
          3,
          2,
          5,
          1,
          25,
          6,
          1,
          1,
          3,
          2,
          2,
          1,
          30,
          2,
          2,
          7,
          2,
          2,
          6,
          2,
          3,
          3,
          36,
          1,
          1,
          31,
          66,
          3,
          32,
          1,
          1,
          1,
          3,
          18,
          14,
          1,
          11,
          4,
          1,
          3,
          12,
          4,
          2,
          1,
          8,
          1,
          1,
          1,
          84,
          1,
          79,
          11,
          1,
          22,
          19,
          20,
          1,
          2,
          2,
          3,
          1,
          1,
          1,
          1,
          4,
          3,
          10,
          1,
          11,
          2,
          2,
          9,
          2,
          18,
          1,
          1,
          2,
          11,
          1,
          3,
          9,
          1,
          10,
          2,
          1,
          7,
          18,
          46,
          1,
          1,
          6,
          37,
          1,
          2,
          1,
          2,
          17,
          5,
          1,
          4,
          3,
          11,
          28,
          11,
          11,
          11,
          6,
          1,
          2,
          1,
          1,
          8,
          1,
          2,
          11,
          2,
          2,
          1,
          1,
          4,
          147,
          1,
          1,
          1,
          6,
          24,
          1,
          8,
          23,
          38,
          1,
          5,
          1,
          14,
          1,
          1,
          1,
          89,
          1,
          53,
          1,
          1,
          1,
          7,
          1,
          1,
          1,
          2,
          6,
          1,
          5,
          1,
          1,
          1,
          3,
          1,
          2,
          1,
          38,
          4,
          1,
          5,
          1,
          2,
          1,
          2,
          5,
          6,
          23,
          13,
          5,
          2,
          6,
          10,
          10,
          1,
          1,
          4,
          2,
          1,
          7,
          4,
          2,
          5,
          2,
          2,
          1,
          8,
          1,
          4,
          1,
          2,
          5,
          1,
          1,
          2,
          1,
          2,
          13,
          1,
          2,
          11,
          1,
          33,
          10,
          21,
          1,
          58,
          4,
          11,
          1,
          1,
          22,
          3,
          14,
          3,
          22,
          1,
          1,
          1,
          2,
          7,
          2,
          30,
          21,
          1,
          4,
          4,
          1,
          7,
          3,
          4,
          12,
          3,
          4,
          2,
          2,
          17,
          8,
          1,
          1,
          18,
          7,
          2,
          48,
          5,
          1,
          5,
          2,
          3,
          1,
          2,
          32,
          3,
          23,
          1,
          1,
          16,
          1,
          13,
          1,
          26,
          1,
          1,
          1,
          7,
          2,
          3,
          4,
          3,
          9,
          6,
          17,
          1,
          25,
          4,
          19,
          9,
          3,
          5,
          1,
          2,
          13,
          67,
          1,
          8,
          1,
          1,
          10,
          47,
          1,
          5,
          2,
          1,
          4,
          2,
          2,
          2,
          4,
          1,
          4,
          1,
          19,
          5,
          1,
          5,
          15,
          17,
          4,
          43,
          6,
          14,
          1,
          59,
          2,
          1,
          3,
          1,
          1,
          1,
          18,
          7,
          26,
          8,
          5,
          1,
          7,
          17,
          1,
          3,
          3,
          1,
          11,
          4,
          1,
          1,
          5,
          1,
          20,
          13,
          10,
          34,
          1,
          1,
          6,
          21,
          45,
          3,
          2,
          8,
          1,
          3,
          1,
          9,
          38,
          19,
          1,
          4,
          12,
          16,
          2,
          1,
          1,
          9,
          1,
          4,
          2,
          1,
          1,
          5,
          24,
          2,
          1,
          1,
          1,
          2,
          1,
          2,
          7,
          13,
          8,
          3,
          12,
          19,
          2,
          2,
          4,
          38,
          1,
          3,
          1,
          27,
          1,
          2,
          1,
          1,
          31,
          3,
          5,
          1,
          3,
          1,
          6,
          1,
          8,
          29,
          34,
          1,
          11,
          22,
          1,
          1,
          7,
          12,
          1,
          1,
          1,
          76,
          10,
          1,
          4,
          8,
          1,
          1,
          16,
          54,
          10,
          145,
          11,
          6,
          3,
          3,
          4,
          15,
          3,
          2,
          35,
          3,
          5,
          11,
          2,
          1,
          1,
          2,
          1,
          7,
          148,
          40,
          7,
          1,
          8,
          3,
          3,
          6,
          1,
          1,
          1,
          1,
          1,
          4,
          1,
          2,
          7,
          1,
          7,
          8,
          2,
          7,
          1,
          8,
          7,
          2,
          1,
          8,
          1,
          2,
          5,
          1,
          3,
          2,
          4,
          1,
          1,
          10,
          1,
          2,
          3,
          10,
          1,
          50,
          1,
          2,
          10,
          4,
          3,
          14,
          4,
          7,
          1,
          6,
          3,
          25,
          1,
          21,
          1,
          300,
          5,
          3,
          1,
          51,
          1,
          2,
          1,
          2,
          2,
          4,
          3,
          21,
          11,
          8,
          1,
          15,
          11,
          33,
          1,
          2,
          1,
          1,
          10,
          8,
          1,
          1,
          6,
          14,
          2,
          5,
          1,
          2,
          2,
          34,
          1,
          82,
          5,
          29,
          4,
          5,
          1,
          2,
          1,
          3,
          1,
          9,
          15,
          26,
          96,
          1,
          5,
          6,
          6,
          15,
          27,
          7,
          2,
          1,
          3,
          4,
          4,
          22,
          7,
          2,
          1,
          4,
          27,
          1,
          3,
          1,
          2,
          6,
          10,
          2,
          170,
          2,
          1,
          64,
          15,
          5,
          8,
          2,
          4,
          10,
          1,
          1,
          10,
          60,
          6,
          11,
          1,
          5,
          2,
          7,
          17,
          2,
          1,
          4,
          2,
          42,
          12,
          4,
          2,
          1,
          1,
          11,
          1,
          3,
          1,
          2,
          2,
          1,
          12,
          7,
          1,
          5,
          1,
          1,
          3,
          1,
          11,
          2,
          1,
          1,
          25,
          12,
          1,
          6,
          3,
          19,
          6,
          2,
          1,
          8,
          5,
          1,
          11,
          1,
          8,
          6,
          14,
          1,
          7,
          1,
          1,
          5,
          50,
          4,
          1,
          6,
          7,
          3,
          2,
          4,
          9,
          1,
          7,
          2,
          16,
          5,
          2,
          1,
          3,
          1,
          1,
          1,
          2,
          13,
          1,
          103,
          1,
          6,
          1,
          5,
          4,
          6,
          1,
          2,
          4,
          2,
          31,
          3,
          50,
          28,
          2,
          5,
          3,
          2,
          4,
          27,
          1,
          2,
          4,
          3,
          4,
          4,
          2,
          3,
          2,
          3,
          2,
          22,
          30,
          2,
          5,
          5,
          18,
          2,
          2,
          9,
          78,
          13,
          9,
          5,
          5,
          4,
          1,
          3,
          1,
          4,
          3,
          1,
          3,
          6,
          34,
          5,
          3,
          25,
          3,
          1,
          1,
          16,
          1,
          1,
          3,
          2,
          11,
          6,
          3,
          3,
          32,
          5,
          1,
          1,
          4,
          2,
          1,
          6,
          2,
          1,
          1,
          5,
          3,
          4,
          24,
          1,
          5,
          37,
          1,
          31,
          4,
          1,
          10,
          3,
          33,
          63,
          1,
          3,
          1,
          1,
          1,
          1,
          3,
          2,
          5,
          6,
          1,
          1,
          1,
          13,
          8,
          12,
          3,
          5,
          45,
          1,
          41,
          21,
          16,
          3,
          6,
          2,
          1,
          7,
          7,
          41,
          1,
          5,
          5,
          18,
          1,
          1,
          4,
          8,
          1,
          30,
          1,
          1,
          76,
          1,
          42,
          3,
          21,
          2,
          1,
          11,
          4,
          7,
          1,
          82,
          1,
          6,
          2,
          3,
          2,
          9,
          9,
          32,
          5,
          16,
          8,
          1,
          4,
          13,
          22,
          4,
          7,
          18,
          1,
          19,
          1,
          4,
          4,
          1,
          1,
          6,
          1,
          1,
          2,
          1,
          1,
          21,
          19,
          6,
          1,
          7,
          4,
          28,
          1,
          18,
          12,
          2,
          10,
          39,
          40,
          7,
          4,
          18,
          8,
          6,
          1,
          1,
          1,
          1,
          7,
          1,
          32,
          1,
          4,
          2,
          10,
          1,
          18,
          1,
          39,
          5,
          2,
          4,
          4,
          5,
          2,
          18,
          5,
          5,
          8,
          3,
          5,
          3,
          8,
          3,
          26,
          8,
          2,
          10,
          7,
          19,
          19,
          3,
          5,
          4,
          1,
          5,
          69,
          7,
          1,
          42,
          1,
          13,
          1,
          5,
          10,
          10,
          3,
          5,
          7,
          2,
          1,
          44,
          6,
          1,
          19,
          4,
          2,
          4,
          2,
          6,
          39,
          2,
          20,
          5,
          1,
          1,
          4,
          95,
          2,
          20,
          82,
          11,
          3,
          60,
          13,
          4,
          21,
          12,
          24,
          1,
          3,
          3,
          12,
          4,
          7,
          25,
          1,
          1,
          21,
          2,
          3,
          5,
          2,
          58,
          3,
          1,
          2,
          3,
          3,
          37,
          4,
          2,
          2,
          1,
          1,
          11,
          2,
          7,
          3,
          5,
          2,
          12,
          4,
          1,
          6,
          2,
          5,
          1,
          5,
          3,
          1,
          24,
          27,
          1,
          1,
          25,
          4,
          1,
          8,
          16,
          1,
          1,
          1,
          17,
          2,
          7,
          3,
          2,
          5,
          3,
          32,
          19,
          3,
          4,
          14,
          5,
          2,
          4,
          1,
          1,
          8,
          5,
          15,
          1,
          1,
          4,
          2,
          1,
          24,
          6,
          2,
          37,
          5,
          7,
          1,
          3,
          7,
          1,
          3,
          3,
          94,
          15,
          5,
          2,
          2,
          1,
          10,
          1,
          12,
          1,
          1,
          2,
          1,
          2,
          2,
          26,
          16,
          1,
          14,
          2,
          25,
          10,
          33,
          3,
          16,
          3,
          4,
          3,
          8,
          1,
          13,
          3,
          1,
          3,
          1,
          2,
          7,
          1,
          5,
          1,
          20,
          30,
          20,
          16,
          8,
          1,
          10,
          2,
          25,
          58,
          3,
          13,
          1,
          2,
          18,
          1,
          35,
          1,
          1,
          4,
          13,
          1,
          1,
          2,
          2,
          1,
          4,
          3,
          4,
          3,
          23,
          3,
          2,
          7,
          102,
          2,
          2,
          8,
          8,
          1,
          1,
          3,
          1,
          2,
          1,
          1,
          2,
          10,
          14,
          6,
          1,
          19,
          1,
          3,
          1,
          1,
          1,
          1,
          8,
          1,
          2,
          4,
          5,
          1,
          7,
          38,
          40,
          1,
          11,
          1,
          1,
          1,
          14,
          1,
          1,
          40,
          2,
          4,
          1,
          1,
          7,
          1,
          6,
          1,
          4,
          9,
          8,
          1,
          4,
          1,
          1,
          38,
          1,
          2,
          6,
          5,
          4,
          1,
          2,
          10,
          1,
          9,
          16,
          24,
          3,
          21,
          3,
          9,
          1,
          7,
          11,
          5,
          10,
          28,
          6,
          1,
          1,
          1,
          1,
          2,
          2,
          1,
          8,
          1,
          75,
          4,
          28,
          1,
          32,
          1,
          9,
          7,
          3,
          11,
          10,
          7,
          7,
          3,
          1,
          1,
          2,
          1,
          1,
          1,
          12,
          4,
          16,
          5,
          6,
          1,
          18,
          2,
          5,
          2,
          1,
          13,
          11,
          2,
          4,
          29,
          5,
          6,
          11,
          1,
          1,
          2,
          29,
          3,
          1,
          9,
          4,
          20,
          2,
          1,
          1,
          1,
          59,
          8,
          3,
          1,
          2,
          4,
          2,
          1,
          3,
          11,
          10,
          5,
          30,
          1,
          13,
          6,
          15,
          5,
          53,
          1,
          2,
          9,
          9,
          9,
          3,
          50,
          3,
          1,
          5,
          2,
          1,
          2,
          46,
          10,
          3,
          1,
          1,
          3,
          3,
          38,
          1,
          4,
          3,
          13,
          1,
          20,
          2,
          1,
          7,
          3,
          14,
          2,
          19,
          14,
          4,
          14,
          2,
          3,
          1,
          1,
          132,
          34,
          1,
          15,
          2,
          4,
          3,
          9,
          3,
          5,
          1,
          11,
          23,
          4,
          2,
          28,
          5,
          3,
          11,
          6,
          27,
          11,
          1,
          30,
          33,
          3,
          7,
          25,
          2,
          5,
          32,
          6,
          4,
          18,
          2,
          3,
          2,
          4,
          2,
          3,
          26,
          2,
          2,
          2,
          6,
          62,
          1,
          1,
          57,
          2,
          14,
          2,
          1,
          4,
          1,
          65,
          2,
          1,
          1,
          144,
          4,
          1,
          3,
          8,
          3,
          6,
          6,
          1,
          6,
          8,
          8,
          1,
          35,
          1,
          1,
          2,
          1,
          33,
          5,
          2,
          76,
          12,
          1,
          4,
          1,
          18,
          14,
          3,
          5,
          1,
          1,
          3,
          2,
          11,
          3,
          4,
          10,
          6,
          1,
          5,
          14,
          10,
          1,
          3,
          3,
          2,
          10,
          3,
          1,
          5,
          3,
          1,
          1,
          3,
          10,
          2,
          3,
          5,
          23,
          2,
          52,
          1,
          2,
          2,
          6,
          1,
          9,
          2,
          3,
          28,
          2,
          2,
          2,
          1,
          8,
          4,
          1,
          1,
          22,
          7,
          16,
          1,
          36,
          4,
          8,
          52,
          1,
          1,
          12,
          1,
          3,
          10,
          1,
          6,
          2,
          2,
          6,
          2,
          11,
          2,
          6,
          17,
          2,
          2,
          6,
          3,
          1,
          13,
          8,
          3,
          1,
          3,
          16,
          2,
          4,
          32,
          2,
          1,
          17,
          4,
          2,
          5,
          2,
          2,
          1,
          5,
          4,
          13,
          1,
          17,
          7,
          3,
          1,
          1,
          2,
          10,
          4,
          29,
          1,
          36,
          4,
          16,
          4,
          23,
          1,
          21,
          16,
          1,
          4,
          2,
          14,
          13,
          15,
          3,
          7,
          4,
          21,
          7,
          1,
          8,
          3,
          3,
          2,
          2,
          15,
          10,
          1,
          1,
          1,
          6,
          59,
          37,
          1,
          3,
          1,
          3,
          1,
          4,
          1,
          2,
          6,
          7,
          2,
          2,
          5,
          1,
          1,
          1,
          5,
          1,
          7,
          1,
          7,
          2,
          1,
          13,
          2,
          2,
          4,
          3,
          11,
          3,
          9,
          16,
          27,
          2,
          9,
          20,
          11,
          3,
          28,
          4,
          11,
          1,
          1,
          3,
          7,
          1,
          14,
          4,
          7,
          2,
          5,
          5,
          14,
          9,
          1,
          11,
          4,
          9,
          14,
          11,
          9,
          6,
          1,
          41,
          2,
          3,
          13,
          9,
          2,
          5,
          12,
          3,
          2,
          39,
          1,
          52,
          12,
          2,
          1,
          24,
          1,
          20,
          3,
          5,
          3,
          2,
          2,
          7,
          2,
          4,
          1,
          10,
          3,
          7,
          15,
          2,
          4,
          3,
          14,
          11,
          1,
          5,
          24,
          7,
          1,
          20,
          8,
          2,
          11,
          5,
          6,
          26,
          4,
          58,
          1,
          1,
          1,
          2,
          1,
          1,
          16,
          6,
          1,
          1,
          20,
          2,
          2,
          1,
          1,
          9,
          5,
          5,
          1,
          4,
          89,
          8,
          2,
          2,
          4,
          15,
          84,
          2,
          4,
          45,
          13,
          69,
          1,
          4,
          9,
          10,
          1,
          1,
          2,
          10,
          2,
          3,
          30,
          1,
          10,
          1,
          6,
          1,
          4,
          15,
          8,
          35,
          67,
          1,
          1,
          5,
          4,
          13,
          53,
          1,
          24,
          5,
          4,
          1,
          7,
          1,
          3,
          1,
          11,
          8,
          1,
          50,
          48,
          1,
          1,
          4,
          4,
          7,
          5,
          16,
          3,
          1,
          43,
          40,
          1,
          1,
          5,
          2,
          2,
          15,
          1,
          1,
          4,
          4,
          3,
          6,
          1,
          2,
          12,
          3,
          2,
          8,
          5,
          3,
          9,
          1,
          8,
          3,
          131,
          3,
          2,
          7,
          1,
          1,
          20,
          9,
          5,
          4,
          8,
          1,
          13,
          1,
          3,
          17,
          3,
          72,
          2,
          1,
          11,
          28,
          26,
          1,
          3,
          2,
          83,
          23,
          4,
          4,
          22,
          1,
          1,
          1,
          4,
          2,
          1,
          2,
          1,
          2,
          2,
          1,
          3,
          11,
          2,
          19,
          34,
          1,
          2,
          42,
          3,
          32,
          2,
          1,
          2,
          92,
          1,
          1,
          11,
          20,
          5,
          10,
          2,
          1,
          4,
          9,
          3,
          3,
          4,
          8,
          10,
          3,
          60,
          1,
          1,
          6,
          2,
          3,
          1,
          5,
          1,
          24,
          1,
          2,
          1,
          4,
          1,
          1,
          7,
          2,
          3,
          28,
          2,
          1,
          1,
          2,
          2,
          1,
          1,
          6,
          1,
          1,
          3,
          1,
          2,
          10,
          10,
          1,
          1,
          3,
          1,
          1,
          13,
          6,
          4,
          12,
          1,
          1,
          2,
          3,
          11,
          1,
          10,
          3,
          1,
          21,
          6,
          14,
          6,
          1,
          8,
          1,
          1,
          4,
          6,
          3,
          16,
          1,
          1,
          2,
          1,
          1,
          4,
          1,
          10,
          20,
          4,
          3,
          8,
          2,
          11,
          1,
          4,
          6,
          1,
          1,
          3,
          1,
          1,
          1,
          3,
          6,
          2,
          8,
          2,
          1,
          2,
          10,
          33,
          9,
          2,
          5,
          9,
          2,
          16,
          4,
          1,
          7,
          2,
          1,
          1,
          4,
          1,
          2,
          5,
          3,
          10,
          1,
          3,
          2,
          34,
          17,
          9,
          2,
          16,
          15,
          58,
          1,
          1,
          1,
          5,
          4,
          5,
          26,
          3,
          5,
          9,
          16,
          7,
          3,
          10,
          3,
          25,
          2,
          3,
          3,
          25,
          4,
          1,
          8,
          27,
          8,
          5,
          1,
          6,
          1,
          3,
          7,
          1,
          1,
          8,
          8,
          1,
          3,
          4,
          1,
          1,
          3,
          4,
          300,
          2,
          4,
          4,
          5,
          4,
          19,
          23,
          21,
          1,
          1,
          10,
          3,
          6,
          1,
          1,
          18,
          7,
          8,
          2,
          2,
          4,
          9,
          5,
          2,
          3,
          35,
          15,
          1,
          18,
          2,
          3,
          13,
          2,
          11,
          1,
          4,
          7,
          5,
          25,
          5,
          3,
          10,
          51,
          5,
          3,
          3,
          50,
          8,
          7,
          8,
          2,
          3,
          4,
          6,
          1,
          8,
          1,
          5,
          13,
          2,
          11,
          4,
          7,
          25,
          12,
          23,
          3,
          91,
          7,
          7,
          2,
          5,
          1,
          4,
          3,
          35,
          2,
          1,
          1,
          9,
          1,
          2,
          2,
          32,
          2,
          10,
          1,
          16,
          10,
          7,
          4,
          13,
          6,
          1,
          9,
          26,
          11,
          2,
          22,
          1,
          1,
          28,
          5,
          13,
          3,
          1,
          1,
          1,
          2,
          5,
          1,
          1,
          18,
          6,
          97,
          24,
          6,
          3,
          1,
          2,
          1,
          20,
          1,
          1,
          4,
          1,
          6,
          1,
          9,
          2,
          3,
          3,
          1,
          10,
          5,
          33,
          18,
          1,
          1,
          5,
          2,
          1,
          1,
          1,
          81,
          1,
          3,
          2,
          3,
          1,
          9,
          7,
          7,
          3,
          25,
          1,
          7,
          1,
          1,
          8,
          36,
          40,
          1,
          4,
          1,
          1,
          3,
          6,
          3,
          3,
          50,
          4,
          6,
          12,
          60,
          2,
          5,
          35,
          1,
          4,
          1,
          4,
          1,
          1,
          1,
          2,
          1,
          14,
          1,
          5,
          10,
          2,
          6,
          9,
          4,
          2,
          1,
          17,
          1,
          4,
          5,
          8,
          2,
          5,
          2,
          1,
          1,
          6,
          1,
          8,
          6,
          51,
          10,
          2,
          2,
          7,
          1,
          1,
          1,
          1,
          8,
          1,
          13,
          3,
          1,
          1,
          7,
          1,
          2,
          84,
          22,
          4,
          11,
          2,
          1,
          1,
          1,
          9,
          1,
          10,
          3,
          1,
          3,
          10,
          3,
          1,
          21,
          22,
          1,
          1,
          2,
          18,
          10,
          160,
          5,
          52,
          3,
          2,
          12,
          1,
          3,
          55,
          7,
          7,
          4,
          80,
          4,
          6,
          2,
          11,
          1,
          4,
          6,
          4,
          2,
          1,
          4,
          3,
          3,
          7,
          1,
          1,
          2,
          2,
          4,
          5,
          2,
          3,
          1,
          11,
          8,
          5,
          2,
          3,
          1,
          19,
          13,
          1,
          4,
          3,
          79,
          2,
          1,
          1,
          3,
          1,
          2,
          23,
          9,
          3,
          3,
          1,
          2,
          22,
          3,
          9,
          3,
          2,
          8,
          7,
          6,
          3,
          3,
          18,
          3,
          2,
          3,
          1,
          1,
          1,
          6,
          2,
          18,
          3,
          1,
          5,
          4,
          1,
          8,
          1,
          4,
          29,
          5,
          1,
          29,
          1,
          9,
          1,
          4,
          9,
          15,
          1,
          80,
          1,
          11,
          5,
          15,
          1,
          7,
          12,
          29,
          2,
          1,
          4,
          1,
          51,
          55,
          7,
          8,
          2,
          6,
          1,
          18,
          1,
          4,
          5,
          2,
          9,
          3,
          3,
          1,
          2,
          2,
          33,
          7,
          4,
          9,
          12,
          6,
          1,
          16,
          3,
          5,
          1,
          32,
          8,
          3,
          3,
          19,
          1,
          1,
          3,
          20,
          12,
          1,
          1,
          8,
          1,
          6,
          1,
          1,
          3,
          1,
          9,
          7,
          2,
          7,
          7,
          1,
          12,
          1,
          1,
          3,
          2,
          1,
          3,
          1,
          2,
          18,
          2,
          7,
          1,
          2,
          2,
          2,
          10,
          1,
          1,
          3,
          39,
          137,
          14,
          2,
          6,
          2,
          1,
          9,
          14,
          1,
          20,
          2,
          4,
          5,
          1,
          3,
          6,
          3,
          5,
          2,
          7,
          2,
          1,
          2,
          6,
          1,
          11,
          3,
          34,
          1,
          1,
          1,
          17,
          20,
          4,
          6,
          1,
          10,
          1,
          8,
          29,
          31,
          5,
          1,
          13,
          2,
          4,
          3,
          1,
          2,
          1,
          2,
          1,
          1,
          5,
          4,
          1,
          1,
          1,
          3,
          1,
          9,
          20,
          1,
          18,
          9,
          1,
          8,
          2,
          1,
          4,
          3,
          10,
          4,
          2,
          1,
          3,
          1,
          2,
          5,
          2,
          9,
          4,
          4,
          4,
          4,
          2,
          2,
          4,
          4,
          2,
          1,
          4,
          12,
          4,
          2,
          6,
          1,
          2,
          7,
          1,
          1,
          44,
          7,
          1,
          1,
          2,
          1,
          2,
          3,
          8,
          15,
          5,
          4,
          1,
          8,
          8,
          12,
          3,
          2,
          4,
          1,
          1,
          4,
          3,
          7,
          30,
          6,
          2,
          1,
          4,
          3,
          6,
          1,
          1,
          19,
          10,
          4,
          2,
          7,
          7,
          6,
          1,
          1,
          1,
          21,
          3,
          5,
          5,
          2,
          2,
          3,
          3,
          10,
          49,
          6,
          2,
          2,
          5,
          15,
          1,
          2,
          9,
          3,
          15,
          16,
          49,
          51,
          4,
          1,
          1,
          1,
          1,
          8,
          5,
          1,
          2,
          4,
          6,
          9,
          2,
          2,
          4,
          2,
          2,
          3,
          3,
          2,
          12,
          26,
          3,
          45,
          6,
          10,
          4,
          5,
          19,
          3,
          3,
          19,
          32,
          12,
          1,
          10,
          3,
          6,
          1,
          4,
          4,
          1,
          3,
          16,
          8,
          1,
          2,
          19,
          38,
          3,
          1,
          1,
          1,
          2,
          5,
          2,
          7,
          2,
          3,
          6,
          2,
          2,
          5,
          14,
          1,
          2,
          57,
          7,
          1,
          2,
          1,
          2,
          2,
          30,
          1,
          14,
          2,
          39,
          1,
          2,
          2,
          2,
          1,
          1,
          3,
          2,
          8,
          1,
          4,
          5,
          3,
          3,
          5,
          9,
          3,
          3,
          3,
          8,
          1,
          2,
          1,
          10,
          6,
          9,
          2,
          1,
          3,
          38,
          2,
          9,
          3,
          3,
          9,
          13,
          3,
          1,
          9,
          2,
          6,
          1,
          2,
          1,
          3,
          4,
          8,
          14,
          1,
          3,
          27,
          5,
          7,
          1,
          1,
          11,
          28,
          1,
          1,
          1,
          3,
          1,
          8,
          1,
          1,
          1,
          18,
          6,
          4,
          2,
          6,
          1,
          3,
          20,
          5,
          16,
          7,
          2,
          4,
          2,
          2,
          1,
          3,
          12,
          8,
          6,
          6,
          19,
          11,
          34,
          8,
          16,
          1,
          12,
          46,
          1,
          2,
          2,
          16,
          33,
          1,
          10,
          11,
          11,
          6,
          6,
          6,
          1,
          5,
          35,
          21,
          2,
          11,
          1,
          42,
          1,
          10,
          1,
          1,
          1,
          1,
          10,
          17,
          2,
          16,
          10,
          1,
          3,
          4,
          1,
          6,
          24,
          1,
          1,
          3,
          24,
          6,
          18,
          2,
          2,
          30,
          1,
          16,
          61,
          10,
          3,
          1,
          1,
          3,
          3,
          2,
          7,
          5,
          1,
          2,
          2,
          5,
          25,
          4,
          1,
          6,
          1,
          3,
          7,
          2,
          6,
          13,
          1,
          5,
          49,
          1,
          9,
          1,
          1,
          3,
          1,
          2,
          4,
          8,
          6,
          1,
          16,
          3,
          14,
          33,
          2,
          1,
          9,
          55,
          6,
          6,
          2,
          5,
          4,
          1,
          6,
          4,
          1,
          20,
          7,
          169,
          4,
          8,
          3,
          12,
          15,
          1,
          45,
          4,
          34,
          26,
          2,
          3,
          1,
          2,
          23,
          4,
          4,
          1,
          22,
          23,
          13,
          28,
          9,
          5,
          2,
          9,
          1,
          25,
          2,
          8,
          8,
          1,
          5,
          3,
          7,
          1,
          1,
          3,
          13,
          6,
          5,
          2,
          36,
          1,
          12,
          5,
          12,
          56,
          1,
          3,
          22,
          63,
          1,
          22,
          38,
          3,
          14,
          1,
          2,
          1,
          1,
          12,
          5,
          4,
          4,
          1,
          2,
          1,
          3,
          3,
          1,
          1,
          1,
          3,
          16,
          10,
          1,
          4,
          5,
          1,
          4,
          8,
          1,
          2,
          4,
          49,
          79,
          6,
          1,
          3,
          2,
          7,
          26,
          2,
          35,
          1,
          10,
          3,
          2,
          4,
          1,
          16,
          1,
          1,
          2,
          12,
          1,
          1,
          2,
          8,
          5,
          1,
          2,
          1,
          1,
          1,
          3,
          3,
          1,
          4,
          1,
          1,
          1,
          7,
          3,
          6,
          8,
          2,
          1,
          6,
          7,
          5,
          4,
          1,
          1,
          5,
          13,
          2,
          2,
          35,
          11,
          7,
          1,
          10,
          19,
          29,
          1,
          1,
          1,
          6,
          2,
          3,
          1,
          4,
          20,
          1,
          1,
          7,
          2,
          56,
          1,
          2,
          16,
          10,
          32,
          34,
          1,
          25,
          2,
          1,
          1,
          1,
          1,
          1,
          4,
          10,
          2,
          5,
          1,
          12,
          3,
          1,
          46,
          1,
          1,
          1,
          7,
          3,
          3,
          2,
          1,
          2,
          30,
          4,
          6,
          1,
          10,
          2,
          2,
          1,
          3,
          1,
          3,
          2,
          1,
          9,
          13,
          2,
          2,
          6,
          5,
          2,
          1,
          3,
          4,
          23,
          14,
          1,
          6,
          35,
          3,
          20,
          1,
          1,
          11,
          59,
          1,
          8,
          10,
          28,
          7,
          2,
          7,
          1,
          48,
          9,
          15,
          2,
          5,
          2,
          8,
          5,
          3,
          2,
          5,
          31,
          1,
          61,
          3,
          5,
          2,
          59,
          7,
          4,
          1,
          1,
          9,
          11,
          1,
          7,
          17,
          25,
          3,
          1,
          1,
          1,
          22,
          3,
          10,
          21,
          1,
          1,
          11,
          2,
          1,
          20,
          1,
          12,
          1,
          2,
          1,
          2,
          1,
          7,
          3,
          1,
          3,
          29,
          5,
          1,
          4,
          6,
          1,
          1,
          95,
          4,
          1,
          2,
          29,
          67,
          20,
          1,
          5,
          2,
          2,
          142,
          2,
          1,
          2,
          2,
          3,
          2,
          4,
          2,
          19,
          20,
          3,
          44,
          23,
          3,
          6,
          37,
          24,
          11,
          1,
          1,
          5,
          1,
          9,
          2,
          1,
          7,
          1,
          1,
          11,
          21,
          2,
          1,
          16,
          9,
          6,
          1,
          3,
          2,
          12,
          7,
          18,
          1,
          1,
          2,
          3,
          7,
          9,
          3,
          17,
          3,
          1,
          5,
          8,
          10,
          2,
          1,
          5,
          4,
          28,
          19,
          1,
          27,
          7,
          1,
          4,
          2,
          3,
          22,
          1,
          37,
          2,
          34,
          21,
          1,
          10,
          1,
          3,
          1,
          1,
          5,
          5,
          1,
          1,
          37,
          6,
          12,
          1,
          1,
          9,
          3,
          1,
          1,
          1,
          24,
          1,
          3,
          1,
          3,
          10,
          14,
          1,
          8,
          10,
          37,
          20,
          5,
          6,
          3,
          3,
          1,
          18,
          1,
          1,
          2,
          1,
          1,
          1,
          5,
          1,
          11,
          5,
          15,
          1,
          1,
          8,
          1,
          1,
          13,
          8,
          6,
          1,
          9,
          1,
          9,
          4,
          3,
          39,
          1,
          2,
          4,
          1,
          82,
          3,
          2,
          11,
          1,
          1,
          52,
          2,
          3,
          1,
          1,
          2,
          5,
          5,
          15,
          30,
          3,
          31,
          8,
          6,
          2,
          5,
          57,
          29,
          4,
          4,
          30,
          11,
          1,
          9,
          8,
          7,
          6,
          21,
          1,
          6,
          1,
          1,
          1,
          14,
          2,
          1,
          7,
          52,
          6,
          8,
          1,
          1,
          10,
          21,
          14,
          68,
          1,
          7,
          1,
          7,
          4,
          6,
          9,
          4,
          1,
          30,
          16,
          5,
          11,
          6,
          58,
          1,
          23,
          51,
          3,
          1,
          10,
          2,
          8,
          1,
          2,
          1,
          1,
          12,
          1,
          8,
          1,
          5,
          2,
          1,
          12,
          1,
          8,
          14,
          3,
          1,
          1,
          1,
          2,
          6,
          1,
          8,
          1,
          2,
          18,
          1,
          6,
          1,
          5,
          1,
          17,
          1,
          1,
          3,
          5,
          77,
          17,
          68,
          12,
          4,
          2,
          3,
          21,
          2,
          11,
          12,
          10,
          1,
          1,
          2,
          1,
          1,
          7,
          1,
          1,
          31,
          1,
          1,
          1,
          20,
          5,
          1,
          7,
          1,
          15,
          8,
          3,
          9,
          4,
          21,
          4,
          3,
          1,
          29,
          2,
          2,
          1,
          1,
          8,
          2,
          10,
          3,
          10,
          6,
          4,
          5,
          1,
          1,
          1,
          3,
          25,
          2,
          5,
          1,
          1,
          2,
          1,
          2,
          3,
          5,
          2,
          22,
          1,
          2,
          70,
          2,
          1,
          49,
          4,
          1,
          24,
          1,
          4,
          1,
          14,
          4,
          5,
          8,
          1,
          2,
          31,
          2,
          1,
          17,
          7,
          1,
          8,
          1,
          10,
          1,
          2,
          9,
          2,
          1,
          4,
          2,
          2,
          2,
          2,
          2,
          1,
          15,
          5,
          9,
          11,
          1,
          11,
          2,
          3,
          1,
          7,
          1,
          8,
          11,
          1,
          7,
          114,
          2,
          1,
          3,
          1,
          6,
          3,
          1,
          1,
          12,
          5,
          1,
          11,
          3,
          12,
          3,
          1,
          1,
          34,
          3,
          5,
          1,
          1,
          3,
          7,
          2,
          8,
          6,
          1,
          1,
          1,
          6,
          2,
          12,
          22,
          4,
          1,
          28,
          1,
          11,
          145,
          27,
          1,
          3,
          39,
          12,
          6,
          1,
          17,
          10,
          1,
          5,
          6,
          3,
          1,
          2,
          2,
          7,
          28,
          1,
          11,
          1,
          20,
          1,
          28,
          1,
          10,
          36,
          24,
          2,
          6,
          23,
          2,
          2,
          9,
          6,
          1,
          1,
          6,
          7,
          9,
          22,
          1,
          6,
          35,
          1,
          2,
          1,
          80,
          1,
          6,
          11,
          1,
          9,
          1,
          5,
          85,
          10,
          3,
          7,
          1,
          2,
          2,
          1,
          7,
          4,
          1,
          3,
          1,
          1,
          17,
          3,
          7,
          1,
          12,
          1,
          2,
          6,
          2,
          4,
          3,
          1,
          1,
          3,
          1,
          3,
          3,
          1,
          10,
          2,
          1,
          4,
          3,
          1,
          2,
          1,
          3,
          1,
          1,
          1,
          5,
          1,
          8,
          10,
          2,
          8,
          8,
          5,
          16,
          5,
          1,
          20,
          6,
          4,
          8,
          14,
          23,
          21,
          1,
          26,
          9,
          8,
          2,
          3,
          8,
          2,
          13,
          37,
          5,
          16,
          2,
          1,
          7,
          9,
          1,
          1,
          4,
          3,
          1,
          6,
          1,
          9,
          1,
          1,
          2,
          6,
          10,
          4,
          1,
          13,
          4,
          5,
          15,
          1,
          1,
          16,
          1,
          6,
          5,
          15,
          1,
          1,
          3,
          1,
          1,
          2,
          140,
          33,
          1,
          6,
          4,
          3,
          2,
          8,
          1,
          2,
          3,
          14,
          1,
          1,
          1,
          1,
          8,
          14,
          13,
          8,
          39,
          5,
          1,
          5,
          1,
          37,
          4,
          6,
          4,
          1,
          10,
          4,
          40,
          1,
          10,
          5,
          1,
          1,
          19,
          2,
          1,
          11,
          1,
          14,
          1,
          2,
          2,
          1,
          11,
          1,
          14,
          1,
          7,
          9,
          6,
          9,
          3,
          47,
          4,
          1,
          2,
          4,
          4,
          4,
          5,
          5,
          47,
          2,
          17,
          2,
          7,
          1,
          2,
          1,
          4,
          3,
          4,
          7,
          8,
          8,
          3,
          6,
          2,
          1,
          27,
          1,
          12,
          1,
          78,
          1,
          12,
          2,
          2,
          1,
          2,
          3,
          6,
          2,
          6,
          1,
          9,
          18,
          39,
          3,
          1,
          2,
          10,
          17,
          11,
          3,
          1,
          22,
          1,
          5,
          2,
          3,
          2,
          3,
          13,
          12,
          4,
          2,
          2,
          1,
          2,
          10,
          4,
          20,
          10,
          5,
          19,
          12,
          2,
          4,
          73,
          10,
          2,
          6,
          18,
          1,
          2,
          2,
          1,
          1,
          26,
          1,
          3,
          8,
          1,
          3,
          3,
          1,
          1,
          1,
          2,
          3,
          3,
          1,
          9,
          10,
          4,
          3,
          4,
          1,
          1,
          2,
          1,
          6,
          2,
          6,
          8,
          4,
          2,
          4,
          5,
          12,
          2,
          9,
          2,
          3,
          8,
          1,
          7,
          12,
          2,
          1,
          3,
          15,
          22,
          6,
          13,
          1,
          1,
          1,
          1,
          2,
          1,
          2,
          3,
          7,
          1,
          3,
          17,
          147,
          1,
          1,
          13,
          2,
          6,
          4,
          11,
          13,
          3,
          1,
          12,
          22,
          23,
          12,
          2,
          9,
          26,
          1,
          1,
          3,
          5,
          31,
          23,
          1,
          6,
          11,
          1,
          1,
          2,
          3,
          9,
          1,
          1,
          30,
          4,
          98,
          2,
          8,
          4,
          1,
          7,
          1,
          1,
          1,
          2,
          2,
          7,
          5,
          1,
          1,
          2,
          30,
          4,
          4,
          5,
          1,
          2,
          4,
          62,
          19,
          22,
          2,
          3,
          9,
          2,
          2,
          8,
          1,
          2,
          23,
          1,
          2,
          1,
          1,
          13,
          5,
          10,
          15,
          2,
          32,
          4,
          3,
          2,
          9,
          6,
          5,
          12,
          1,
          1,
          18,
          2,
          6,
          3,
          6,
          8,
          5,
          5,
          13,
          15,
          7,
          1,
          2,
          18,
          1,
          2,
          7,
          8,
          1,
          1,
          20,
          5,
          4,
          3,
          2,
          42,
          5,
          2,
          12,
          53,
          11,
          3,
          1,
          6,
          7,
          45,
          1,
          1,
          6,
          57,
          3,
          1,
          4,
          1,
          6,
          1,
          2,
          1,
          31,
          3,
          3,
          12,
          18,
          1,
          6,
          1,
          4,
          38,
          26,
          9,
          14,
          1,
          3,
          6,
          7,
          2,
          8,
          1,
          1,
          1,
          30,
          20,
          3,
          2,
          2,
          4,
          14,
          2,
          22,
          5,
          4,
          4,
          39,
          1,
          1,
          15,
          67,
          1,
          12,
          13,
          29,
          3,
          5,
          2,
          1,
          2,
          1,
          3,
          1,
          8,
          6,
          6,
          24,
          7,
          2,
          136,
          48,
          28,
          7,
          5,
          11,
          7,
          1,
          19,
          6,
          1,
          2,
          1,
          1,
          11,
          3,
          30,
          24,
          3,
          2,
          7,
          20,
          5,
          2,
          10,
          23,
          1,
          74,
          2,
          1,
          4,
          2,
          1,
          4,
          1,
          3,
          4,
          13,
          2,
          3,
          2,
          2,
          1,
          11,
          3,
          6,
          2,
          4,
          1,
          3,
          7,
          7,
          2,
          2,
          1,
          11,
          1,
          14,
          1,
          1,
          1,
          1,
          68,
          5,
          2,
          57,
          4,
          2,
          22,
          1,
          1,
          7,
          3,
          4,
          12,
          1,
          5,
          3,
          1,
          1,
          1,
          53,
          1,
          1,
          2,
          5,
          5,
          1,
          1,
          2,
          2,
          3,
          14,
          1,
          18,
          5,
          11,
          10,
          4,
          1,
          15,
          1,
          2,
          1,
          1,
          1,
          2,
          6,
          41,
          1,
          5,
          5,
          1,
          7,
          50,
          2,
          8,
          1,
          6,
          4,
          1,
          2,
          26,
          101,
          34,
          1,
          5,
          6,
          2,
          4,
          2,
          1,
          5,
          47,
          1,
          13,
          6,
          6,
          1,
          10,
          23,
          1,
          5,
          2,
          6,
          2,
          6,
          1,
          2,
          2,
          6,
          2,
          1,
          14,
          33,
          4,
          16,
          4,
          2,
          6,
          6,
          2,
          16,
          12,
          21,
          3,
          4,
          7,
          1,
          20,
          1,
          13,
          1,
          7,
          1,
          23,
          17,
          46,
          2,
          3,
          1,
          1,
          12,
          8,
          38,
          21,
          48,
          1,
          43,
          2,
          5,
          2,
          28,
          5,
          1,
          1,
          1,
          1,
          2,
          28,
          3,
          53,
          1,
          11,
          2,
          1,
          25,
          1,
          2,
          17,
          5,
          1,
          2,
          25,
          1,
          3,
          1,
          8,
          28,
          1,
          1,
          2,
          38,
          8,
          6,
          1,
          1,
          2,
          6,
          12,
          1,
          1,
          1,
          1,
          5,
          7,
          10,
          52,
          1,
          1,
          9,
          2,
          1,
          5,
          12,
          21,
          2,
          1,
          47,
          2,
          1,
          17,
          3,
          7,
          2,
          1,
          12,
          3,
          7,
          5,
          6,
          1,
          1,
          1,
          1,
          4,
          2,
          5,
          11,
          2,
          1,
          7,
          36,
          2,
          1,
          9,
          2,
          3,
          1,
          1,
          4,
          7,
          3,
          10,
          9,
          5,
          2,
          11,
          1,
          1,
          4,
          26,
          1,
          2,
          1,
          94,
          3,
          1,
          4,
          6,
          3,
          1,
          15,
          4,
          25,
          4,
          8,
          1,
          1,
          5,
          3,
          1,
          2,
          2,
          33,
          7,
          8,
          25,
          2,
          3,
          8,
          2,
          7,
          1,
          11,
          14,
          1,
          1,
          1,
          18,
          2,
          4,
          9,
          2,
          1,
          10,
          2,
          6,
          11,
          28,
          7,
          9,
          1,
          13,
          20,
          3,
          1,
          2,
          2,
          3,
          1,
          1,
          1,
          3,
          2,
          14,
          2,
          1,
          10,
          3,
          1,
          13,
          30,
          1,
          43,
          8,
          1,
          8,
          3,
          4,
          13,
          17,
          6,
          1,
          8,
          3,
          7,
          8,
          2,
          2,
          6,
          1,
          1,
          6,
          3,
          5,
          8,
          10,
          1,
          6,
          6,
          2,
          1,
          3,
          10,
          1,
          13,
          16,
          1,
          42,
          5,
          13,
          1,
          2,
          42,
          15,
          36,
          11,
          1,
          158,
          1,
          12,
          5,
          2,
          2,
          11,
          4,
          6,
          25,
          4,
          1,
          4,
          12,
          3,
          1,
          5,
          1,
          44,
          1,
          12,
          5,
          2,
          4,
          5,
          19,
          19,
          9,
          2,
          2,
          4,
          3,
          3,
          1,
          3,
          4,
          1,
          1,
          5,
          1,
          1,
          2,
          13,
          1,
          15,
          1,
          1,
          1,
          2,
          27,
          1,
          13,
          18,
          6,
          3,
          35,
          21,
          1,
          1,
          5,
          2,
          5,
          1,
          82,
          1,
          18,
          5,
          2,
          29,
          4,
          4,
          1,
          28,
          1,
          2,
          35,
          8,
          2,
          6,
          1,
          2,
          38,
          1,
          7,
          1,
          1,
          5,
          1,
          1,
          1,
          9,
          2,
          13,
          7,
          3,
          33,
          116,
          1,
          7,
          1,
          1,
          1,
          1,
          3,
          3,
          13,
          4,
          8,
          20,
          10,
          30,
          5,
          1,
          1,
          1,
          15,
          3,
          3,
          2,
          4,
          1,
          3,
          1,
          1,
          4,
          13,
          3,
          4,
          1,
          1,
          2,
          3,
          1,
          14,
          7,
          9,
          38,
          1,
          2,
          4,
          32,
          10,
          13
         ],
         "xaxis": "x2",
         "xbins": {
          "end": 300,
          "size": 5,
          "start": 0
         },
         "yaxis": "y2"
        }
       ],
       "layout": {
        "bargap": 0.1,
        "height": 500,
        "legend": {
         "x": 0.8,
         "xanchor": "center",
         "y": 0.8,
         "yanchor": "middle"
        },
        "margin": {
         "b": 50,
         "l": 50,
         "r": 30,
         "t": 40
        },
        "title": "User x Article Interactions",
        "titlefont": {
         "size": 13
        },
        "width": 900,
        "xaxis1": {
         "anchor": "y1",
         "domain": [
          0,
          0.45
         ],
         "title": "No of Times an Article is Viewed",
         "titlefont": {
          "size": 10
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": "No of Articles a User Views",
         "titlefont": {
          "size": 10
         }
        },
        "yaxis1": {
         "anchor": "x1",
         "domain": [
          0,
          1
         ],
         "gridwidth": null,
         "tickfont": {
          "size": 10
         },
         "title": "Frequency",
         "titlefont": {
          "size": 12
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "gridwidth": null,
         "tickfont": {
          "size": 10
         },
         "titlefont": {
          "size": 12
         }
        }
       }
      },
      "text/html": [
       "<div id=\"e26d9398-8ca2-4110-9d9e-5acbe5e31f75\" style=\"height: 500px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e26d9398-8ca2-4110-9d9e-5acbe5e31f75\", [{\"type\": \"histogram\", \"x\": [14, 58, 13, 85, 10, 157, 89, 26, 61, 78, 248, 15, 89, 42, 75, 17, 64, 141, 93, 18, 68, 70, 300, 11, 89, 124, 115, 20, 140, 11, 13, 16, 20, 55, 29, 57, 69, 57, 11, 57, 19, 24, 12, 18, 24, 38, 7, 152, 9, 89, 29, 78, 28, 189, 198, 64, 68, 20, 28, 16, 160, 10, 130, 110, 300, 127, 54, 75, 44, 10, 37, 75, 42, 26, 22, 33, 300, 59, 85, 13, 38, 149, 222, 91, 12, 16, 9, 40, 7, 78, 33, 124, 115, 21, 89, 63, 53, 113, 21, 113, 85, 41, 31, 33, 68, 16, 20, 41, 198, 33, 48, 169, 37, 155, 42, 23, 46, 59, 10, 15, 222, 44, 20, 146, 16, 24, 14, 60, 45, 24, 38, 18, 41, 28, 18, 23, 34, 10, 84, 34, 15, 51, 60, 90, 15, 18, 18, 65, 9, 85, 34, 19, 25, 22, 23, 85, 43, 6, 19, 67, 5, 13, 33, 80, 3, 2, 11, 24, 93, 11, 9, 2, 73, 29, 44, 10, 2, 4, 270, 3, 21, 12, 10, 7, 134, 35, 13, 151, 2, 1, 4, 47, 15, 32, 10, 4, 2, 10, 40, 2, 54, 8, 49, 23, 20, 98, 11, 56, 48, 22, 60, 9, 5, 19, 91, 17, 16, 160, 50, 77, 48, 12, 48, 68, 2, 12, 6, 2, 60, 113, 8, 8, 4, 17, 22, 85, 32, 10, 8, 179, 14, 54, 4, 4, 14, 56, 30, 5, 42, 8, 18, 2, 23, 26, 2, 6, 128, 21, 209, 32, 46, 43, 4, 21, 64, 20, 21, 10, 3, 18, 38, 2, 124, 2, 102, 54, 108, 1, 9, 19, 83, 22, 1, 39, 28, 12, 84, 16, 107, 1, 2, 13, 6, 18, 220, 73, 107, 18, 67, 36, 58, 4, 32, 2, 6, 12, 18, 31, 21, 95, 1, 41, 32, 121, 143, 239, 25, 4, 46, 52, 10, 2, 2, 12, 7, 56, 6, 46, 64, 28, 2, 10, 29, 25, 18, 68, 37, 111, 4, 5, 108, 151, 40, 84, 41, 101, 44, 99, 34, 15, 35, 8, 29, 27, 12, 36, 123, 32, 2, 38, 19, 41, 104, 11, 18, 4, 45, 34, 23, 10, 63, 54, 24, 7, 125, 52, 10, 10, 26, 44, 11, 105, 14, 30, 135, 2, 6, 126, 2, 10, 11, 28, 25, 35, 100, 83, 65, 2, 51, 27, 45, 26, 139, 2, 9, 1, 74, 36, 130, 1, 4, 13, 26, 19, 62, 4, 16, 7, 14, 17, 116, 5, 80, 234, 66, 74, 182, 51, 8, 18, 8, 45, 4, 52, 137, 108, 87, 42, 300, 215, 219, 103, 58, 79, 22, 66, 57, 22, 8, 6, 3, 9, 5, 2, 4, 2, 6, 4, 1, 5, 9, 2, 9, 3, 8, 5, 2, 4, 5, 2, 2, 2, 1, 8, 2, 3, 3, 2, 1, 8, 4, 1, 8, 2, 2, 6, 9, 8, 1, 3, 2, 2, 2, 2, 26, 6, 6, 11, 9, 12, 2, 12, 8, 4, 8, 14, 23, 8, 16, 10, 14, 26, 2, 42, 55, 37, 300, 24, 300, 290, 253, 300, 192, 2, 28, 57, 300, 213, 300, 32, 212, 55, 171, 21, 38, 6, 78, 116, 168, 73, 300, 145, 6, 2, 32, 16, 10, 8, 2, 2, 2, 23, 5, 1, 1, 2, 3, 2, 2, 23, 8, 30, 2, 2, 5, 2, 12, 1, 4, 2, 1, 2, 4, 2, 5, 7, 6, 6, 8, 12, 32, 1, 4, 300, 24, 204, 300, 74, 104, 30, 25, 18, 191, 2, 3, 30, 13, 39, 7, 15, 300, 4, 10, 193, 4, 61, 40, 2, 300, 300, 8, 4, 4, 47, 300, 4, 95, 6, 6, 160, 58, 183, 2, 148, 40, 300, 29, 206, 8, 2, 2, 300, 37, 300, 2, 293, 1, 2, 7, 24, 43, 300, 300, 3, 41, 123, 19, 13, 214, 12, 16, 22, 300, 2, 69, 185, 300, 10, 4, 2, 11, 2, 189, 26, 2, 191, 300, 182, 122, 206, 24, 300, 279, 7, 52, 69, 50, 136, 58, 22, 16, 54, 109, 42, 25, 4, 11, 102, 43, 6, 113, 3, 163, 155, 131, 71, 138, 300, 120, 300, 300, 300, 300, 108, 42, 120, 300, 218, 59, 10, 8, 4, 22, 5], \"opacity\": 0.75, \"name\": \"Views per Article\", \"xbins\": {\"start\": 0, \"end\": 300, \"size\": 5}, \"marker\": {\"color\": \"red\"}, \"xaxis\": \"x1\", \"yaxis\": \"y1\"}, {\"type\": \"histogram\", \"x\": [13, 4, 3, 6, 2, 2, 3, 10, 1, 13, 1, 4, 3, 4, 3, 11, 3, 1, 2, 4, 9, 1, 35, 11, 15, 3, 7, 2, 1, 11, 101, 20, 2, 2, 10, 4, 3, 1, 1, 14, 40, 3, 13, 7, 4, 11, 1, 9, 3, 5, 1, 10, 2, 3, 8, 83, 18, 6, 3, 5, 2, 1, 6, 1, 1, 1, 3, 1, 1, 5, 11, 3, 8, 3, 6, 2, 5, 3, 9, 1, 6, 40, 26, 2, 1, 1, 2, 24, 3, 8, 2, 1, 2, 25, 1, 3, 12, 1, 3, 6, 1, 6, 4, 1, 4, 3, 9, 35, 7, 6, 4, 1, 2, 33, 3, 29, 4, 7, 1, 9, 4, 1, 9, 12, 5, 4, 1, 1, 19, 5, 2, 3, 3, 45, 2, 2, 12, 1, 16, 1, 5, 1, 2, 1, 2, 8, 5, 4, 26, 26, 2, 1, 2, 1, 15, 3, 14, 3, 4, 49, 4, 3, 13, 3, 1, 1, 3, 24, 1, 4, 1, 5, 5, 1, 14, 11, 3, 2, 26, 7, 18, 2, 3, 3, 1, 1, 41, 1, 2, 6, 1, 9, 29, 11, 1, 17, 10, 12, 12, 1, 1, 2, 3, 6, 1, 1, 1, 1, 12, 7, 1, 10, 48, 9, 1, 2, 3, 1, 4, 1, 1, 5, 1, 3, 1, 1, 1, 1, 5, 1, 5, 1, 1, 17, 3, 1, 1, 12, 4, 2, 1, 20, 11, 2, 4, 3, 13, 5, 20, 9, 14, 29, 3, 6, 39, 2, 3, 1, 8, 8, 5, 4, 6, 13, 3, 6, 7, 1, 2, 6, 1, 66, 1, 1, 16, 1, 1, 6, 2, 2, 1, 3, 2, 102, 4, 8, 6, 6, 41, 23, 7, 2, 4, 17, 2, 8, 4, 5, 1, 3, 1, 9, 1, 79, 33, 1, 1, 1, 2, 72, 2, 5, 1, 14, 2, 3, 6, 5, 2, 1, 1, 1, 1, 15, 1, 5, 1, 25, 1, 5, 24, 2, 31, 1, 1, 16, 4, 8, 1, 1, 15, 17, 3, 1, 2, 1, 10, 1, 1, 1, 5, 8, 1, 4, 64, 3, 1, 4, 2, 7, 10, 4, 4, 4, 48, 41, 14, 4, 2, 91, 17, 19, 4, 1, 1, 4, 1, 6, 1, 2, 62, 1, 4, 3, 1, 4, 1, 24, 2, 2, 14, 1, 2, 6, 32, 1, 5, 9, 75, 4, 7, 104, 6, 14, 15, 3, 2, 5, 1, 25, 6, 1, 1, 3, 2, 2, 1, 30, 2, 2, 7, 2, 2, 6, 2, 3, 3, 36, 1, 1, 31, 66, 3, 32, 1, 1, 1, 3, 18, 14, 1, 11, 4, 1, 3, 12, 4, 2, 1, 8, 1, 1, 1, 84, 1, 79, 11, 1, 22, 19, 20, 1, 2, 2, 3, 1, 1, 1, 1, 4, 3, 10, 1, 11, 2, 2, 9, 2, 18, 1, 1, 2, 11, 1, 3, 9, 1, 10, 2, 1, 7, 18, 46, 1, 1, 6, 37, 1, 2, 1, 2, 17, 5, 1, 4, 3, 11, 28, 11, 11, 11, 6, 1, 2, 1, 1, 8, 1, 2, 11, 2, 2, 1, 1, 4, 147, 1, 1, 1, 6, 24, 1, 8, 23, 38, 1, 5, 1, 14, 1, 1, 1, 89, 1, 53, 1, 1, 1, 7, 1, 1, 1, 2, 6, 1, 5, 1, 1, 1, 3, 1, 2, 1, 38, 4, 1, 5, 1, 2, 1, 2, 5, 6, 23, 13, 5, 2, 6, 10, 10, 1, 1, 4, 2, 1, 7, 4, 2, 5, 2, 2, 1, 8, 1, 4, 1, 2, 5, 1, 1, 2, 1, 2, 13, 1, 2, 11, 1, 33, 10, 21, 1, 58, 4, 11, 1, 1, 22, 3, 14, 3, 22, 1, 1, 1, 2, 7, 2, 30, 21, 1, 4, 4, 1, 7, 3, 4, 12, 3, 4, 2, 2, 17, 8, 1, 1, 18, 7, 2, 48, 5, 1, 5, 2, 3, 1, 2, 32, 3, 23, 1, 1, 16, 1, 13, 1, 26, 1, 1, 1, 7, 2, 3, 4, 3, 9, 6, 17, 1, 25, 4, 19, 9, 3, 5, 1, 2, 13, 67, 1, 8, 1, 1, 10, 47, 1, 5, 2, 1, 4, 2, 2, 2, 4, 1, 4, 1, 19, 5, 1, 5, 15, 17, 4, 43, 6, 14, 1, 59, 2, 1, 3, 1, 1, 1, 18, 7, 26, 8, 5, 1, 7, 17, 1, 3, 3, 1, 11, 4, 1, 1, 5, 1, 20, 13, 10, 34, 1, 1, 6, 21, 45, 3, 2, 8, 1, 3, 1, 9, 38, 19, 1, 4, 12, 16, 2, 1, 1, 9, 1, 4, 2, 1, 1, 5, 24, 2, 1, 1, 1, 2, 1, 2, 7, 13, 8, 3, 12, 19, 2, 2, 4, 38, 1, 3, 1, 27, 1, 2, 1, 1, 31, 3, 5, 1, 3, 1, 6, 1, 8, 29, 34, 1, 11, 22, 1, 1, 7, 12, 1, 1, 1, 76, 10, 1, 4, 8, 1, 1, 16, 54, 10, 145, 11, 6, 3, 3, 4, 15, 3, 2, 35, 3, 5, 11, 2, 1, 1, 2, 1, 7, 148, 40, 7, 1, 8, 3, 3, 6, 1, 1, 1, 1, 1, 4, 1, 2, 7, 1, 7, 8, 2, 7, 1, 8, 7, 2, 1, 8, 1, 2, 5, 1, 3, 2, 4, 1, 1, 10, 1, 2, 3, 10, 1, 50, 1, 2, 10, 4, 3, 14, 4, 7, 1, 6, 3, 25, 1, 21, 1, 300, 5, 3, 1, 51, 1, 2, 1, 2, 2, 4, 3, 21, 11, 8, 1, 15, 11, 33, 1, 2, 1, 1, 10, 8, 1, 1, 6, 14, 2, 5, 1, 2, 2, 34, 1, 82, 5, 29, 4, 5, 1, 2, 1, 3, 1, 9, 15, 26, 96, 1, 5, 6, 6, 15, 27, 7, 2, 1, 3, 4, 4, 22, 7, 2, 1, 4, 27, 1, 3, 1, 2, 6, 10, 2, 170, 2, 1, 64, 15, 5, 8, 2, 4, 10, 1, 1, 10, 60, 6, 11, 1, 5, 2, 7, 17, 2, 1, 4, 2, 42, 12, 4, 2, 1, 1, 11, 1, 3, 1, 2, 2, 1, 12, 7, 1, 5, 1, 1, 3, 1, 11, 2, 1, 1, 25, 12, 1, 6, 3, 19, 6, 2, 1, 8, 5, 1, 11, 1, 8, 6, 14, 1, 7, 1, 1, 5, 50, 4, 1, 6, 7, 3, 2, 4, 9, 1, 7, 2, 16, 5, 2, 1, 3, 1, 1, 1, 2, 13, 1, 103, 1, 6, 1, 5, 4, 6, 1, 2, 4, 2, 31, 3, 50, 28, 2, 5, 3, 2, 4, 27, 1, 2, 4, 3, 4, 4, 2, 3, 2, 3, 2, 22, 30, 2, 5, 5, 18, 2, 2, 9, 78, 13, 9, 5, 5, 4, 1, 3, 1, 4, 3, 1, 3, 6, 34, 5, 3, 25, 3, 1, 1, 16, 1, 1, 3, 2, 11, 6, 3, 3, 32, 5, 1, 1, 4, 2, 1, 6, 2, 1, 1, 5, 3, 4, 24, 1, 5, 37, 1, 31, 4, 1, 10, 3, 33, 63, 1, 3, 1, 1, 1, 1, 3, 2, 5, 6, 1, 1, 1, 13, 8, 12, 3, 5, 45, 1, 41, 21, 16, 3, 6, 2, 1, 7, 7, 41, 1, 5, 5, 18, 1, 1, 4, 8, 1, 30, 1, 1, 76, 1, 42, 3, 21, 2, 1, 11, 4, 7, 1, 82, 1, 6, 2, 3, 2, 9, 9, 32, 5, 16, 8, 1, 4, 13, 22, 4, 7, 18, 1, 19, 1, 4, 4, 1, 1, 6, 1, 1, 2, 1, 1, 21, 19, 6, 1, 7, 4, 28, 1, 18, 12, 2, 10, 39, 40, 7, 4, 18, 8, 6, 1, 1, 1, 1, 7, 1, 32, 1, 4, 2, 10, 1, 18, 1, 39, 5, 2, 4, 4, 5, 2, 18, 5, 5, 8, 3, 5, 3, 8, 3, 26, 8, 2, 10, 7, 19, 19, 3, 5, 4, 1, 5, 69, 7, 1, 42, 1, 13, 1, 5, 10, 10, 3, 5, 7, 2, 1, 44, 6, 1, 19, 4, 2, 4, 2, 6, 39, 2, 20, 5, 1, 1, 4, 95, 2, 20, 82, 11, 3, 60, 13, 4, 21, 12, 24, 1, 3, 3, 12, 4, 7, 25, 1, 1, 21, 2, 3, 5, 2, 58, 3, 1, 2, 3, 3, 37, 4, 2, 2, 1, 1, 11, 2, 7, 3, 5, 2, 12, 4, 1, 6, 2, 5, 1, 5, 3, 1, 24, 27, 1, 1, 25, 4, 1, 8, 16, 1, 1, 1, 17, 2, 7, 3, 2, 5, 3, 32, 19, 3, 4, 14, 5, 2, 4, 1, 1, 8, 5, 15, 1, 1, 4, 2, 1, 24, 6, 2, 37, 5, 7, 1, 3, 7, 1, 3, 3, 94, 15, 5, 2, 2, 1, 10, 1, 12, 1, 1, 2, 1, 2, 2, 26, 16, 1, 14, 2, 25, 10, 33, 3, 16, 3, 4, 3, 8, 1, 13, 3, 1, 3, 1, 2, 7, 1, 5, 1, 20, 30, 20, 16, 8, 1, 10, 2, 25, 58, 3, 13, 1, 2, 18, 1, 35, 1, 1, 4, 13, 1, 1, 2, 2, 1, 4, 3, 4, 3, 23, 3, 2, 7, 102, 2, 2, 8, 8, 1, 1, 3, 1, 2, 1, 1, 2, 10, 14, 6, 1, 19, 1, 3, 1, 1, 1, 1, 8, 1, 2, 4, 5, 1, 7, 38, 40, 1, 11, 1, 1, 1, 14, 1, 1, 40, 2, 4, 1, 1, 7, 1, 6, 1, 4, 9, 8, 1, 4, 1, 1, 38, 1, 2, 6, 5, 4, 1, 2, 10, 1, 9, 16, 24, 3, 21, 3, 9, 1, 7, 11, 5, 10, 28, 6, 1, 1, 1, 1, 2, 2, 1, 8, 1, 75, 4, 28, 1, 32, 1, 9, 7, 3, 11, 10, 7, 7, 3, 1, 1, 2, 1, 1, 1, 12, 4, 16, 5, 6, 1, 18, 2, 5, 2, 1, 13, 11, 2, 4, 29, 5, 6, 11, 1, 1, 2, 29, 3, 1, 9, 4, 20, 2, 1, 1, 1, 59, 8, 3, 1, 2, 4, 2, 1, 3, 11, 10, 5, 30, 1, 13, 6, 15, 5, 53, 1, 2, 9, 9, 9, 3, 50, 3, 1, 5, 2, 1, 2, 46, 10, 3, 1, 1, 3, 3, 38, 1, 4, 3, 13, 1, 20, 2, 1, 7, 3, 14, 2, 19, 14, 4, 14, 2, 3, 1, 1, 132, 34, 1, 15, 2, 4, 3, 9, 3, 5, 1, 11, 23, 4, 2, 28, 5, 3, 11, 6, 27, 11, 1, 30, 33, 3, 7, 25, 2, 5, 32, 6, 4, 18, 2, 3, 2, 4, 2, 3, 26, 2, 2, 2, 6, 62, 1, 1, 57, 2, 14, 2, 1, 4, 1, 65, 2, 1, 1, 144, 4, 1, 3, 8, 3, 6, 6, 1, 6, 8, 8, 1, 35, 1, 1, 2, 1, 33, 5, 2, 76, 12, 1, 4, 1, 18, 14, 3, 5, 1, 1, 3, 2, 11, 3, 4, 10, 6, 1, 5, 14, 10, 1, 3, 3, 2, 10, 3, 1, 5, 3, 1, 1, 3, 10, 2, 3, 5, 23, 2, 52, 1, 2, 2, 6, 1, 9, 2, 3, 28, 2, 2, 2, 1, 8, 4, 1, 1, 22, 7, 16, 1, 36, 4, 8, 52, 1, 1, 12, 1, 3, 10, 1, 6, 2, 2, 6, 2, 11, 2, 6, 17, 2, 2, 6, 3, 1, 13, 8, 3, 1, 3, 16, 2, 4, 32, 2, 1, 17, 4, 2, 5, 2, 2, 1, 5, 4, 13, 1, 17, 7, 3, 1, 1, 2, 10, 4, 29, 1, 36, 4, 16, 4, 23, 1, 21, 16, 1, 4, 2, 14, 13, 15, 3, 7, 4, 21, 7, 1, 8, 3, 3, 2, 2, 15, 10, 1, 1, 1, 6, 59, 37, 1, 3, 1, 3, 1, 4, 1, 2, 6, 7, 2, 2, 5, 1, 1, 1, 5, 1, 7, 1, 7, 2, 1, 13, 2, 2, 4, 3, 11, 3, 9, 16, 27, 2, 9, 20, 11, 3, 28, 4, 11, 1, 1, 3, 7, 1, 14, 4, 7, 2, 5, 5, 14, 9, 1, 11, 4, 9, 14, 11, 9, 6, 1, 41, 2, 3, 13, 9, 2, 5, 12, 3, 2, 39, 1, 52, 12, 2, 1, 24, 1, 20, 3, 5, 3, 2, 2, 7, 2, 4, 1, 10, 3, 7, 15, 2, 4, 3, 14, 11, 1, 5, 24, 7, 1, 20, 8, 2, 11, 5, 6, 26, 4, 58, 1, 1, 1, 2, 1, 1, 16, 6, 1, 1, 20, 2, 2, 1, 1, 9, 5, 5, 1, 4, 89, 8, 2, 2, 4, 15, 84, 2, 4, 45, 13, 69, 1, 4, 9, 10, 1, 1, 2, 10, 2, 3, 30, 1, 10, 1, 6, 1, 4, 15, 8, 35, 67, 1, 1, 5, 4, 13, 53, 1, 24, 5, 4, 1, 7, 1, 3, 1, 11, 8, 1, 50, 48, 1, 1, 4, 4, 7, 5, 16, 3, 1, 43, 40, 1, 1, 5, 2, 2, 15, 1, 1, 4, 4, 3, 6, 1, 2, 12, 3, 2, 8, 5, 3, 9, 1, 8, 3, 131, 3, 2, 7, 1, 1, 20, 9, 5, 4, 8, 1, 13, 1, 3, 17, 3, 72, 2, 1, 11, 28, 26, 1, 3, 2, 83, 23, 4, 4, 22, 1, 1, 1, 4, 2, 1, 2, 1, 2, 2, 1, 3, 11, 2, 19, 34, 1, 2, 42, 3, 32, 2, 1, 2, 92, 1, 1, 11, 20, 5, 10, 2, 1, 4, 9, 3, 3, 4, 8, 10, 3, 60, 1, 1, 6, 2, 3, 1, 5, 1, 24, 1, 2, 1, 4, 1, 1, 7, 2, 3, 28, 2, 1, 1, 2, 2, 1, 1, 6, 1, 1, 3, 1, 2, 10, 10, 1, 1, 3, 1, 1, 13, 6, 4, 12, 1, 1, 2, 3, 11, 1, 10, 3, 1, 21, 6, 14, 6, 1, 8, 1, 1, 4, 6, 3, 16, 1, 1, 2, 1, 1, 4, 1, 10, 20, 4, 3, 8, 2, 11, 1, 4, 6, 1, 1, 3, 1, 1, 1, 3, 6, 2, 8, 2, 1, 2, 10, 33, 9, 2, 5, 9, 2, 16, 4, 1, 7, 2, 1, 1, 4, 1, 2, 5, 3, 10, 1, 3, 2, 34, 17, 9, 2, 16, 15, 58, 1, 1, 1, 5, 4, 5, 26, 3, 5, 9, 16, 7, 3, 10, 3, 25, 2, 3, 3, 25, 4, 1, 8, 27, 8, 5, 1, 6, 1, 3, 7, 1, 1, 8, 8, 1, 3, 4, 1, 1, 3, 4, 300, 2, 4, 4, 5, 4, 19, 23, 21, 1, 1, 10, 3, 6, 1, 1, 18, 7, 8, 2, 2, 4, 9, 5, 2, 3, 35, 15, 1, 18, 2, 3, 13, 2, 11, 1, 4, 7, 5, 25, 5, 3, 10, 51, 5, 3, 3, 50, 8, 7, 8, 2, 3, 4, 6, 1, 8, 1, 5, 13, 2, 11, 4, 7, 25, 12, 23, 3, 91, 7, 7, 2, 5, 1, 4, 3, 35, 2, 1, 1, 9, 1, 2, 2, 32, 2, 10, 1, 16, 10, 7, 4, 13, 6, 1, 9, 26, 11, 2, 22, 1, 1, 28, 5, 13, 3, 1, 1, 1, 2, 5, 1, 1, 18, 6, 97, 24, 6, 3, 1, 2, 1, 20, 1, 1, 4, 1, 6, 1, 9, 2, 3, 3, 1, 10, 5, 33, 18, 1, 1, 5, 2, 1, 1, 1, 81, 1, 3, 2, 3, 1, 9, 7, 7, 3, 25, 1, 7, 1, 1, 8, 36, 40, 1, 4, 1, 1, 3, 6, 3, 3, 50, 4, 6, 12, 60, 2, 5, 35, 1, 4, 1, 4, 1, 1, 1, 2, 1, 14, 1, 5, 10, 2, 6, 9, 4, 2, 1, 17, 1, 4, 5, 8, 2, 5, 2, 1, 1, 6, 1, 8, 6, 51, 10, 2, 2, 7, 1, 1, 1, 1, 8, 1, 13, 3, 1, 1, 7, 1, 2, 84, 22, 4, 11, 2, 1, 1, 1, 9, 1, 10, 3, 1, 3, 10, 3, 1, 21, 22, 1, 1, 2, 18, 10, 160, 5, 52, 3, 2, 12, 1, 3, 55, 7, 7, 4, 80, 4, 6, 2, 11, 1, 4, 6, 4, 2, 1, 4, 3, 3, 7, 1, 1, 2, 2, 4, 5, 2, 3, 1, 11, 8, 5, 2, 3, 1, 19, 13, 1, 4, 3, 79, 2, 1, 1, 3, 1, 2, 23, 9, 3, 3, 1, 2, 22, 3, 9, 3, 2, 8, 7, 6, 3, 3, 18, 3, 2, 3, 1, 1, 1, 6, 2, 18, 3, 1, 5, 4, 1, 8, 1, 4, 29, 5, 1, 29, 1, 9, 1, 4, 9, 15, 1, 80, 1, 11, 5, 15, 1, 7, 12, 29, 2, 1, 4, 1, 51, 55, 7, 8, 2, 6, 1, 18, 1, 4, 5, 2, 9, 3, 3, 1, 2, 2, 33, 7, 4, 9, 12, 6, 1, 16, 3, 5, 1, 32, 8, 3, 3, 19, 1, 1, 3, 20, 12, 1, 1, 8, 1, 6, 1, 1, 3, 1, 9, 7, 2, 7, 7, 1, 12, 1, 1, 3, 2, 1, 3, 1, 2, 18, 2, 7, 1, 2, 2, 2, 10, 1, 1, 3, 39, 137, 14, 2, 6, 2, 1, 9, 14, 1, 20, 2, 4, 5, 1, 3, 6, 3, 5, 2, 7, 2, 1, 2, 6, 1, 11, 3, 34, 1, 1, 1, 17, 20, 4, 6, 1, 10, 1, 8, 29, 31, 5, 1, 13, 2, 4, 3, 1, 2, 1, 2, 1, 1, 5, 4, 1, 1, 1, 3, 1, 9, 20, 1, 18, 9, 1, 8, 2, 1, 4, 3, 10, 4, 2, 1, 3, 1, 2, 5, 2, 9, 4, 4, 4, 4, 2, 2, 4, 4, 2, 1, 4, 12, 4, 2, 6, 1, 2, 7, 1, 1, 44, 7, 1, 1, 2, 1, 2, 3, 8, 15, 5, 4, 1, 8, 8, 12, 3, 2, 4, 1, 1, 4, 3, 7, 30, 6, 2, 1, 4, 3, 6, 1, 1, 19, 10, 4, 2, 7, 7, 6, 1, 1, 1, 21, 3, 5, 5, 2, 2, 3, 3, 10, 49, 6, 2, 2, 5, 15, 1, 2, 9, 3, 15, 16, 49, 51, 4, 1, 1, 1, 1, 8, 5, 1, 2, 4, 6, 9, 2, 2, 4, 2, 2, 3, 3, 2, 12, 26, 3, 45, 6, 10, 4, 5, 19, 3, 3, 19, 32, 12, 1, 10, 3, 6, 1, 4, 4, 1, 3, 16, 8, 1, 2, 19, 38, 3, 1, 1, 1, 2, 5, 2, 7, 2, 3, 6, 2, 2, 5, 14, 1, 2, 57, 7, 1, 2, 1, 2, 2, 30, 1, 14, 2, 39, 1, 2, 2, 2, 1, 1, 3, 2, 8, 1, 4, 5, 3, 3, 5, 9, 3, 3, 3, 8, 1, 2, 1, 10, 6, 9, 2, 1, 3, 38, 2, 9, 3, 3, 9, 13, 3, 1, 9, 2, 6, 1, 2, 1, 3, 4, 8, 14, 1, 3, 27, 5, 7, 1, 1, 11, 28, 1, 1, 1, 3, 1, 8, 1, 1, 1, 18, 6, 4, 2, 6, 1, 3, 20, 5, 16, 7, 2, 4, 2, 2, 1, 3, 12, 8, 6, 6, 19, 11, 34, 8, 16, 1, 12, 46, 1, 2, 2, 16, 33, 1, 10, 11, 11, 6, 6, 6, 1, 5, 35, 21, 2, 11, 1, 42, 1, 10, 1, 1, 1, 1, 10, 17, 2, 16, 10, 1, 3, 4, 1, 6, 24, 1, 1, 3, 24, 6, 18, 2, 2, 30, 1, 16, 61, 10, 3, 1, 1, 3, 3, 2, 7, 5, 1, 2, 2, 5, 25, 4, 1, 6, 1, 3, 7, 2, 6, 13, 1, 5, 49, 1, 9, 1, 1, 3, 1, 2, 4, 8, 6, 1, 16, 3, 14, 33, 2, 1, 9, 55, 6, 6, 2, 5, 4, 1, 6, 4, 1, 20, 7, 169, 4, 8, 3, 12, 15, 1, 45, 4, 34, 26, 2, 3, 1, 2, 23, 4, 4, 1, 22, 23, 13, 28, 9, 5, 2, 9, 1, 25, 2, 8, 8, 1, 5, 3, 7, 1, 1, 3, 13, 6, 5, 2, 36, 1, 12, 5, 12, 56, 1, 3, 22, 63, 1, 22, 38, 3, 14, 1, 2, 1, 1, 12, 5, 4, 4, 1, 2, 1, 3, 3, 1, 1, 1, 3, 16, 10, 1, 4, 5, 1, 4, 8, 1, 2, 4, 49, 79, 6, 1, 3, 2, 7, 26, 2, 35, 1, 10, 3, 2, 4, 1, 16, 1, 1, 2, 12, 1, 1, 2, 8, 5, 1, 2, 1, 1, 1, 3, 3, 1, 4, 1, 1, 1, 7, 3, 6, 8, 2, 1, 6, 7, 5, 4, 1, 1, 5, 13, 2, 2, 35, 11, 7, 1, 10, 19, 29, 1, 1, 1, 6, 2, 3, 1, 4, 20, 1, 1, 7, 2, 56, 1, 2, 16, 10, 32, 34, 1, 25, 2, 1, 1, 1, 1, 1, 4, 10, 2, 5, 1, 12, 3, 1, 46, 1, 1, 1, 7, 3, 3, 2, 1, 2, 30, 4, 6, 1, 10, 2, 2, 1, 3, 1, 3, 2, 1, 9, 13, 2, 2, 6, 5, 2, 1, 3, 4, 23, 14, 1, 6, 35, 3, 20, 1, 1, 11, 59, 1, 8, 10, 28, 7, 2, 7, 1, 48, 9, 15, 2, 5, 2, 8, 5, 3, 2, 5, 31, 1, 61, 3, 5, 2, 59, 7, 4, 1, 1, 9, 11, 1, 7, 17, 25, 3, 1, 1, 1, 22, 3, 10, 21, 1, 1, 11, 2, 1, 20, 1, 12, 1, 2, 1, 2, 1, 7, 3, 1, 3, 29, 5, 1, 4, 6, 1, 1, 95, 4, 1, 2, 29, 67, 20, 1, 5, 2, 2, 142, 2, 1, 2, 2, 3, 2, 4, 2, 19, 20, 3, 44, 23, 3, 6, 37, 24, 11, 1, 1, 5, 1, 9, 2, 1, 7, 1, 1, 11, 21, 2, 1, 16, 9, 6, 1, 3, 2, 12, 7, 18, 1, 1, 2, 3, 7, 9, 3, 17, 3, 1, 5, 8, 10, 2, 1, 5, 4, 28, 19, 1, 27, 7, 1, 4, 2, 3, 22, 1, 37, 2, 34, 21, 1, 10, 1, 3, 1, 1, 5, 5, 1, 1, 37, 6, 12, 1, 1, 9, 3, 1, 1, 1, 24, 1, 3, 1, 3, 10, 14, 1, 8, 10, 37, 20, 5, 6, 3, 3, 1, 18, 1, 1, 2, 1, 1, 1, 5, 1, 11, 5, 15, 1, 1, 8, 1, 1, 13, 8, 6, 1, 9, 1, 9, 4, 3, 39, 1, 2, 4, 1, 82, 3, 2, 11, 1, 1, 52, 2, 3, 1, 1, 2, 5, 5, 15, 30, 3, 31, 8, 6, 2, 5, 57, 29, 4, 4, 30, 11, 1, 9, 8, 7, 6, 21, 1, 6, 1, 1, 1, 14, 2, 1, 7, 52, 6, 8, 1, 1, 10, 21, 14, 68, 1, 7, 1, 7, 4, 6, 9, 4, 1, 30, 16, 5, 11, 6, 58, 1, 23, 51, 3, 1, 10, 2, 8, 1, 2, 1, 1, 12, 1, 8, 1, 5, 2, 1, 12, 1, 8, 14, 3, 1, 1, 1, 2, 6, 1, 8, 1, 2, 18, 1, 6, 1, 5, 1, 17, 1, 1, 3, 5, 77, 17, 68, 12, 4, 2, 3, 21, 2, 11, 12, 10, 1, 1, 2, 1, 1, 7, 1, 1, 31, 1, 1, 1, 20, 5, 1, 7, 1, 15, 8, 3, 9, 4, 21, 4, 3, 1, 29, 2, 2, 1, 1, 8, 2, 10, 3, 10, 6, 4, 5, 1, 1, 1, 3, 25, 2, 5, 1, 1, 2, 1, 2, 3, 5, 2, 22, 1, 2, 70, 2, 1, 49, 4, 1, 24, 1, 4, 1, 14, 4, 5, 8, 1, 2, 31, 2, 1, 17, 7, 1, 8, 1, 10, 1, 2, 9, 2, 1, 4, 2, 2, 2, 2, 2, 1, 15, 5, 9, 11, 1, 11, 2, 3, 1, 7, 1, 8, 11, 1, 7, 114, 2, 1, 3, 1, 6, 3, 1, 1, 12, 5, 1, 11, 3, 12, 3, 1, 1, 34, 3, 5, 1, 1, 3, 7, 2, 8, 6, 1, 1, 1, 6, 2, 12, 22, 4, 1, 28, 1, 11, 145, 27, 1, 3, 39, 12, 6, 1, 17, 10, 1, 5, 6, 3, 1, 2, 2, 7, 28, 1, 11, 1, 20, 1, 28, 1, 10, 36, 24, 2, 6, 23, 2, 2, 9, 6, 1, 1, 6, 7, 9, 22, 1, 6, 35, 1, 2, 1, 80, 1, 6, 11, 1, 9, 1, 5, 85, 10, 3, 7, 1, 2, 2, 1, 7, 4, 1, 3, 1, 1, 17, 3, 7, 1, 12, 1, 2, 6, 2, 4, 3, 1, 1, 3, 1, 3, 3, 1, 10, 2, 1, 4, 3, 1, 2, 1, 3, 1, 1, 1, 5, 1, 8, 10, 2, 8, 8, 5, 16, 5, 1, 20, 6, 4, 8, 14, 23, 21, 1, 26, 9, 8, 2, 3, 8, 2, 13, 37, 5, 16, 2, 1, 7, 9, 1, 1, 4, 3, 1, 6, 1, 9, 1, 1, 2, 6, 10, 4, 1, 13, 4, 5, 15, 1, 1, 16, 1, 6, 5, 15, 1, 1, 3, 1, 1, 2, 140, 33, 1, 6, 4, 3, 2, 8, 1, 2, 3, 14, 1, 1, 1, 1, 8, 14, 13, 8, 39, 5, 1, 5, 1, 37, 4, 6, 4, 1, 10, 4, 40, 1, 10, 5, 1, 1, 19, 2, 1, 11, 1, 14, 1, 2, 2, 1, 11, 1, 14, 1, 7, 9, 6, 9, 3, 47, 4, 1, 2, 4, 4, 4, 5, 5, 47, 2, 17, 2, 7, 1, 2, 1, 4, 3, 4, 7, 8, 8, 3, 6, 2, 1, 27, 1, 12, 1, 78, 1, 12, 2, 2, 1, 2, 3, 6, 2, 6, 1, 9, 18, 39, 3, 1, 2, 10, 17, 11, 3, 1, 22, 1, 5, 2, 3, 2, 3, 13, 12, 4, 2, 2, 1, 2, 10, 4, 20, 10, 5, 19, 12, 2, 4, 73, 10, 2, 6, 18, 1, 2, 2, 1, 1, 26, 1, 3, 8, 1, 3, 3, 1, 1, 1, 2, 3, 3, 1, 9, 10, 4, 3, 4, 1, 1, 2, 1, 6, 2, 6, 8, 4, 2, 4, 5, 12, 2, 9, 2, 3, 8, 1, 7, 12, 2, 1, 3, 15, 22, 6, 13, 1, 1, 1, 1, 2, 1, 2, 3, 7, 1, 3, 17, 147, 1, 1, 13, 2, 6, 4, 11, 13, 3, 1, 12, 22, 23, 12, 2, 9, 26, 1, 1, 3, 5, 31, 23, 1, 6, 11, 1, 1, 2, 3, 9, 1, 1, 30, 4, 98, 2, 8, 4, 1, 7, 1, 1, 1, 2, 2, 7, 5, 1, 1, 2, 30, 4, 4, 5, 1, 2, 4, 62, 19, 22, 2, 3, 9, 2, 2, 8, 1, 2, 23, 1, 2, 1, 1, 13, 5, 10, 15, 2, 32, 4, 3, 2, 9, 6, 5, 12, 1, 1, 18, 2, 6, 3, 6, 8, 5, 5, 13, 15, 7, 1, 2, 18, 1, 2, 7, 8, 1, 1, 20, 5, 4, 3, 2, 42, 5, 2, 12, 53, 11, 3, 1, 6, 7, 45, 1, 1, 6, 57, 3, 1, 4, 1, 6, 1, 2, 1, 31, 3, 3, 12, 18, 1, 6, 1, 4, 38, 26, 9, 14, 1, 3, 6, 7, 2, 8, 1, 1, 1, 30, 20, 3, 2, 2, 4, 14, 2, 22, 5, 4, 4, 39, 1, 1, 15, 67, 1, 12, 13, 29, 3, 5, 2, 1, 2, 1, 3, 1, 8, 6, 6, 24, 7, 2, 136, 48, 28, 7, 5, 11, 7, 1, 19, 6, 1, 2, 1, 1, 11, 3, 30, 24, 3, 2, 7, 20, 5, 2, 10, 23, 1, 74, 2, 1, 4, 2, 1, 4, 1, 3, 4, 13, 2, 3, 2, 2, 1, 11, 3, 6, 2, 4, 1, 3, 7, 7, 2, 2, 1, 11, 1, 14, 1, 1, 1, 1, 68, 5, 2, 57, 4, 2, 22, 1, 1, 7, 3, 4, 12, 1, 5, 3, 1, 1, 1, 53, 1, 1, 2, 5, 5, 1, 1, 2, 2, 3, 14, 1, 18, 5, 11, 10, 4, 1, 15, 1, 2, 1, 1, 1, 2, 6, 41, 1, 5, 5, 1, 7, 50, 2, 8, 1, 6, 4, 1, 2, 26, 101, 34, 1, 5, 6, 2, 4, 2, 1, 5, 47, 1, 13, 6, 6, 1, 10, 23, 1, 5, 2, 6, 2, 6, 1, 2, 2, 6, 2, 1, 14, 33, 4, 16, 4, 2, 6, 6, 2, 16, 12, 21, 3, 4, 7, 1, 20, 1, 13, 1, 7, 1, 23, 17, 46, 2, 3, 1, 1, 12, 8, 38, 21, 48, 1, 43, 2, 5, 2, 28, 5, 1, 1, 1, 1, 2, 28, 3, 53, 1, 11, 2, 1, 25, 1, 2, 17, 5, 1, 2, 25, 1, 3, 1, 8, 28, 1, 1, 2, 38, 8, 6, 1, 1, 2, 6, 12, 1, 1, 1, 1, 5, 7, 10, 52, 1, 1, 9, 2, 1, 5, 12, 21, 2, 1, 47, 2, 1, 17, 3, 7, 2, 1, 12, 3, 7, 5, 6, 1, 1, 1, 1, 4, 2, 5, 11, 2, 1, 7, 36, 2, 1, 9, 2, 3, 1, 1, 4, 7, 3, 10, 9, 5, 2, 11, 1, 1, 4, 26, 1, 2, 1, 94, 3, 1, 4, 6, 3, 1, 15, 4, 25, 4, 8, 1, 1, 5, 3, 1, 2, 2, 33, 7, 8, 25, 2, 3, 8, 2, 7, 1, 11, 14, 1, 1, 1, 18, 2, 4, 9, 2, 1, 10, 2, 6, 11, 28, 7, 9, 1, 13, 20, 3, 1, 2, 2, 3, 1, 1, 1, 3, 2, 14, 2, 1, 10, 3, 1, 13, 30, 1, 43, 8, 1, 8, 3, 4, 13, 17, 6, 1, 8, 3, 7, 8, 2, 2, 6, 1, 1, 6, 3, 5, 8, 10, 1, 6, 6, 2, 1, 3, 10, 1, 13, 16, 1, 42, 5, 13, 1, 2, 42, 15, 36, 11, 1, 158, 1, 12, 5, 2, 2, 11, 4, 6, 25, 4, 1, 4, 12, 3, 1, 5, 1, 44, 1, 12, 5, 2, 4, 5, 19, 19, 9, 2, 2, 4, 3, 3, 1, 3, 4, 1, 1, 5, 1, 1, 2, 13, 1, 15, 1, 1, 1, 2, 27, 1, 13, 18, 6, 3, 35, 21, 1, 1, 5, 2, 5, 1, 82, 1, 18, 5, 2, 29, 4, 4, 1, 28, 1, 2, 35, 8, 2, 6, 1, 2, 38, 1, 7, 1, 1, 5, 1, 1, 1, 9, 2, 13, 7, 3, 33, 116, 1, 7, 1, 1, 1, 1, 3, 3, 13, 4, 8, 20, 10, 30, 5, 1, 1, 1, 15, 3, 3, 2, 4, 1, 3, 1, 1, 4, 13, 3, 4, 1, 1, 2, 3, 1, 14, 7, 9, 38, 1, 2, 4, 32, 10, 13], \"opacity\": 0.75, \"name\": \"Articles per User\", \"xbins\": {\"start\": 0, \"end\": 300, \"size\": 5}, \"marker\": {\"color\": \"darkblue\"}, \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"xaxis1\": {\"domain\": [0.0, 0.45], \"anchor\": \"y1\", \"title\": \"No of Times an Article is Viewed\", \"titlefont\": {\"size\": 10}}, \"yaxis1\": {\"domain\": [0.0, 1.0], \"anchor\": \"x1\", \"title\": \"Frequency\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"gridwidth\": null}, \"xaxis2\": {\"domain\": [0.55, 1.0], \"anchor\": \"y2\", \"title\": \"No of Articles a User Views\", \"titlefont\": {\"size\": 10}}, \"yaxis2\": {\"domain\": [0.0, 1.0], \"anchor\": \"x2\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"gridwidth\": null}, \"height\": 500, \"width\": 900, \"title\": \"User x Article Interactions\", \"titlefont\": {\"size\": 13}, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"bargap\": 0.1, \"legend\": {\"x\": 0.8, \"y\": 0.8, \"xanchor\": \"center\", \"yanchor\": \"middle\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"e26d9398-8ca2-4110-9d9e-5acbe5e31f75\" style=\"height: 500px; width: 900px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e26d9398-8ca2-4110-9d9e-5acbe5e31f75\", [{\"type\": \"histogram\", \"x\": [14, 58, 13, 85, 10, 157, 89, 26, 61, 78, 248, 15, 89, 42, 75, 17, 64, 141, 93, 18, 68, 70, 300, 11, 89, 124, 115, 20, 140, 11, 13, 16, 20, 55, 29, 57, 69, 57, 11, 57, 19, 24, 12, 18, 24, 38, 7, 152, 9, 89, 29, 78, 28, 189, 198, 64, 68, 20, 28, 16, 160, 10, 130, 110, 300, 127, 54, 75, 44, 10, 37, 75, 42, 26, 22, 33, 300, 59, 85, 13, 38, 149, 222, 91, 12, 16, 9, 40, 7, 78, 33, 124, 115, 21, 89, 63, 53, 113, 21, 113, 85, 41, 31, 33, 68, 16, 20, 41, 198, 33, 48, 169, 37, 155, 42, 23, 46, 59, 10, 15, 222, 44, 20, 146, 16, 24, 14, 60, 45, 24, 38, 18, 41, 28, 18, 23, 34, 10, 84, 34, 15, 51, 60, 90, 15, 18, 18, 65, 9, 85, 34, 19, 25, 22, 23, 85, 43, 6, 19, 67, 5, 13, 33, 80, 3, 2, 11, 24, 93, 11, 9, 2, 73, 29, 44, 10, 2, 4, 270, 3, 21, 12, 10, 7, 134, 35, 13, 151, 2, 1, 4, 47, 15, 32, 10, 4, 2, 10, 40, 2, 54, 8, 49, 23, 20, 98, 11, 56, 48, 22, 60, 9, 5, 19, 91, 17, 16, 160, 50, 77, 48, 12, 48, 68, 2, 12, 6, 2, 60, 113, 8, 8, 4, 17, 22, 85, 32, 10, 8, 179, 14, 54, 4, 4, 14, 56, 30, 5, 42, 8, 18, 2, 23, 26, 2, 6, 128, 21, 209, 32, 46, 43, 4, 21, 64, 20, 21, 10, 3, 18, 38, 2, 124, 2, 102, 54, 108, 1, 9, 19, 83, 22, 1, 39, 28, 12, 84, 16, 107, 1, 2, 13, 6, 18, 220, 73, 107, 18, 67, 36, 58, 4, 32, 2, 6, 12, 18, 31, 21, 95, 1, 41, 32, 121, 143, 239, 25, 4, 46, 52, 10, 2, 2, 12, 7, 56, 6, 46, 64, 28, 2, 10, 29, 25, 18, 68, 37, 111, 4, 5, 108, 151, 40, 84, 41, 101, 44, 99, 34, 15, 35, 8, 29, 27, 12, 36, 123, 32, 2, 38, 19, 41, 104, 11, 18, 4, 45, 34, 23, 10, 63, 54, 24, 7, 125, 52, 10, 10, 26, 44, 11, 105, 14, 30, 135, 2, 6, 126, 2, 10, 11, 28, 25, 35, 100, 83, 65, 2, 51, 27, 45, 26, 139, 2, 9, 1, 74, 36, 130, 1, 4, 13, 26, 19, 62, 4, 16, 7, 14, 17, 116, 5, 80, 234, 66, 74, 182, 51, 8, 18, 8, 45, 4, 52, 137, 108, 87, 42, 300, 215, 219, 103, 58, 79, 22, 66, 57, 22, 8, 6, 3, 9, 5, 2, 4, 2, 6, 4, 1, 5, 9, 2, 9, 3, 8, 5, 2, 4, 5, 2, 2, 2, 1, 8, 2, 3, 3, 2, 1, 8, 4, 1, 8, 2, 2, 6, 9, 8, 1, 3, 2, 2, 2, 2, 26, 6, 6, 11, 9, 12, 2, 12, 8, 4, 8, 14, 23, 8, 16, 10, 14, 26, 2, 42, 55, 37, 300, 24, 300, 290, 253, 300, 192, 2, 28, 57, 300, 213, 300, 32, 212, 55, 171, 21, 38, 6, 78, 116, 168, 73, 300, 145, 6, 2, 32, 16, 10, 8, 2, 2, 2, 23, 5, 1, 1, 2, 3, 2, 2, 23, 8, 30, 2, 2, 5, 2, 12, 1, 4, 2, 1, 2, 4, 2, 5, 7, 6, 6, 8, 12, 32, 1, 4, 300, 24, 204, 300, 74, 104, 30, 25, 18, 191, 2, 3, 30, 13, 39, 7, 15, 300, 4, 10, 193, 4, 61, 40, 2, 300, 300, 8, 4, 4, 47, 300, 4, 95, 6, 6, 160, 58, 183, 2, 148, 40, 300, 29, 206, 8, 2, 2, 300, 37, 300, 2, 293, 1, 2, 7, 24, 43, 300, 300, 3, 41, 123, 19, 13, 214, 12, 16, 22, 300, 2, 69, 185, 300, 10, 4, 2, 11, 2, 189, 26, 2, 191, 300, 182, 122, 206, 24, 300, 279, 7, 52, 69, 50, 136, 58, 22, 16, 54, 109, 42, 25, 4, 11, 102, 43, 6, 113, 3, 163, 155, 131, 71, 138, 300, 120, 300, 300, 300, 300, 108, 42, 120, 300, 218, 59, 10, 8, 4, 22, 5], \"opacity\": 0.75, \"name\": \"Views per Article\", \"xbins\": {\"start\": 0, \"end\": 300, \"size\": 5}, \"marker\": {\"color\": \"red\"}, \"xaxis\": \"x1\", \"yaxis\": \"y1\"}, {\"type\": \"histogram\", \"x\": [13, 4, 3, 6, 2, 2, 3, 10, 1, 13, 1, 4, 3, 4, 3, 11, 3, 1, 2, 4, 9, 1, 35, 11, 15, 3, 7, 2, 1, 11, 101, 20, 2, 2, 10, 4, 3, 1, 1, 14, 40, 3, 13, 7, 4, 11, 1, 9, 3, 5, 1, 10, 2, 3, 8, 83, 18, 6, 3, 5, 2, 1, 6, 1, 1, 1, 3, 1, 1, 5, 11, 3, 8, 3, 6, 2, 5, 3, 9, 1, 6, 40, 26, 2, 1, 1, 2, 24, 3, 8, 2, 1, 2, 25, 1, 3, 12, 1, 3, 6, 1, 6, 4, 1, 4, 3, 9, 35, 7, 6, 4, 1, 2, 33, 3, 29, 4, 7, 1, 9, 4, 1, 9, 12, 5, 4, 1, 1, 19, 5, 2, 3, 3, 45, 2, 2, 12, 1, 16, 1, 5, 1, 2, 1, 2, 8, 5, 4, 26, 26, 2, 1, 2, 1, 15, 3, 14, 3, 4, 49, 4, 3, 13, 3, 1, 1, 3, 24, 1, 4, 1, 5, 5, 1, 14, 11, 3, 2, 26, 7, 18, 2, 3, 3, 1, 1, 41, 1, 2, 6, 1, 9, 29, 11, 1, 17, 10, 12, 12, 1, 1, 2, 3, 6, 1, 1, 1, 1, 12, 7, 1, 10, 48, 9, 1, 2, 3, 1, 4, 1, 1, 5, 1, 3, 1, 1, 1, 1, 5, 1, 5, 1, 1, 17, 3, 1, 1, 12, 4, 2, 1, 20, 11, 2, 4, 3, 13, 5, 20, 9, 14, 29, 3, 6, 39, 2, 3, 1, 8, 8, 5, 4, 6, 13, 3, 6, 7, 1, 2, 6, 1, 66, 1, 1, 16, 1, 1, 6, 2, 2, 1, 3, 2, 102, 4, 8, 6, 6, 41, 23, 7, 2, 4, 17, 2, 8, 4, 5, 1, 3, 1, 9, 1, 79, 33, 1, 1, 1, 2, 72, 2, 5, 1, 14, 2, 3, 6, 5, 2, 1, 1, 1, 1, 15, 1, 5, 1, 25, 1, 5, 24, 2, 31, 1, 1, 16, 4, 8, 1, 1, 15, 17, 3, 1, 2, 1, 10, 1, 1, 1, 5, 8, 1, 4, 64, 3, 1, 4, 2, 7, 10, 4, 4, 4, 48, 41, 14, 4, 2, 91, 17, 19, 4, 1, 1, 4, 1, 6, 1, 2, 62, 1, 4, 3, 1, 4, 1, 24, 2, 2, 14, 1, 2, 6, 32, 1, 5, 9, 75, 4, 7, 104, 6, 14, 15, 3, 2, 5, 1, 25, 6, 1, 1, 3, 2, 2, 1, 30, 2, 2, 7, 2, 2, 6, 2, 3, 3, 36, 1, 1, 31, 66, 3, 32, 1, 1, 1, 3, 18, 14, 1, 11, 4, 1, 3, 12, 4, 2, 1, 8, 1, 1, 1, 84, 1, 79, 11, 1, 22, 19, 20, 1, 2, 2, 3, 1, 1, 1, 1, 4, 3, 10, 1, 11, 2, 2, 9, 2, 18, 1, 1, 2, 11, 1, 3, 9, 1, 10, 2, 1, 7, 18, 46, 1, 1, 6, 37, 1, 2, 1, 2, 17, 5, 1, 4, 3, 11, 28, 11, 11, 11, 6, 1, 2, 1, 1, 8, 1, 2, 11, 2, 2, 1, 1, 4, 147, 1, 1, 1, 6, 24, 1, 8, 23, 38, 1, 5, 1, 14, 1, 1, 1, 89, 1, 53, 1, 1, 1, 7, 1, 1, 1, 2, 6, 1, 5, 1, 1, 1, 3, 1, 2, 1, 38, 4, 1, 5, 1, 2, 1, 2, 5, 6, 23, 13, 5, 2, 6, 10, 10, 1, 1, 4, 2, 1, 7, 4, 2, 5, 2, 2, 1, 8, 1, 4, 1, 2, 5, 1, 1, 2, 1, 2, 13, 1, 2, 11, 1, 33, 10, 21, 1, 58, 4, 11, 1, 1, 22, 3, 14, 3, 22, 1, 1, 1, 2, 7, 2, 30, 21, 1, 4, 4, 1, 7, 3, 4, 12, 3, 4, 2, 2, 17, 8, 1, 1, 18, 7, 2, 48, 5, 1, 5, 2, 3, 1, 2, 32, 3, 23, 1, 1, 16, 1, 13, 1, 26, 1, 1, 1, 7, 2, 3, 4, 3, 9, 6, 17, 1, 25, 4, 19, 9, 3, 5, 1, 2, 13, 67, 1, 8, 1, 1, 10, 47, 1, 5, 2, 1, 4, 2, 2, 2, 4, 1, 4, 1, 19, 5, 1, 5, 15, 17, 4, 43, 6, 14, 1, 59, 2, 1, 3, 1, 1, 1, 18, 7, 26, 8, 5, 1, 7, 17, 1, 3, 3, 1, 11, 4, 1, 1, 5, 1, 20, 13, 10, 34, 1, 1, 6, 21, 45, 3, 2, 8, 1, 3, 1, 9, 38, 19, 1, 4, 12, 16, 2, 1, 1, 9, 1, 4, 2, 1, 1, 5, 24, 2, 1, 1, 1, 2, 1, 2, 7, 13, 8, 3, 12, 19, 2, 2, 4, 38, 1, 3, 1, 27, 1, 2, 1, 1, 31, 3, 5, 1, 3, 1, 6, 1, 8, 29, 34, 1, 11, 22, 1, 1, 7, 12, 1, 1, 1, 76, 10, 1, 4, 8, 1, 1, 16, 54, 10, 145, 11, 6, 3, 3, 4, 15, 3, 2, 35, 3, 5, 11, 2, 1, 1, 2, 1, 7, 148, 40, 7, 1, 8, 3, 3, 6, 1, 1, 1, 1, 1, 4, 1, 2, 7, 1, 7, 8, 2, 7, 1, 8, 7, 2, 1, 8, 1, 2, 5, 1, 3, 2, 4, 1, 1, 10, 1, 2, 3, 10, 1, 50, 1, 2, 10, 4, 3, 14, 4, 7, 1, 6, 3, 25, 1, 21, 1, 300, 5, 3, 1, 51, 1, 2, 1, 2, 2, 4, 3, 21, 11, 8, 1, 15, 11, 33, 1, 2, 1, 1, 10, 8, 1, 1, 6, 14, 2, 5, 1, 2, 2, 34, 1, 82, 5, 29, 4, 5, 1, 2, 1, 3, 1, 9, 15, 26, 96, 1, 5, 6, 6, 15, 27, 7, 2, 1, 3, 4, 4, 22, 7, 2, 1, 4, 27, 1, 3, 1, 2, 6, 10, 2, 170, 2, 1, 64, 15, 5, 8, 2, 4, 10, 1, 1, 10, 60, 6, 11, 1, 5, 2, 7, 17, 2, 1, 4, 2, 42, 12, 4, 2, 1, 1, 11, 1, 3, 1, 2, 2, 1, 12, 7, 1, 5, 1, 1, 3, 1, 11, 2, 1, 1, 25, 12, 1, 6, 3, 19, 6, 2, 1, 8, 5, 1, 11, 1, 8, 6, 14, 1, 7, 1, 1, 5, 50, 4, 1, 6, 7, 3, 2, 4, 9, 1, 7, 2, 16, 5, 2, 1, 3, 1, 1, 1, 2, 13, 1, 103, 1, 6, 1, 5, 4, 6, 1, 2, 4, 2, 31, 3, 50, 28, 2, 5, 3, 2, 4, 27, 1, 2, 4, 3, 4, 4, 2, 3, 2, 3, 2, 22, 30, 2, 5, 5, 18, 2, 2, 9, 78, 13, 9, 5, 5, 4, 1, 3, 1, 4, 3, 1, 3, 6, 34, 5, 3, 25, 3, 1, 1, 16, 1, 1, 3, 2, 11, 6, 3, 3, 32, 5, 1, 1, 4, 2, 1, 6, 2, 1, 1, 5, 3, 4, 24, 1, 5, 37, 1, 31, 4, 1, 10, 3, 33, 63, 1, 3, 1, 1, 1, 1, 3, 2, 5, 6, 1, 1, 1, 13, 8, 12, 3, 5, 45, 1, 41, 21, 16, 3, 6, 2, 1, 7, 7, 41, 1, 5, 5, 18, 1, 1, 4, 8, 1, 30, 1, 1, 76, 1, 42, 3, 21, 2, 1, 11, 4, 7, 1, 82, 1, 6, 2, 3, 2, 9, 9, 32, 5, 16, 8, 1, 4, 13, 22, 4, 7, 18, 1, 19, 1, 4, 4, 1, 1, 6, 1, 1, 2, 1, 1, 21, 19, 6, 1, 7, 4, 28, 1, 18, 12, 2, 10, 39, 40, 7, 4, 18, 8, 6, 1, 1, 1, 1, 7, 1, 32, 1, 4, 2, 10, 1, 18, 1, 39, 5, 2, 4, 4, 5, 2, 18, 5, 5, 8, 3, 5, 3, 8, 3, 26, 8, 2, 10, 7, 19, 19, 3, 5, 4, 1, 5, 69, 7, 1, 42, 1, 13, 1, 5, 10, 10, 3, 5, 7, 2, 1, 44, 6, 1, 19, 4, 2, 4, 2, 6, 39, 2, 20, 5, 1, 1, 4, 95, 2, 20, 82, 11, 3, 60, 13, 4, 21, 12, 24, 1, 3, 3, 12, 4, 7, 25, 1, 1, 21, 2, 3, 5, 2, 58, 3, 1, 2, 3, 3, 37, 4, 2, 2, 1, 1, 11, 2, 7, 3, 5, 2, 12, 4, 1, 6, 2, 5, 1, 5, 3, 1, 24, 27, 1, 1, 25, 4, 1, 8, 16, 1, 1, 1, 17, 2, 7, 3, 2, 5, 3, 32, 19, 3, 4, 14, 5, 2, 4, 1, 1, 8, 5, 15, 1, 1, 4, 2, 1, 24, 6, 2, 37, 5, 7, 1, 3, 7, 1, 3, 3, 94, 15, 5, 2, 2, 1, 10, 1, 12, 1, 1, 2, 1, 2, 2, 26, 16, 1, 14, 2, 25, 10, 33, 3, 16, 3, 4, 3, 8, 1, 13, 3, 1, 3, 1, 2, 7, 1, 5, 1, 20, 30, 20, 16, 8, 1, 10, 2, 25, 58, 3, 13, 1, 2, 18, 1, 35, 1, 1, 4, 13, 1, 1, 2, 2, 1, 4, 3, 4, 3, 23, 3, 2, 7, 102, 2, 2, 8, 8, 1, 1, 3, 1, 2, 1, 1, 2, 10, 14, 6, 1, 19, 1, 3, 1, 1, 1, 1, 8, 1, 2, 4, 5, 1, 7, 38, 40, 1, 11, 1, 1, 1, 14, 1, 1, 40, 2, 4, 1, 1, 7, 1, 6, 1, 4, 9, 8, 1, 4, 1, 1, 38, 1, 2, 6, 5, 4, 1, 2, 10, 1, 9, 16, 24, 3, 21, 3, 9, 1, 7, 11, 5, 10, 28, 6, 1, 1, 1, 1, 2, 2, 1, 8, 1, 75, 4, 28, 1, 32, 1, 9, 7, 3, 11, 10, 7, 7, 3, 1, 1, 2, 1, 1, 1, 12, 4, 16, 5, 6, 1, 18, 2, 5, 2, 1, 13, 11, 2, 4, 29, 5, 6, 11, 1, 1, 2, 29, 3, 1, 9, 4, 20, 2, 1, 1, 1, 59, 8, 3, 1, 2, 4, 2, 1, 3, 11, 10, 5, 30, 1, 13, 6, 15, 5, 53, 1, 2, 9, 9, 9, 3, 50, 3, 1, 5, 2, 1, 2, 46, 10, 3, 1, 1, 3, 3, 38, 1, 4, 3, 13, 1, 20, 2, 1, 7, 3, 14, 2, 19, 14, 4, 14, 2, 3, 1, 1, 132, 34, 1, 15, 2, 4, 3, 9, 3, 5, 1, 11, 23, 4, 2, 28, 5, 3, 11, 6, 27, 11, 1, 30, 33, 3, 7, 25, 2, 5, 32, 6, 4, 18, 2, 3, 2, 4, 2, 3, 26, 2, 2, 2, 6, 62, 1, 1, 57, 2, 14, 2, 1, 4, 1, 65, 2, 1, 1, 144, 4, 1, 3, 8, 3, 6, 6, 1, 6, 8, 8, 1, 35, 1, 1, 2, 1, 33, 5, 2, 76, 12, 1, 4, 1, 18, 14, 3, 5, 1, 1, 3, 2, 11, 3, 4, 10, 6, 1, 5, 14, 10, 1, 3, 3, 2, 10, 3, 1, 5, 3, 1, 1, 3, 10, 2, 3, 5, 23, 2, 52, 1, 2, 2, 6, 1, 9, 2, 3, 28, 2, 2, 2, 1, 8, 4, 1, 1, 22, 7, 16, 1, 36, 4, 8, 52, 1, 1, 12, 1, 3, 10, 1, 6, 2, 2, 6, 2, 11, 2, 6, 17, 2, 2, 6, 3, 1, 13, 8, 3, 1, 3, 16, 2, 4, 32, 2, 1, 17, 4, 2, 5, 2, 2, 1, 5, 4, 13, 1, 17, 7, 3, 1, 1, 2, 10, 4, 29, 1, 36, 4, 16, 4, 23, 1, 21, 16, 1, 4, 2, 14, 13, 15, 3, 7, 4, 21, 7, 1, 8, 3, 3, 2, 2, 15, 10, 1, 1, 1, 6, 59, 37, 1, 3, 1, 3, 1, 4, 1, 2, 6, 7, 2, 2, 5, 1, 1, 1, 5, 1, 7, 1, 7, 2, 1, 13, 2, 2, 4, 3, 11, 3, 9, 16, 27, 2, 9, 20, 11, 3, 28, 4, 11, 1, 1, 3, 7, 1, 14, 4, 7, 2, 5, 5, 14, 9, 1, 11, 4, 9, 14, 11, 9, 6, 1, 41, 2, 3, 13, 9, 2, 5, 12, 3, 2, 39, 1, 52, 12, 2, 1, 24, 1, 20, 3, 5, 3, 2, 2, 7, 2, 4, 1, 10, 3, 7, 15, 2, 4, 3, 14, 11, 1, 5, 24, 7, 1, 20, 8, 2, 11, 5, 6, 26, 4, 58, 1, 1, 1, 2, 1, 1, 16, 6, 1, 1, 20, 2, 2, 1, 1, 9, 5, 5, 1, 4, 89, 8, 2, 2, 4, 15, 84, 2, 4, 45, 13, 69, 1, 4, 9, 10, 1, 1, 2, 10, 2, 3, 30, 1, 10, 1, 6, 1, 4, 15, 8, 35, 67, 1, 1, 5, 4, 13, 53, 1, 24, 5, 4, 1, 7, 1, 3, 1, 11, 8, 1, 50, 48, 1, 1, 4, 4, 7, 5, 16, 3, 1, 43, 40, 1, 1, 5, 2, 2, 15, 1, 1, 4, 4, 3, 6, 1, 2, 12, 3, 2, 8, 5, 3, 9, 1, 8, 3, 131, 3, 2, 7, 1, 1, 20, 9, 5, 4, 8, 1, 13, 1, 3, 17, 3, 72, 2, 1, 11, 28, 26, 1, 3, 2, 83, 23, 4, 4, 22, 1, 1, 1, 4, 2, 1, 2, 1, 2, 2, 1, 3, 11, 2, 19, 34, 1, 2, 42, 3, 32, 2, 1, 2, 92, 1, 1, 11, 20, 5, 10, 2, 1, 4, 9, 3, 3, 4, 8, 10, 3, 60, 1, 1, 6, 2, 3, 1, 5, 1, 24, 1, 2, 1, 4, 1, 1, 7, 2, 3, 28, 2, 1, 1, 2, 2, 1, 1, 6, 1, 1, 3, 1, 2, 10, 10, 1, 1, 3, 1, 1, 13, 6, 4, 12, 1, 1, 2, 3, 11, 1, 10, 3, 1, 21, 6, 14, 6, 1, 8, 1, 1, 4, 6, 3, 16, 1, 1, 2, 1, 1, 4, 1, 10, 20, 4, 3, 8, 2, 11, 1, 4, 6, 1, 1, 3, 1, 1, 1, 3, 6, 2, 8, 2, 1, 2, 10, 33, 9, 2, 5, 9, 2, 16, 4, 1, 7, 2, 1, 1, 4, 1, 2, 5, 3, 10, 1, 3, 2, 34, 17, 9, 2, 16, 15, 58, 1, 1, 1, 5, 4, 5, 26, 3, 5, 9, 16, 7, 3, 10, 3, 25, 2, 3, 3, 25, 4, 1, 8, 27, 8, 5, 1, 6, 1, 3, 7, 1, 1, 8, 8, 1, 3, 4, 1, 1, 3, 4, 300, 2, 4, 4, 5, 4, 19, 23, 21, 1, 1, 10, 3, 6, 1, 1, 18, 7, 8, 2, 2, 4, 9, 5, 2, 3, 35, 15, 1, 18, 2, 3, 13, 2, 11, 1, 4, 7, 5, 25, 5, 3, 10, 51, 5, 3, 3, 50, 8, 7, 8, 2, 3, 4, 6, 1, 8, 1, 5, 13, 2, 11, 4, 7, 25, 12, 23, 3, 91, 7, 7, 2, 5, 1, 4, 3, 35, 2, 1, 1, 9, 1, 2, 2, 32, 2, 10, 1, 16, 10, 7, 4, 13, 6, 1, 9, 26, 11, 2, 22, 1, 1, 28, 5, 13, 3, 1, 1, 1, 2, 5, 1, 1, 18, 6, 97, 24, 6, 3, 1, 2, 1, 20, 1, 1, 4, 1, 6, 1, 9, 2, 3, 3, 1, 10, 5, 33, 18, 1, 1, 5, 2, 1, 1, 1, 81, 1, 3, 2, 3, 1, 9, 7, 7, 3, 25, 1, 7, 1, 1, 8, 36, 40, 1, 4, 1, 1, 3, 6, 3, 3, 50, 4, 6, 12, 60, 2, 5, 35, 1, 4, 1, 4, 1, 1, 1, 2, 1, 14, 1, 5, 10, 2, 6, 9, 4, 2, 1, 17, 1, 4, 5, 8, 2, 5, 2, 1, 1, 6, 1, 8, 6, 51, 10, 2, 2, 7, 1, 1, 1, 1, 8, 1, 13, 3, 1, 1, 7, 1, 2, 84, 22, 4, 11, 2, 1, 1, 1, 9, 1, 10, 3, 1, 3, 10, 3, 1, 21, 22, 1, 1, 2, 18, 10, 160, 5, 52, 3, 2, 12, 1, 3, 55, 7, 7, 4, 80, 4, 6, 2, 11, 1, 4, 6, 4, 2, 1, 4, 3, 3, 7, 1, 1, 2, 2, 4, 5, 2, 3, 1, 11, 8, 5, 2, 3, 1, 19, 13, 1, 4, 3, 79, 2, 1, 1, 3, 1, 2, 23, 9, 3, 3, 1, 2, 22, 3, 9, 3, 2, 8, 7, 6, 3, 3, 18, 3, 2, 3, 1, 1, 1, 6, 2, 18, 3, 1, 5, 4, 1, 8, 1, 4, 29, 5, 1, 29, 1, 9, 1, 4, 9, 15, 1, 80, 1, 11, 5, 15, 1, 7, 12, 29, 2, 1, 4, 1, 51, 55, 7, 8, 2, 6, 1, 18, 1, 4, 5, 2, 9, 3, 3, 1, 2, 2, 33, 7, 4, 9, 12, 6, 1, 16, 3, 5, 1, 32, 8, 3, 3, 19, 1, 1, 3, 20, 12, 1, 1, 8, 1, 6, 1, 1, 3, 1, 9, 7, 2, 7, 7, 1, 12, 1, 1, 3, 2, 1, 3, 1, 2, 18, 2, 7, 1, 2, 2, 2, 10, 1, 1, 3, 39, 137, 14, 2, 6, 2, 1, 9, 14, 1, 20, 2, 4, 5, 1, 3, 6, 3, 5, 2, 7, 2, 1, 2, 6, 1, 11, 3, 34, 1, 1, 1, 17, 20, 4, 6, 1, 10, 1, 8, 29, 31, 5, 1, 13, 2, 4, 3, 1, 2, 1, 2, 1, 1, 5, 4, 1, 1, 1, 3, 1, 9, 20, 1, 18, 9, 1, 8, 2, 1, 4, 3, 10, 4, 2, 1, 3, 1, 2, 5, 2, 9, 4, 4, 4, 4, 2, 2, 4, 4, 2, 1, 4, 12, 4, 2, 6, 1, 2, 7, 1, 1, 44, 7, 1, 1, 2, 1, 2, 3, 8, 15, 5, 4, 1, 8, 8, 12, 3, 2, 4, 1, 1, 4, 3, 7, 30, 6, 2, 1, 4, 3, 6, 1, 1, 19, 10, 4, 2, 7, 7, 6, 1, 1, 1, 21, 3, 5, 5, 2, 2, 3, 3, 10, 49, 6, 2, 2, 5, 15, 1, 2, 9, 3, 15, 16, 49, 51, 4, 1, 1, 1, 1, 8, 5, 1, 2, 4, 6, 9, 2, 2, 4, 2, 2, 3, 3, 2, 12, 26, 3, 45, 6, 10, 4, 5, 19, 3, 3, 19, 32, 12, 1, 10, 3, 6, 1, 4, 4, 1, 3, 16, 8, 1, 2, 19, 38, 3, 1, 1, 1, 2, 5, 2, 7, 2, 3, 6, 2, 2, 5, 14, 1, 2, 57, 7, 1, 2, 1, 2, 2, 30, 1, 14, 2, 39, 1, 2, 2, 2, 1, 1, 3, 2, 8, 1, 4, 5, 3, 3, 5, 9, 3, 3, 3, 8, 1, 2, 1, 10, 6, 9, 2, 1, 3, 38, 2, 9, 3, 3, 9, 13, 3, 1, 9, 2, 6, 1, 2, 1, 3, 4, 8, 14, 1, 3, 27, 5, 7, 1, 1, 11, 28, 1, 1, 1, 3, 1, 8, 1, 1, 1, 18, 6, 4, 2, 6, 1, 3, 20, 5, 16, 7, 2, 4, 2, 2, 1, 3, 12, 8, 6, 6, 19, 11, 34, 8, 16, 1, 12, 46, 1, 2, 2, 16, 33, 1, 10, 11, 11, 6, 6, 6, 1, 5, 35, 21, 2, 11, 1, 42, 1, 10, 1, 1, 1, 1, 10, 17, 2, 16, 10, 1, 3, 4, 1, 6, 24, 1, 1, 3, 24, 6, 18, 2, 2, 30, 1, 16, 61, 10, 3, 1, 1, 3, 3, 2, 7, 5, 1, 2, 2, 5, 25, 4, 1, 6, 1, 3, 7, 2, 6, 13, 1, 5, 49, 1, 9, 1, 1, 3, 1, 2, 4, 8, 6, 1, 16, 3, 14, 33, 2, 1, 9, 55, 6, 6, 2, 5, 4, 1, 6, 4, 1, 20, 7, 169, 4, 8, 3, 12, 15, 1, 45, 4, 34, 26, 2, 3, 1, 2, 23, 4, 4, 1, 22, 23, 13, 28, 9, 5, 2, 9, 1, 25, 2, 8, 8, 1, 5, 3, 7, 1, 1, 3, 13, 6, 5, 2, 36, 1, 12, 5, 12, 56, 1, 3, 22, 63, 1, 22, 38, 3, 14, 1, 2, 1, 1, 12, 5, 4, 4, 1, 2, 1, 3, 3, 1, 1, 1, 3, 16, 10, 1, 4, 5, 1, 4, 8, 1, 2, 4, 49, 79, 6, 1, 3, 2, 7, 26, 2, 35, 1, 10, 3, 2, 4, 1, 16, 1, 1, 2, 12, 1, 1, 2, 8, 5, 1, 2, 1, 1, 1, 3, 3, 1, 4, 1, 1, 1, 7, 3, 6, 8, 2, 1, 6, 7, 5, 4, 1, 1, 5, 13, 2, 2, 35, 11, 7, 1, 10, 19, 29, 1, 1, 1, 6, 2, 3, 1, 4, 20, 1, 1, 7, 2, 56, 1, 2, 16, 10, 32, 34, 1, 25, 2, 1, 1, 1, 1, 1, 4, 10, 2, 5, 1, 12, 3, 1, 46, 1, 1, 1, 7, 3, 3, 2, 1, 2, 30, 4, 6, 1, 10, 2, 2, 1, 3, 1, 3, 2, 1, 9, 13, 2, 2, 6, 5, 2, 1, 3, 4, 23, 14, 1, 6, 35, 3, 20, 1, 1, 11, 59, 1, 8, 10, 28, 7, 2, 7, 1, 48, 9, 15, 2, 5, 2, 8, 5, 3, 2, 5, 31, 1, 61, 3, 5, 2, 59, 7, 4, 1, 1, 9, 11, 1, 7, 17, 25, 3, 1, 1, 1, 22, 3, 10, 21, 1, 1, 11, 2, 1, 20, 1, 12, 1, 2, 1, 2, 1, 7, 3, 1, 3, 29, 5, 1, 4, 6, 1, 1, 95, 4, 1, 2, 29, 67, 20, 1, 5, 2, 2, 142, 2, 1, 2, 2, 3, 2, 4, 2, 19, 20, 3, 44, 23, 3, 6, 37, 24, 11, 1, 1, 5, 1, 9, 2, 1, 7, 1, 1, 11, 21, 2, 1, 16, 9, 6, 1, 3, 2, 12, 7, 18, 1, 1, 2, 3, 7, 9, 3, 17, 3, 1, 5, 8, 10, 2, 1, 5, 4, 28, 19, 1, 27, 7, 1, 4, 2, 3, 22, 1, 37, 2, 34, 21, 1, 10, 1, 3, 1, 1, 5, 5, 1, 1, 37, 6, 12, 1, 1, 9, 3, 1, 1, 1, 24, 1, 3, 1, 3, 10, 14, 1, 8, 10, 37, 20, 5, 6, 3, 3, 1, 18, 1, 1, 2, 1, 1, 1, 5, 1, 11, 5, 15, 1, 1, 8, 1, 1, 13, 8, 6, 1, 9, 1, 9, 4, 3, 39, 1, 2, 4, 1, 82, 3, 2, 11, 1, 1, 52, 2, 3, 1, 1, 2, 5, 5, 15, 30, 3, 31, 8, 6, 2, 5, 57, 29, 4, 4, 30, 11, 1, 9, 8, 7, 6, 21, 1, 6, 1, 1, 1, 14, 2, 1, 7, 52, 6, 8, 1, 1, 10, 21, 14, 68, 1, 7, 1, 7, 4, 6, 9, 4, 1, 30, 16, 5, 11, 6, 58, 1, 23, 51, 3, 1, 10, 2, 8, 1, 2, 1, 1, 12, 1, 8, 1, 5, 2, 1, 12, 1, 8, 14, 3, 1, 1, 1, 2, 6, 1, 8, 1, 2, 18, 1, 6, 1, 5, 1, 17, 1, 1, 3, 5, 77, 17, 68, 12, 4, 2, 3, 21, 2, 11, 12, 10, 1, 1, 2, 1, 1, 7, 1, 1, 31, 1, 1, 1, 20, 5, 1, 7, 1, 15, 8, 3, 9, 4, 21, 4, 3, 1, 29, 2, 2, 1, 1, 8, 2, 10, 3, 10, 6, 4, 5, 1, 1, 1, 3, 25, 2, 5, 1, 1, 2, 1, 2, 3, 5, 2, 22, 1, 2, 70, 2, 1, 49, 4, 1, 24, 1, 4, 1, 14, 4, 5, 8, 1, 2, 31, 2, 1, 17, 7, 1, 8, 1, 10, 1, 2, 9, 2, 1, 4, 2, 2, 2, 2, 2, 1, 15, 5, 9, 11, 1, 11, 2, 3, 1, 7, 1, 8, 11, 1, 7, 114, 2, 1, 3, 1, 6, 3, 1, 1, 12, 5, 1, 11, 3, 12, 3, 1, 1, 34, 3, 5, 1, 1, 3, 7, 2, 8, 6, 1, 1, 1, 6, 2, 12, 22, 4, 1, 28, 1, 11, 145, 27, 1, 3, 39, 12, 6, 1, 17, 10, 1, 5, 6, 3, 1, 2, 2, 7, 28, 1, 11, 1, 20, 1, 28, 1, 10, 36, 24, 2, 6, 23, 2, 2, 9, 6, 1, 1, 6, 7, 9, 22, 1, 6, 35, 1, 2, 1, 80, 1, 6, 11, 1, 9, 1, 5, 85, 10, 3, 7, 1, 2, 2, 1, 7, 4, 1, 3, 1, 1, 17, 3, 7, 1, 12, 1, 2, 6, 2, 4, 3, 1, 1, 3, 1, 3, 3, 1, 10, 2, 1, 4, 3, 1, 2, 1, 3, 1, 1, 1, 5, 1, 8, 10, 2, 8, 8, 5, 16, 5, 1, 20, 6, 4, 8, 14, 23, 21, 1, 26, 9, 8, 2, 3, 8, 2, 13, 37, 5, 16, 2, 1, 7, 9, 1, 1, 4, 3, 1, 6, 1, 9, 1, 1, 2, 6, 10, 4, 1, 13, 4, 5, 15, 1, 1, 16, 1, 6, 5, 15, 1, 1, 3, 1, 1, 2, 140, 33, 1, 6, 4, 3, 2, 8, 1, 2, 3, 14, 1, 1, 1, 1, 8, 14, 13, 8, 39, 5, 1, 5, 1, 37, 4, 6, 4, 1, 10, 4, 40, 1, 10, 5, 1, 1, 19, 2, 1, 11, 1, 14, 1, 2, 2, 1, 11, 1, 14, 1, 7, 9, 6, 9, 3, 47, 4, 1, 2, 4, 4, 4, 5, 5, 47, 2, 17, 2, 7, 1, 2, 1, 4, 3, 4, 7, 8, 8, 3, 6, 2, 1, 27, 1, 12, 1, 78, 1, 12, 2, 2, 1, 2, 3, 6, 2, 6, 1, 9, 18, 39, 3, 1, 2, 10, 17, 11, 3, 1, 22, 1, 5, 2, 3, 2, 3, 13, 12, 4, 2, 2, 1, 2, 10, 4, 20, 10, 5, 19, 12, 2, 4, 73, 10, 2, 6, 18, 1, 2, 2, 1, 1, 26, 1, 3, 8, 1, 3, 3, 1, 1, 1, 2, 3, 3, 1, 9, 10, 4, 3, 4, 1, 1, 2, 1, 6, 2, 6, 8, 4, 2, 4, 5, 12, 2, 9, 2, 3, 8, 1, 7, 12, 2, 1, 3, 15, 22, 6, 13, 1, 1, 1, 1, 2, 1, 2, 3, 7, 1, 3, 17, 147, 1, 1, 13, 2, 6, 4, 11, 13, 3, 1, 12, 22, 23, 12, 2, 9, 26, 1, 1, 3, 5, 31, 23, 1, 6, 11, 1, 1, 2, 3, 9, 1, 1, 30, 4, 98, 2, 8, 4, 1, 7, 1, 1, 1, 2, 2, 7, 5, 1, 1, 2, 30, 4, 4, 5, 1, 2, 4, 62, 19, 22, 2, 3, 9, 2, 2, 8, 1, 2, 23, 1, 2, 1, 1, 13, 5, 10, 15, 2, 32, 4, 3, 2, 9, 6, 5, 12, 1, 1, 18, 2, 6, 3, 6, 8, 5, 5, 13, 15, 7, 1, 2, 18, 1, 2, 7, 8, 1, 1, 20, 5, 4, 3, 2, 42, 5, 2, 12, 53, 11, 3, 1, 6, 7, 45, 1, 1, 6, 57, 3, 1, 4, 1, 6, 1, 2, 1, 31, 3, 3, 12, 18, 1, 6, 1, 4, 38, 26, 9, 14, 1, 3, 6, 7, 2, 8, 1, 1, 1, 30, 20, 3, 2, 2, 4, 14, 2, 22, 5, 4, 4, 39, 1, 1, 15, 67, 1, 12, 13, 29, 3, 5, 2, 1, 2, 1, 3, 1, 8, 6, 6, 24, 7, 2, 136, 48, 28, 7, 5, 11, 7, 1, 19, 6, 1, 2, 1, 1, 11, 3, 30, 24, 3, 2, 7, 20, 5, 2, 10, 23, 1, 74, 2, 1, 4, 2, 1, 4, 1, 3, 4, 13, 2, 3, 2, 2, 1, 11, 3, 6, 2, 4, 1, 3, 7, 7, 2, 2, 1, 11, 1, 14, 1, 1, 1, 1, 68, 5, 2, 57, 4, 2, 22, 1, 1, 7, 3, 4, 12, 1, 5, 3, 1, 1, 1, 53, 1, 1, 2, 5, 5, 1, 1, 2, 2, 3, 14, 1, 18, 5, 11, 10, 4, 1, 15, 1, 2, 1, 1, 1, 2, 6, 41, 1, 5, 5, 1, 7, 50, 2, 8, 1, 6, 4, 1, 2, 26, 101, 34, 1, 5, 6, 2, 4, 2, 1, 5, 47, 1, 13, 6, 6, 1, 10, 23, 1, 5, 2, 6, 2, 6, 1, 2, 2, 6, 2, 1, 14, 33, 4, 16, 4, 2, 6, 6, 2, 16, 12, 21, 3, 4, 7, 1, 20, 1, 13, 1, 7, 1, 23, 17, 46, 2, 3, 1, 1, 12, 8, 38, 21, 48, 1, 43, 2, 5, 2, 28, 5, 1, 1, 1, 1, 2, 28, 3, 53, 1, 11, 2, 1, 25, 1, 2, 17, 5, 1, 2, 25, 1, 3, 1, 8, 28, 1, 1, 2, 38, 8, 6, 1, 1, 2, 6, 12, 1, 1, 1, 1, 5, 7, 10, 52, 1, 1, 9, 2, 1, 5, 12, 21, 2, 1, 47, 2, 1, 17, 3, 7, 2, 1, 12, 3, 7, 5, 6, 1, 1, 1, 1, 4, 2, 5, 11, 2, 1, 7, 36, 2, 1, 9, 2, 3, 1, 1, 4, 7, 3, 10, 9, 5, 2, 11, 1, 1, 4, 26, 1, 2, 1, 94, 3, 1, 4, 6, 3, 1, 15, 4, 25, 4, 8, 1, 1, 5, 3, 1, 2, 2, 33, 7, 8, 25, 2, 3, 8, 2, 7, 1, 11, 14, 1, 1, 1, 18, 2, 4, 9, 2, 1, 10, 2, 6, 11, 28, 7, 9, 1, 13, 20, 3, 1, 2, 2, 3, 1, 1, 1, 3, 2, 14, 2, 1, 10, 3, 1, 13, 30, 1, 43, 8, 1, 8, 3, 4, 13, 17, 6, 1, 8, 3, 7, 8, 2, 2, 6, 1, 1, 6, 3, 5, 8, 10, 1, 6, 6, 2, 1, 3, 10, 1, 13, 16, 1, 42, 5, 13, 1, 2, 42, 15, 36, 11, 1, 158, 1, 12, 5, 2, 2, 11, 4, 6, 25, 4, 1, 4, 12, 3, 1, 5, 1, 44, 1, 12, 5, 2, 4, 5, 19, 19, 9, 2, 2, 4, 3, 3, 1, 3, 4, 1, 1, 5, 1, 1, 2, 13, 1, 15, 1, 1, 1, 2, 27, 1, 13, 18, 6, 3, 35, 21, 1, 1, 5, 2, 5, 1, 82, 1, 18, 5, 2, 29, 4, 4, 1, 28, 1, 2, 35, 8, 2, 6, 1, 2, 38, 1, 7, 1, 1, 5, 1, 1, 1, 9, 2, 13, 7, 3, 33, 116, 1, 7, 1, 1, 1, 1, 3, 3, 13, 4, 8, 20, 10, 30, 5, 1, 1, 1, 15, 3, 3, 2, 4, 1, 3, 1, 1, 4, 13, 3, 4, 1, 1, 2, 3, 1, 14, 7, 9, 38, 1, 2, 4, 32, 10, 13], \"opacity\": 0.75, \"name\": \"Articles per User\", \"xbins\": {\"start\": 0, \"end\": 300, \"size\": 5}, \"marker\": {\"color\": \"darkblue\"}, \"xaxis\": \"x2\", \"yaxis\": \"y2\"}], {\"xaxis1\": {\"domain\": [0.0, 0.45], \"anchor\": \"y1\", \"title\": \"No of Times an Article is Viewed\", \"titlefont\": {\"size\": 10}}, \"yaxis1\": {\"domain\": [0.0, 1.0], \"anchor\": \"x1\", \"title\": \"Frequency\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"gridwidth\": null}, \"xaxis2\": {\"domain\": [0.55, 1.0], \"anchor\": \"y2\", \"title\": \"No of Articles a User Views\", \"titlefont\": {\"size\": 10}}, \"yaxis2\": {\"domain\": [0.0, 1.0], \"anchor\": \"x2\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"gridwidth\": null}, \"height\": 500, \"width\": 900, \"title\": \"User x Article Interactions\", \"titlefont\": {\"size\": 13}, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"bargap\": 0.1, \"legend\": {\"x\": 0.8, \"y\": 0.8, \"xanchor\": \"center\", \"yanchor\": \"middle\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Define the threshold for the trailing bin\n",
    "threshold = 300 \n",
    "\n",
    "# Adjust the data for the trailing bin\n",
    "\n",
    "x1 = article_read['readers'].apply(lambda x: threshold if x >= threshold else x)\n",
    "\n",
    "trace1 =go.Histogram(\n",
    "    x=x1, \n",
    "    opacity=0.75,\n",
    "    name='Views per Article',\n",
    "    xbins=dict( # bins used for histogram\n",
    "        start=0,\n",
    "        end=threshold,\n",
    "        size=5 ),\n",
    "    marker= dict(color='red')\n",
    ")\n",
    "\n",
    "\n",
    "# Adjust the data for the trailing bin\n",
    "x2 = user_read['articles'].apply(lambda x: threshold if x >= threshold else x)\n",
    "\n",
    "trace2 =go.Histogram(\n",
    "    x=x2,\n",
    "    opacity=0.75,\n",
    "    name='Articles per User',\n",
    "    xbins=dict( # bins used for histogram\n",
    "        start=0,\n",
    "        end=threshold,\n",
    "        size=5 ),\n",
    "    marker= dict(color='darkblue')\n",
    ")\n",
    "\n",
    "fig = tools.make_subplots(rows=1, cols=2)\n",
    "fig.append_trace(trace1, 1,1)\n",
    "fig.append_trace(trace2, 1,2)\n",
    "fig['layout'].update(\n",
    "    height = 500, \n",
    "    width = 900, \n",
    "    title ='User x Article Interactions',\n",
    "    titlefont = dict(size=13),\n",
    "    margin=dict(l=50, r=30, t=40, b=50),    \n",
    "    bargap=0.1,\n",
    "    yaxis1 = {\n",
    "        'title': 'Frequency',\n",
    "        'titlefont': dict(size=12),\n",
    "        'tickfont' : dict(size=10),\n",
    "        'gridwidth': None\n",
    "        },\n",
    "    xaxis1 = {\n",
    "        'title': 'No of Times an Article is Viewed', \n",
    "        'titlefont': dict(size=10)\n",
    "        },        \n",
    "    yaxis2 = {\n",
    "        #'title': 'Frequency',\n",
    "        'titlefont': dict(size=12),\n",
    "        'tickfont' : dict(size=10),\n",
    "        'gridwidth': None        \n",
    "        },\n",
    "    xaxis2 = {\n",
    "        'title': 'No of Articles a User Views', \n",
    "        'titlefont': dict(size=10)\n",
    "        },\n",
    "    legend=dict(\n",
    "        x=0.8,  # Horizontally center the legend\n",
    "        y=0.8,  # Adjust vertical position as needed\n",
    "        xanchor='center',  # Ensure that x=0.5 is the center of the legend\n",
    "        yanchor='middle'   # Ensure that y=0.5 is the middle of the legend\n",
    "    )              \n",
    "    )\n",
    "\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% of individuals interact with 3.0 number of articles or fewer\n",
      "The maximum number of user-article interactions by any 1 user is 364\n"
     ]
    }
   ],
   "source": [
    "# Fill in the median and maximum number of user_article interactios below\n",
    "\n",
    "# 50% of individuals interact with ____ number of articles or fewer.\n",
    "median_val = user_read['articles'].median()\n",
    "print(f'50% of individuals interact with {median_val} number of articles or fewer')\n",
    "\n",
    "# The maximum number of user-article interactions by any 1 user is _____\n",
    "max_views_by_user =  user_read['articles'].max()\n",
    "print(f'The maximum number of user-article interactions by any 1 user is {max_views_by_user}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Explore and remove duplicate articles from the **df_content** dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate records in df_content\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Follow Sign in / Sign up Home About Insight Data Science Data Engineering Health Data AI Never miss a story from Insight Data , when you sign up for Medium. Learn more Never miss a story from Insi...</td>\n",
       "      <td>Community Detection at Scale</td>\n",
       "      <td>Graph-based machine learning</td>\n",
       "      <td>Live</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Follow Sign in / Sign up Home About Insight Data Science Data Engineering Health Data AI 5 * Share\\r\\n * 5\\r\\n * \\r\\n * \\r\\n\\r\\nNever miss a story from Insight Data , when you sign up for Medium. ...</td>\n",
       "      <td>During the seven-week Insight Data Engineering Fellows Program recent grads and experienced software engineers learn the latest open source technologies by building a data platform to handle large…</td>\n",
       "      <td>Graph-based machine learning</td>\n",
       "      <td>Live</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>* United States\\r\\n\\r\\nIBM® * Site map\\r\\n\\r\\nSearch within Bluemix Blog Bluemix Blog * About Bluemix * What is Bluemix\\r\\n    * Getting Started\\r\\n    * Case Studies\\r\\n    * Hybrid Architecture\\...</td>\n",
       "      <td>When used to make sense of huge amounts of constantly changing data, smart catalog capabilities can make all the difference.</td>\n",
       "      <td>How smart catalogs can turn the big data flood into an ocean of opportunity</td>\n",
       "      <td>Live</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Homepage Follow Sign in / Sign up Homepage * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nSusanna Tai Blocked Unblock Follow Following Offe...</td>\n",
       "      <td>One of the earliest documented catalogs was compiled at the great library of Alexandria in the third century BC, to help scholars manage, understand and access its vast collection of literature…</td>\n",
       "      <td>How smart catalogs can turn the big data flood into an ocean of opportunity</td>\n",
       "      <td>Live</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Homepage Follow Sign in Get started Homepage * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * IBM Data Refinery\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nCarmen Ruppach Blocked ...</td>\n",
       "      <td>If you are like most data scientists, you are probably spending a lot of time to cleanse, shape and prepare your data before you can actually start with the more enjoyable part of building and…</td>\n",
       "      <td>Self-service data preparation with IBM Data Refinery</td>\n",
       "      <td>Live</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Homepage Follow Sign in Get started * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * IBM Data Refinery\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nCarmen Ruppach Blocked Unblock F...</td>\n",
       "      <td>If you are like most data scientists, you are probably spending a lot of time to cleanse, shape and prepare your data before you can actually start with the more enjoyable part of building and…</td>\n",
       "      <td>Self-service data preparation with IBM Data Refinery</td>\n",
       "      <td>Live</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Homepage Follow Sign in Get started * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * IBM Data Refinery\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nSourav Mazumder Blocked Unblock ...</td>\n",
       "      <td>Today’s world of data science leverages data from various sources. Commonly, these sources are Hadoop File System, Enterprise Data Warehouse, Relational Database systems, Enterprise file systems, ...</td>\n",
       "      <td>Using Apache Spark as a parallel processing framework for accessing REST based data services</td>\n",
       "      <td>Live</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Homepage Follow Sign in Get started Homepage * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * IBM Data Refinery\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nSourav Mazumder Blocked...</td>\n",
       "      <td>Today’s world of data science leverages data from various sources. Commonly, these sources are Hadoop File System, Enterprise Data Warehouse, Relational Database systems, Enterprise file systems, ...</td>\n",
       "      <td>Using Apache Spark as a parallel processing framework for accessing REST based data services</td>\n",
       "      <td>Live</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>This video shows you how to construct queries to access the primary index through the API.Visit http://www.cloudant.com/sign-up to sign up for a free Cloudant account. Find more videos and tutoria...</td>\n",
       "      <td>This video shows you how to construct queries to access the primary index through Cloudant's API.</td>\n",
       "      <td>Use the Primary Index</td>\n",
       "      <td>Live</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>This video shows you how to construct queries to access the primary index through the API.Visit http://www.cloudant.com/sign-up to sign up for a free Cloudant account.</td>\n",
       "      <td>This video shows you how to construct queries to access the primary index through the API</td>\n",
       "      <td>Use the Primary Index</td>\n",
       "      <td>Live</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    doc_body  \\\n",
       "50   Follow Sign in / Sign up Home About Insight Data Science Data Engineering Health Data AI Never miss a story from Insight Data , when you sign up for Medium. Learn more Never miss a story from Insi...   \n",
       "365  Follow Sign in / Sign up Home About Insight Data Science Data Engineering Health Data AI 5 * Share\\r\\n * 5\\r\\n * \\r\\n * \\r\\n\\r\\nNever miss a story from Insight Data , when you sign up for Medium. ...   \n",
       "221  * United States\\r\\n\\r\\nIBM® * Site map\\r\\n\\r\\nSearch within Bluemix Blog Bluemix Blog * About Bluemix * What is Bluemix\\r\\n    * Getting Started\\r\\n    * Case Studies\\r\\n    * Hybrid Architecture\\...   \n",
       "692  Homepage Follow Sign in / Sign up Homepage * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nSusanna Tai Blocked Unblock Follow Following Offe...   \n",
       "232  Homepage Follow Sign in Get started Homepage * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * IBM Data Refinery\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nCarmen Ruppach Blocked ...   \n",
       "971  Homepage Follow Sign in Get started * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * IBM Data Refinery\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nCarmen Ruppach Blocked Unblock F...   \n",
       "399  Homepage Follow Sign in Get started * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * IBM Data Refinery\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nSourav Mazumder Blocked Unblock ...   \n",
       "761  Homepage Follow Sign in Get started Homepage * Home\\r\\n * Data Science Experience\\r\\n * Data Catalog\\r\\n * IBM Data Refinery\\r\\n * \\r\\n * Watson Data Platform\\r\\n * \\r\\n\\r\\nSourav Mazumder Blocked...   \n",
       "578  This video shows you how to construct queries to access the primary index through the API.Visit http://www.cloudant.com/sign-up to sign up for a free Cloudant account. Find more videos and tutoria...   \n",
       "970                                  This video shows you how to construct queries to access the primary index through the API.Visit http://www.cloudant.com/sign-up to sign up for a free Cloudant account.   \n",
       "\n",
       "                                                                                                                                                                                             doc_description  \\\n",
       "50                                                                                                                                                                              Community Detection at Scale   \n",
       "365    During the seven-week Insight Data Engineering Fellows Program recent grads and experienced software engineers learn the latest open source technologies by building a data platform to handle large…   \n",
       "221                                                                             When used to make sense of huge amounts of constantly changing data, smart catalog capabilities can make all the difference.   \n",
       "692       One of the earliest documented catalogs was compiled at the great library of Alexandria in the third century BC, to help scholars manage, understand and access its vast collection of literature…   \n",
       "232        If you are like most data scientists, you are probably spending a lot of time to cleanse, shape and prepare your data before you can actually start with the more enjoyable part of building and…   \n",
       "971        If you are like most data scientists, you are probably spending a lot of time to cleanse, shape and prepare your data before you can actually start with the more enjoyable part of building and…   \n",
       "399  Today’s world of data science leverages data from various sources. Commonly, these sources are Hadoop File System, Enterprise Data Warehouse, Relational Database systems, Enterprise file systems, ...   \n",
       "761  Today’s world of data science leverages data from various sources. Commonly, these sources are Hadoop File System, Enterprise Data Warehouse, Relational Database systems, Enterprise file systems, ...   \n",
       "578                                                                                                        This video shows you how to construct queries to access the primary index through Cloudant's API.   \n",
       "970                                                                                                                This video shows you how to construct queries to access the primary index through the API   \n",
       "\n",
       "                                                                                    doc_full_name  \\\n",
       "50                                                                   Graph-based machine learning   \n",
       "365                                                                  Graph-based machine learning   \n",
       "221                   How smart catalogs can turn the big data flood into an ocean of opportunity   \n",
       "692                   How smart catalogs can turn the big data flood into an ocean of opportunity   \n",
       "232                                          Self-service data preparation with IBM Data Refinery   \n",
       "971                                          Self-service data preparation with IBM Data Refinery   \n",
       "399  Using Apache Spark as a parallel processing framework for accessing REST based data services   \n",
       "761  Using Apache Spark as a parallel processing framework for accessing REST based data services   \n",
       "578                                                                         Use the Primary Index   \n",
       "970                                                                         Use the Primary Index   \n",
       "\n",
       "    doc_status  article_id  \n",
       "50        Live          50  \n",
       "365       Live          50  \n",
       "221       Live         221  \n",
       "692       Live         221  \n",
       "232       Live         232  \n",
       "971       Live         232  \n",
       "399       Live         398  \n",
       "761       Live         398  \n",
       "578       Live         577  \n",
       "970       Live         577  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and explore duplicate articles\n",
    "\n",
    "print('Duplicate records in df_content')\n",
    "df_content.loc[df_content['article_id'].duplicated(keep=False)].sort_values(by=['article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size: (1056, 5)\n",
      "Size after deduped: (1051, 5)\n"
     ]
    }
   ],
   "source": [
    "# Remove any rows that have the same article_id - only keep the first\n",
    "\n",
    "print('Original Size:', df_content.shape)\n",
    "df_content = df_content.drop_duplicates(subset='article_id', keep='first')\n",
    "print('Size after deduped:', df_content.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use the cells below to find:\n",
    "\n",
    "**a.** The number of unique articles that have an interaction with a user.  \n",
    "**b.** The number of unique articles in the dataset (whether they have any interactions or not).<br>\n",
    "**c.** The number of unique users in the dataset. (excluding null values) <br>\n",
    "**d.** The number of user-article interactions in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique articles that have at least one interaction: 714\n",
      "The number of unique articles listed on the community file: 1051\n",
      "The number of unique users: 5148\n",
      "The number of user-article interactions: 45993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_articles = df['article_id'].nunique()\n",
    "print('The number of unique articles that have at least one interaction:', unique_articles)\n",
    "\n",
    "total_articles =  df_content['article_id'].nunique()\n",
    "print('The number of unique articles listed on the community file:', total_articles)\n",
    "\n",
    "unique_users = df['email'].nunique()\n",
    "print('The number of unique users:', unique_users)\n",
    "\n",
    "user_article_interactions =  df.shape[0] \n",
    "print('The number of user-article interactions:', user_article_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use the cells below to find the most viewed **article_id**, as well as how often it was viewed.  After talking to the company leaders, the `email_mapper` function was deemed a reasonable way to map users to ids.  There were a small number of null values, and it was found that all of these null values likely belonged to a single user (which is how they are stored using the function below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of article with most views: 699\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# index of article id with most read/viewed by users\n",
    "max_index = article_read['readers'].idxmax()\n",
    "print('Index of article with most views:', max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most viewed article 1429.0, Maximum view 937\n"
     ]
    }
   ],
   "source": [
    "# The most viewed article in the dataset as a string with one value following the decimal \n",
    "most_viewed_article_id = str(article_read.loc[max_index, 'article_id'])\n",
    "\n",
    "# The most viewed article in the dataset was viewed how many times?\n",
    "max_views = article_read.loc[max_index, 'readers']\n",
    "\n",
    "print(f'Most viewed article {most_viewed_article_id}, Maximum view {max_views}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier data analysis and experimentation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  \\\n",
       "0      1430.0   \n",
       "1      1314.0   \n",
       "2      1429.0   \n",
       "3      1338.0   \n",
       "4      1276.0   \n",
       "\n",
       "                                                                              title  \\\n",
       "0  using pixiedust for fast, flexible, and easier data analysis and experimentation   \n",
       "1                                      healthcare python streaming application demo   \n",
       "2                                        use deep learning for image classification   \n",
       "3                                         ml optimization using cognitive assistant   \n",
       "4                                         deploy your python model as a restful api   \n",
       "\n",
       "   user_id  \n",
       "0        1  \n",
       "1        2  \n",
       "2        3  \n",
       "3        4  \n",
       "4        5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you have everything right here! Nice job!\n"
     ]
    }
   ],
   "source": [
    "## If you stored all your results in the variable names above, \n",
    "## you shouldn't need to change anything in this cell\n",
    "\n",
    "sol_1_dict = {\n",
    "    '`50% of individuals have _____ or fewer interactions.`': median_val,\n",
    "    '`The total number of user-article interactions in the dataset is ______.`': user_article_interactions,\n",
    "    '`The maximum number of user-article interactions by any 1 user is ______.`': max_views_by_user,\n",
    "    '`The most viewed article in the dataset was viewed _____ times.`': max_views,\n",
    "    '`The article_id of the most viewed article is ______.`': most_viewed_article_id,\n",
    "    '`The number of unique articles that have at least 1 rating ______.`': unique_articles,\n",
    "    '`The number of unique users in the dataset is ______`': unique_users,\n",
    "    '`The number of unique articles on the IBM platform`': total_articles\n",
    "}\n",
    "\n",
    "# Test your dictionary against the solution\n",
    "t.sol_1_test(sol_1_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Rank\">Part II: Rank-Based Recommendations</a>\n",
    "\n",
    "Unlike in the earlier lessons, we don't actually have ratings for whether a user liked an article or not.  We only know that a user has interacted with an article.  In these cases, the popularity of an article can really only be based on how often an article was interacted with.\n",
    "\n",
    "`1.` Fill in the function below to return the **n** top articles ordered with most interactions as the top. Test your function using the tests below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_top_articles(n, df=df):\n",
    "    \n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Find top article_ids (this avoids grouping articles with identical titles)\n",
    "    articles_cnt = list(df.groupby('article_id')['user_id'].count().sort_values(ascending=False).index)\n",
    "    top_id = articles_cnt[:n]\n",
    "    \n",
    "    # Find titles of those articles\n",
    "    top_articles = df.loc[df.article_id.isin(top_id),['article_id','title']].drop_duplicates()\n",
    "    top_articles = list(top_articles.title)\n",
    "        \n",
    "    return top_articles # Return the top article titles from df (not df_content)\n",
    "\n",
    "def get_top_article_ids(n, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    n - (int) the number of top articles to return\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    \n",
    "    OUTPUT:\n",
    "    top_articles - (list) A list of the top 'n' article titles \n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Find top article_ids (this avoids grouping articles with identical titles)\n",
    "    articles_cnt = list(df.groupby('article_id')['user_id'].count().sort_values(ascending=False).index)\n",
    "    top_articles_id = articles_cnt[:n]\n",
    " \n",
    "    return list(map(str, top_articles_id)) # Return the top article ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular Articles\n",
      "------------------------------------------------------\n",
      "1429.0 Use Deep Learning For Image Classification\n",
      "1330.0 Predicting Churn With The Spss Random Tree Algorithm\n",
      "1431.0 Visualize Car Data With Brunel\n",
      "1427.0 Use Xgboost, Scikit-Learn & Ibm Watson Machine Learning Apis\n",
      "1364.0 Insights From New York Car Accident Reports\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Top Article IDs, Articles \n",
    "print('Popular Articles')\n",
    "print('------------------------------------------------------')\n",
    "for id, title in zip(get_top_article_ids(5), get_top_articles(5)):\n",
    "    print(id, title.title())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your top_5 looks like the solution list! Nice job.\n",
      "Your top_10 looks like the solution list! Nice job.\n",
      "Your top_20 looks like the solution list! Nice job.\n"
     ]
    }
   ],
   "source": [
    "# Test your function by returning the top 5, 10, and 20 articles\n",
    "top_5 = get_top_articles(5)\n",
    "top_10 = get_top_articles(10)\n",
    "top_20 = get_top_articles(20)\n",
    "\n",
    "# Test each of your three lists from above\n",
    "t.sol_2_test(get_top_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"User-User\">Part III: User-User Based Collaborative Filtering</a>\n",
    "\n",
    "\n",
    "`1.` Use the function below to reformat the **df** dataframe to be shaped with users as the rows and articles as the columns.  \n",
    "\n",
    "* Each **user** should only appear in each **row** once.\n",
    "\n",
    "\n",
    "* Each **article** should only show up in one **column**.  \n",
    "\n",
    "\n",
    "* **If a user has interacted with an article, then place a 1 where the user-row meets for that article-column**.  It does not matter how many times a user has interacted with the article, all entries where a user has interacted with an article should be a 1.  \n",
    "\n",
    "\n",
    "* **If a user has not interacted with an item, then place a zero where the user-row meets for that article-column**. \n",
    "\n",
    "Use the tests to make sure the basic structure of your matrix matches what is expected by the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the user-article matrix with 1's and 0's\n",
    "\n",
    "def create_user_item_matrix(df):\n",
    "    \n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with article_id, title, user_id columns\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item - user item matrix \n",
    "    \n",
    "    Description:\n",
    "    Return a matrix with user ids as rows and article ids on the columns with 1 values where a user interacted with \n",
    "    an article and a 0 otherwise\n",
    "    '''\n",
    "    \n",
    "    user_item = df.groupby(['user_id','article_id'])['user_id'].nunique().unstack()\n",
    "    user_item.fillna(0, inplace=True)\n",
    "    \n",
    "    return user_item # return the user_item matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Item matrix: (5149, 714)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_item = create_user_item_matrix(df)\n",
    "print('User Item matrix:', user_item.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have passed our quick tests!  Please proceed!\n"
     ]
    }
   ],
   "source": [
    "## Tests: You should just need to run this cell.  Don't change the code.\n",
    "assert user_item.shape[0] == 5149, \"Oops!  The number of users in the user-article matrix doesn't look right.\"\n",
    "assert user_item.shape[1] == 714, \"Oops!  The number of articles in the user-article matrix doesn't look right.\"\n",
    "assert user_item.sum(axis=1)[1] == 36, \"Oops!  The number of articles seen by user 1 doesn't look right.\"\n",
    "print(\"You have passed our quick tests!  Please proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Complete the function below which should take a user_id and provide an ordered list of the most similar users to that user (from most similar to least similar).  The returned result should not contain the provided user_id, as we know that each user is similar to him/herself. Because the results for each user here are binary, it (perhaps) makes sense to compute similarity as the dot product of two users. \n",
    "\n",
    "Use the tests to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_similar_users(user_id, user_item=user_item, return_similarity=False):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user_id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    similar_users - (list) an ordered list where the closest users (largest dot product users)\n",
    "                    are listed first\n",
    "    \n",
    "    Description:\n",
    "    Computes the similarity of every pair of users based on the dot product\n",
    "    Returns an ordered\n",
    "    \n",
    "    '''\n",
    "    # compute similarity of each user to the provided user\n",
    "    user_similarity = np.dot(user_item.loc[user_id], user_item.T)\n",
    "\n",
    "    # Sort similarities in descending order and get the corresponding user IDs\n",
    "    # Exclude the similarity with itself \n",
    "    sorted_ids = np.argsort(user_similarity)[::-1]   \n",
    "    most_similar_users = list(user_item.index[sorted_ids][1:])\n",
    "    sorted_similarity = list(user_similarity[sorted_ids][1:])\n",
    "\n",
    "    if return_similarity:\n",
    "        # return a list of the users in order from most to least similar\n",
    "        return most_similar_users, sorted_similarity \n",
    "    else:\n",
    "        return most_similar_users\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most similar users to user 1 are: [3933, 23, 3782, 203, 4459, 131, 3870, 46, 4201, 5041]\n",
      "The 5 most similar users to user 3933 are: [3933, 23, 3782, 4459, 203]\n",
      "The 3 most similar users to user 46 are: [46, 23, 3782]\n"
     ]
    }
   ],
   "source": [
    "# Do a spot check of your function\n",
    "print(\"The 10 most similar users to user 1 are: {}\".format(find_similar_users(1)[:10]))\n",
    "print(\"The 5 most similar users to user 3933 are: {}\".format(find_similar_users(3933)[:5]))\n",
    "print(\"The 3 most similar users to user 46 are: {}\".format(find_similar_users(46)[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now that you have a function that provides the most similar users to each user, you will want to use these users to find articles you can recommend.  Complete the functions below to return the articles you would recommend to each user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_article_names(article_ids, df=df):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    \n",
    "    article_names= list(df[df['article_id'].isin(article_ids)]['title'].unique())\n",
    "    \n",
    "    return article_names # Return the article names associated with list of article ids\n",
    "\n",
    "\n",
    "def get_user_articles(user_id, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "                1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_ids - (list) a list of the article ids seen by the user\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the doc_full_name column in df_content)\n",
    "    \n",
    "    Description:\n",
    "    Provides a list of the article_ids and article titles that have been seen by a user\n",
    "    '''\n",
    "    \n",
    "    # Fetching article ids where the user interaction is 1 (has interacted)\n",
    "    article_ids = user_item.loc[user_id, user_item.loc[user_id] == 1].index.tolist()\n",
    "    article_names = get_article_names(article_ids)\n",
    "\n",
    "    return list(map(str, article_ids)), article_names\n",
    "\n",
    "\n",
    "def user_user_recs(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    Users who are the same closeness are chosen arbitrarily as the 'next' user\n",
    "    \n",
    "    For the user where the number of recommended articles starts below m \n",
    "    and ends exceeding m, the last items are chosen arbitrarily\n",
    "    \n",
    "    ''' \n",
    "\n",
    "    similar_users = find_similar_users(user_id, user_item)\n",
    "    articles_seen_ids = set(get_user_articles(user_id, user_item)[0])\n",
    "\n",
    "    rec_ids = set()\n",
    "\n",
    "    for user in similar_users:\n",
    "        articles_rec_ids, _ = get_user_articles(user, user_item)\n",
    "        new_recs = set(articles_rec_ids) - articles_seen_ids\n",
    "        rec_ids.update(new_recs)\n",
    "\n",
    "        if len(rec_ids) > m:\n",
    "            break\n",
    "\n",
    "    rec_names = get_article_names(list(rec_ids)[:m], df)\n",
    "\n",
    "    return rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 20 Viewed Articles\n",
      "------------------------------------------------------\n",
      "Housing (2015): United States Demographic Measures\n",
      "Use The Cloudant-Spark Connector In Python Notebook\n",
      "Self-Service Data Preparation With Ibm Data Refinery\n",
      "\n",
      "The top 10 recommendations for User 20\n",
      "------------------------------------------------------\n",
      "Use Deep Learning For Image Classification\n",
      "Analyze Energy Consumption In Buildings\n",
      "Model Bike Sharing Data With Spss\n",
      "Imitation Learning In Tensorflow (Hopper From Openai Gym)\n",
      "10 Tips On Using Jupyter Notebook\n",
      "Deep Learning From Scratch I: Computational Graphs\n",
      "What Is Machine Learning?\n",
      "Machine Learning For The Enterprise.\n",
      "Overlapping Co-Cluster Recommendation Algorithm (Ocular)\n",
      "Small Steps To Tensorflow\n"
     ]
    }
   ],
   "source": [
    "# Quick Spot Check\n",
    "\n",
    "print('User 20 Viewed Articles')\n",
    "print('------------------------------------------------------')\n",
    "_, user_articles = get_user_articles(20, user_item=user_item)    \n",
    "for title in user_articles:\n",
    "    print(title.title())\n",
    "print()\n",
    "\n",
    "print(\"The top 10 recommendations for User 20\")\n",
    "print('------------------------------------------------------')\n",
    "rec_names = user_user_recs(20, 10)\n",
    "for title in rec_names:\n",
    "    print(title.title())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you passed all of our tests!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Test your functions here - No need to change this code - just run this cell\n",
    "assert set(get_article_names(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_article_names(['1320.0', '232.0', '844.0'])) == set(['housing (2015): united states demographic measures','self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook']), \"Oops! Your the get_article_names function doesn't work quite how we expect.\"\n",
    "assert set(get_user_articles(20)[0]) == set(['1320.0', '232.0', '844.0'])\n",
    "assert set(get_user_articles(20)[1]) == set(['housing (2015): united states demographic measures', 'self-service data preparation with ibm data refinery','use the cloudant-spark connector in python notebook'])\n",
    "assert set(get_user_articles(2)[0]) == set(['1024.0', '1176.0', '1305.0', '1314.0', '1422.0', '1427.0'])\n",
    "assert set(get_user_articles(2)[1]) == set(['using deep learning to reconstruct high-resolution audio', 'build a python app on the streaming analytics service', 'gosales transactions for naive bayes model', 'healthcare python streaming application demo', 'use r dataframes & ibm watson natural language understanding', 'use xgboost, scikit-learn & ibm watson machine learning apis'])\n",
    "print(\"If this is all you see, you passed all of our tests!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Now we are going to improve the consistency of the **user_user_recs** function from above.  \n",
    "\n",
    "* Instead of arbitrarily choosing when we obtain users who are all the same closeness to a given user - choose the users that have the most total article interactions before choosing those with fewer article interactions.\n",
    "\n",
    "\n",
    "* Instead of arbitrarily choosing articles from the user where the number of recommended articles starts below m and ends exceeding m, choose articles with the articles with the most total interactions before choosing those with fewer total interactions. This ranking should be  what would be obtained from the **top_articles** function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_top_sorted_users(user_id, df=df, user_item=user_item):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int)\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook \n",
    "    user_item - (pandas dataframe) matrix of users by articles: \n",
    "            1's when a user has interacted with an article, 0 otherwise\n",
    "    \n",
    "            \n",
    "    OUTPUT:\n",
    "    neighbors_df - (pandas dataframe) a dataframe with:\n",
    "                    neighbor_id - is a neighbor user_id\n",
    "                    similarity - measure of the similarity of each user to the provided user_id\n",
    "                    num_interactions - the number of articles viewed by the user \n",
    "                    \n",
    "    Other Details - sort the neighbors_df by the similarity and then by number of interactions where \n",
    "                    highest of each is higher in the dataframe\n",
    "     \n",
    "    '''\n",
    "\n",
    "    # Find similar users and  similarity scores\n",
    "    neighbor_id, neighbor_similarity = find_similar_users(user_id,user_item,True)\n",
    "    \n",
    "    # Find number of interactions of each user (non-unique)\n",
    "    neighbor_id_count = df.groupby('user_id').size().reset_index(name='num_interactions').rename(columns={'user_id': 'neighbor_id'})\n",
    "\n",
    "    # Create DataFrame\n",
    "    neighbors_df = pd.DataFrame({'neighbor_id': neighbor_id, 'similarity': neighbor_similarity})\n",
    "    neighbors_df = neighbors_df.merge(neighbor_id_count, on='neighbor_id')\n",
    "\n",
    "    # Sorting by similarity and then by number of interactions\n",
    "    neighbors_df.sort_values(by=['similarity', 'num_interactions'], inplace=True, ascending=[False, False])\n",
    "    \n",
    "    return neighbors_df \n",
    "\n",
    "\n",
    "def user_user_recs_part2(user_id, m=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - (int) a user id\n",
    "    m - (int) the number of recommendations you want for the user\n",
    "    \n",
    "    OUTPUT:\n",
    "    recs - (list) a list of recommendations for the user by article id\n",
    "    rec_names - (list) a list of recommendations for the user by article title\n",
    "    \n",
    "    Description:\n",
    "    Loops through the users based on closeness to the input user_id\n",
    "    For each user - finds articles the user hasn't seen before and provides them as recs\n",
    "    Does this until m recommendations are found\n",
    "    \n",
    "    Notes:\n",
    "    * Choose the users that have the most total article interactions \n",
    "    before choosing those with fewer article interactions.\n",
    "\n",
    "    * Choose articles with the articles with the most total interactions \n",
    "    before choosing those with fewer total interactions. \n",
    "   \n",
    "    '''\n",
    "   \n",
    "    similar_users = get_top_sorted_users(user_id)\n",
    "    articles_seen_ids = set(get_user_articles(user_id, user_item)[0])\n",
    "\n",
    "    rec_ids = set()\n",
    "\n",
    "    for index, row in similar_users.iterrows():\n",
    "        articles_rec_ids, _ = get_user_articles(row['neighbor_id'], user_item)\n",
    "        new_recs = set(articles_rec_ids) - articles_seen_ids\n",
    "        rec_ids.update(new_recs)\n",
    "\n",
    "        if len(rec_ids) > m:\n",
    "            break\n",
    "\n",
    "    rec_names = get_article_names(list(rec_ids)[:m], df)\n",
    "    \n",
    "    return rec_ids, rec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 20 Viewed Articles\n",
      "------------------------------------------------------\n",
      "Housing (2015): United States Demographic Measures\n",
      "Use The Cloudant-Spark Connector In Python Notebook\n",
      "Self-Service Data Preparation With Ibm Data Refinery\n",
      "\n",
      "The top 10 recommendations for User 20\n",
      "------------------------------------------------------\n",
      "1357.0 Ml Optimization Using Cognitive Assistant\n",
      "681.0 Apache Spark Lab, Part 1: Basic Concepts\n",
      "1162.0 Analyze Energy Consumption In Buildings\n",
      "1386.0 Model Bike Sharing Data With Spss\n",
      "939.0 Deep Learning From Scratch I: Computational Graphs\n",
      "1278.0 Real-Time Sentiment Analysis Of Twitter Hashtags With Spark (+ Pixiedust)\n",
      "1170.0 Score A Predictive Model Built With Ibm Spss Modeler, Wml & Dsx\n",
      "686.0 Overlapping Co-Cluster Recommendation Algorithm (Ocular)\n",
      "1351.0 Develop A Scala Spark Model On Chicago Building Violations\n",
      "1338.0 Small Steps To Tensorflow\n"
     ]
    }
   ],
   "source": [
    "# Quick spot check - don't change this code - just use it to test your functions\n",
    "\n",
    "print('User 20 Viewed Articles')\n",
    "print('------------------------------------------------------')\n",
    "_, user_articles = get_user_articles(20, user_item=user_item)    \n",
    "for title in user_articles:\n",
    "    print(title.title())\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"The top 10 recommendations for User 20\")\n",
    "print('------------------------------------------------------')\n",
    "rec_ids, rec_names = user_user_recs_part2(20, 10)\n",
    "for id, title in zip(rec_ids, rec_names):\n",
    "    print(id, title.title())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Use your functions from above to correctly fill in the solutions to the dictionary below.  Then test your dictionary against the solution.  Provide the code you need to answer each following the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Tests with a dictionary of results\n",
    "\n",
    "# Find the user that is most similar to user 1 \n",
    "user1_most_sim =  get_top_sorted_users(1).neighbor_id[0]\n",
    "# Find the 10th most similar user to user 131 \n",
    "user131_10th_sim = get_top_sorted_users(131).neighbor_id[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This all looks good!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "## Dictionary Test Here\n",
    "sol_5_dict = {\n",
    "    'The user that is most similar to user 1.': user1_most_sim, \n",
    "    'The user that is the 10th most similar to user 131': user131_10th_sim,\n",
    "}\n",
    "\n",
    "t.sol_5_test(sol_5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` If we were given a new user, which of the above functions would you be able to use to make recommendations?  Explain.  Can you think of a better way we might make recommendations?  Use the cell below to explain a better method for new users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide your response here.**\n",
    "\n",
    "If given a new user (often referred to as a \"cold start\" problem in recommendation systems), the traditional user-user collaborative filtering method (which relies on the user's past interactions) is not applicable because the new user has no prior interactions or history. Therefore, of the functions discussed earlier:\n",
    "\n",
    "> get_user_articles: This function wouldn't be useful for a new user because it requires a user's past interactions to recommend articles.  \n",
    "> user_user_recs: This function also relies on finding similar users based on past interactions, so it wouldn't be applicable for a new user.\n",
    "\n",
    "For new users, a different approach is needed. Here are some common strategies:\n",
    "\n",
    "1. Popular Items Recommendation: Recommend items that are trending or most interacted with by other users. This helps new users see what's currently popular.\n",
    "Ask for User Preferences:\n",
    "2. When a new user signs up, ask them to choose their favorite categories or interests. Use this information to recommend more personalized items.\n",
    "3. Hybrid Approach for Minimal Interactions: Combine popular recommendations with a few tailored suggestions based on the user's limited interactions.\n",
    "    - Use item-item collaborative filtering to recommend items similar to what the user has shown interest in.\n",
    "    - Apply content-based filtering by using item features (like type or description) to find and suggest similar items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` Using your existing functions, provide the top 10 recommended articles you would provide for the a new user below.  You can test your function against our thoughts to make sure we are all on the same page with how we might make a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1429.0', '1330.0', '1431.0', '1427.0', '1364.0', '1314.0', '1293.0', '1170.0', '1162.0', '1304.0']\n"
     ]
    }
   ],
   "source": [
    "new_user = '0.0'\n",
    "\n",
    "# What would your recommendations be for this new user '0.0'?  As a new user, they have no observed articles.\n",
    "# Provide a list of the top 10 article ids you would give to \n",
    "# Your recommendations here\n",
    "new_user_recs = get_top_article_ids(10)\n",
    "print(new_user_recs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "assert set(new_user_recs) == set(['1314.0','1429.0','1293.0','1427.0','1162.0','1364.0','1304.0','1170.0','1431.0','1330.0']), \"Oops!  It makes sense that in this case we would want to recommend the most popular articles, because we don't know anything about these users.\"\n",
    "\n",
    "print(\"That's right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Content-Recs\">Part IV: Content Based Recommendations (EXTRA - NOT REQUIRED)</a>\n",
    "\n",
    "Another method we might use to make recommendations is to perform a ranking of the highest ranked articles associated with some term.  You might consider content to be the **doc_body**, **doc_description**, or **doc_full_name**.  There isn't one way to create a content based recommendation, especially considering that each of these columns hold content related information.  \n",
    "\n",
    "`1.` Use the function body below to create a content based recommender.  Since there isn't one right answer for this recommendation tactic, no test functions are provided.  Feel free to change the function inputs if you decide you want to try a method that requires more input values.  The input values are currently set with one idea in mind that you may use to make content based recommendations.  One additional idea is that you might want to choose the most popular recommendations that meet your 'content criteria', but again, there is a lot of flexibility in how you might make these recommendations.\n",
    "\n",
    "Note: This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Steps to constructing content-based recommendations:**  \n",
    "\n",
    "1. Combine unique articles from df_content and df.  \n",
    "2. Create a TD-IDF matrix using from the combined article titles .  \n",
    "3. Utilize the TD-IDF matrix to generate a similarity matrix using cosine similarity, where scores close to 1 indicate strong similarity.  \n",
    "4. Find similar article titles from the similarity matrix in sorted order.    \n",
    "\n",
    "**Constructing a Similarity Matrix for Article Titles via NLP TF-IDF**  \n",
    "\n",
    "TF-IDF, short for \"Term Frequency-Inverse Document Frequency,\" is used to assign numerical importance scores to words in documents. These scores are then utilized to create TF-IDF vectors for documents, enabling the calculation of document similarities using techniques like cosine similarity. The resulting similarity matrix quantifies the relationships between documents based on their content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Articles in df_content: 1051\n",
      "Unique Articles in df: 714\n",
      "How many article IDs overlap 437\n",
      "Total Combined Articles: 1328\n",
      "Note: 277 of 714 articles are not found in df_content\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Unique Articles in df_content:', df_content.article_id.nunique())\n",
    "print('Unique Articles in df:', df.article_id.nunique())\n",
    "\n",
    "print('How many article IDs overlap', len(np.intersect1d(df_content['article_id'].unique(), df['article_id'].unique())))\n",
    "\n",
    "print('Total Combined Articles:', len(set(list(df.article_id.unique())+list(df_content.article_id.unique()))))\n",
    "\n",
    "print('Note: 277 of 714 articles are not found in df_content')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This step involves the amalgamation of all articles from both df_content and df to create a comprehensive dataset for building the TD-IDF matrix folloerf by cosine similarity among articles. Additionally, we compute article-level statistics, which will play a crucial role in fine-tuning recommendations. When users request popular articles, the user engagement metric will guide the identification of widely viewed articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Unique Articles: 1328 1328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewed</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">unique_user_views</th>\n",
       "      <th>count</th>\n",
       "      <td>614.0</td>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>47.173669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>65.467790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>467.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">total_user_views</th>\n",
       "      <th>count</th>\n",
       "      <td>614.0</td>\n",
       "      <td>714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>64.415966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>109.175923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>937.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "viewed                       0           1\n",
       "unique_user_views count  614.0  714.000000\n",
       "                  mean     0.0   47.173669\n",
       "                  std      0.0   65.467790\n",
       "                  min      0.0    1.000000\n",
       "                  25%      0.0    7.000000\n",
       "                  50%      0.0   21.500000\n",
       "                  75%      0.0   59.000000\n",
       "                  max      0.0  467.000000\n",
       "total_user_views  count  614.0  714.000000\n",
       "                  mean     0.0   64.415966\n",
       "                  std      0.0  109.175923\n",
       "                  min      0.0    1.000000\n",
       "                  25%      0.0    8.000000\n",
       "                  50%      0.0   25.000000\n",
       "                  75%      0.0   69.000000\n",
       "                  max      0.0  937.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>title</th>\n",
       "      <th>unique_user_views</th>\n",
       "      <th>total_user_views</th>\n",
       "      <th>viewed</th>\n",
       "      <th>article_title</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1330</td>\n",
       "      <td>0</td>\n",
       "      <td>insights from new york car accident reports</td>\n",
       "      <td>467.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>1</td>\n",
       "      <td>insights from new york car accident reports</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>1429</td>\n",
       "      <td>0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>397.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>1</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1364</td>\n",
       "      <td>0</td>\n",
       "      <td>predicting churn with the spss random tree algorithm</td>\n",
       "      <td>388.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>1</td>\n",
       "      <td>predicting churn with the spss random tree algorithm</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>1314</td>\n",
       "      <td>0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>345.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>1</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>1398</td>\n",
       "      <td>0</td>\n",
       "      <td>total population by country</td>\n",
       "      <td>329.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>1</td>\n",
       "      <td>total population by country</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>1431</td>\n",
       "      <td>0</td>\n",
       "      <td>visualize car data with brunel</td>\n",
       "      <td>320.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>1</td>\n",
       "      <td>visualize car data with brunel</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1271</td>\n",
       "      <td>0</td>\n",
       "      <td>customer demographics and sales</td>\n",
       "      <td>314.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>1</td>\n",
       "      <td>customer demographics and sales</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1427</td>\n",
       "      <td>0</td>\n",
       "      <td>use xgboost, scikit-learn &amp; ibm watson machine learning apis</td>\n",
       "      <td>308.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1</td>\n",
       "      <td>use xgboost, scikit-learn &amp; ibm watson machine learning apis</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Deep Learning With Tensorflow Course by Big Data University</td>\n",
       "      <td>deep learning with tensorflow course by big data university</td>\n",
       "      <td>299.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Deep Learning With Tensorflow Course by Big Data University</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1160</td>\n",
       "      <td>0</td>\n",
       "      <td>analyze accident reports on amazon emr spark</td>\n",
       "      <td>299.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1</td>\n",
       "      <td>analyze accident reports on amazon emr spark</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id                                                doc_full_name  \\\n",
       "1239        1330                                                            0   \n",
       "1313        1429                                                            0   \n",
       "1266        1364                                                            0   \n",
       "1228        1314                                                            0   \n",
       "1285        1398                                                            0   \n",
       "1315        1431                                                            0   \n",
       "1197        1271                                                            0   \n",
       "1311        1427                                                            0   \n",
       "43            43  Deep Learning With Tensorflow Course by Big Data University   \n",
       "1130        1160                                                            0   \n",
       "\n",
       "                                                             title  \\\n",
       "1239                   insights from new york car accident reports   \n",
       "1313                    use deep learning for image classification   \n",
       "1266          predicting churn with the spss random tree algorithm   \n",
       "1228                  healthcare python streaming application demo   \n",
       "1285                                   total population by country   \n",
       "1315                                visualize car data with brunel   \n",
       "1197                               customer demographics and sales   \n",
       "1311  use xgboost, scikit-learn & ibm watson machine learning apis   \n",
       "43     deep learning with tensorflow course by big data university   \n",
       "1130                  analyze accident reports on amazon emr spark   \n",
       "\n",
       "      unique_user_views  total_user_views  viewed  \\\n",
       "1239              467.0             927.0       1   \n",
       "1313              397.0             937.0       1   \n",
       "1266              388.0             627.0       1   \n",
       "1228              345.0             614.0       1   \n",
       "1285              329.0             465.0       1   \n",
       "1315              320.0             671.0       1   \n",
       "1197              314.0             473.0       1   \n",
       "1311              308.0             643.0       1   \n",
       "43                299.0             460.0       1   \n",
       "1130              299.0             433.0       1   \n",
       "\n",
       "                                                     article_title  rank  \n",
       "1239                   insights from new york car accident reports   1.0  \n",
       "1313                    use deep learning for image classification   2.0  \n",
       "1266          predicting churn with the spss random tree algorithm   3.0  \n",
       "1228                  healthcare python streaming application demo   4.0  \n",
       "1285                                   total population by country   5.0  \n",
       "1315                                visualize car data with brunel   6.0  \n",
       "1197                               customer demographics and sales   7.0  \n",
       "1311  use xgboost, scikit-learn & ibm watson machine learning apis   8.0  \n",
       "43     Deep Learning With Tensorflow Course by Big Data University   9.0  \n",
       "1130                  analyze accident reports on amazon emr spark   9.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# STEP 1 - Combine All Articles - Viewed or Unseen\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "# Create a Article Meta DF - combine df_content and aggregated df \n",
    "# Includes viewed articles and those in the content dataset\n",
    "\n",
    "# Combine all metrics under article_meta\n",
    "article_meta = df.groupby(['article_id','title']).agg({'user_id': ['nunique', 'count']}).reset_index(drop=False)\n",
    "article_meta.columns =  ['article_id','title','unique_user_views', 'total_user_views']\n",
    "article_meta['article_id'] = article_meta['article_id'].astype(int)\n",
    "\n",
    "article_meta = pd.merge(df_content[['article_id','doc_full_name']], article_meta, on='article_id', how='outer')\n",
    "article_meta['viewed'] = np.where(article_meta['unique_user_views'].isnull(), 0,1)\n",
    "article_meta.fillna(0, inplace=True)\n",
    "article_meta['article_title'] = np.where(article_meta['doc_full_name'] != 0, article_meta['doc_full_name'], article_meta['title'])\n",
    "article_meta['rank'] = article_meta['unique_user_views'].rank(ascending=False, method='dense')\n",
    "print('Combined Unique Articles:', article_meta['article_title'].nunique(),article_meta['article_id'].nunique())\n",
    "\n",
    "# Display the results\n",
    "display(article_meta.groupby('viewed')[['unique_user_views','total_user_views']].describe().T)\n",
    "article_meta.sort_values('rank', ascending=True).head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "histnorm": true,
         "marker": {
          "color": "purple"
         },
         "name": "User Views",
         "opacity": 0.75,
         "type": "histogram",
         "x": [
          12,
          44,
          13,
          82,
          10,
          99,
          89,
          26,
          56,
          68,
          187,
          15,
          80,
          39,
          41,
          17,
          60,
          109,
          86,
          18,
          59,
          64,
          299,
          11,
          69,
          107,
          93,
          20,
          128,
          11,
          13,
          16,
          21,
          51,
          26,
          53,
          67,
          47,
          11,
          48,
          17,
          23,
          12,
          18,
          24,
          36,
          7,
          127,
          9,
          79,
          29,
          66,
          26,
          131,
          161,
          58,
          66,
          18,
          26,
          16,
          134,
          10,
          109,
          89,
          270,
          110,
          50,
          69,
          42,
          10,
          35,
          67,
          40,
          24,
          20,
          30,
          279,
          55,
          70,
          13,
          37,
          140,
          180,
          89,
          12,
          14,
          9,
          38,
          7,
          67,
          33,
          104,
          96,
          21,
          83,
          60,
          46,
          74,
          19,
          92,
          81,
          40,
          31,
          33,
          62,
          16,
          20,
          39,
          136,
          31,
          37,
          124,
          37,
          120,
          26,
          23,
          46,
          51,
          10,
          15,
          189,
          42,
          17,
          110,
          16,
          24,
          13,
          52,
          43,
          24,
          36,
          18,
          39,
          27,
          18,
          19,
          28,
          8,
          77,
          31,
          15,
          45,
          54,
          73,
          15,
          14,
          18,
          59,
          9,
          78,
          34,
          19,
          21,
          22,
          23,
          82,
          43,
          6,
          19,
          46,
          4,
          13,
          31,
          65,
          3,
          2,
          5,
          24,
          72,
          11,
          8,
          2,
          61,
          25,
          44,
          10,
          2,
          4,
          211,
          3,
          21,
          10,
          10,
          6,
          99,
          30,
          11,
          139,
          2,
          1,
          4,
          39,
          15,
          29,
          6,
          2,
          2,
          4,
          36,
          2,
          45,
          8,
          34,
          21,
          20,
          86,
          9,
          48,
          44,
          20,
          53,
          9,
          5,
          17,
          68,
          16,
          16,
          132,
          46,
          47,
          42,
          10,
          44,
          59,
          2,
          12,
          6,
          2,
          50,
          74,
          8,
          6,
          2,
          15,
          20,
          74,
          29,
          9,
          6,
          129,
          12,
          47,
          4,
          2,
          8,
          50,
          26,
          5,
          39,
          8,
          18,
          2,
          22,
          24,
          2,
          4,
          108,
          21,
          159,
          22,
          34,
          34,
          4,
          17,
          59,
          20,
          19,
          9,
          3,
          18,
          35,
          2,
          100,
          2,
          81,
          47,
          61,
          1,
          6,
          18,
          74,
          20,
          1,
          37,
          24,
          10,
          71,
          16,
          84,
          1,
          2,
          9,
          4,
          18,
          174,
          63,
          71,
          11,
          59,
          33,
          50,
          4,
          24,
          2,
          6,
          12,
          18,
          29,
          15,
          83,
          1,
          21,
          29,
          91,
          114,
          157,
          23,
          4,
          44,
          43,
          6,
          2,
          2,
          12,
          5,
          50,
          6,
          45,
          51,
          28,
          2,
          10,
          29,
          23,
          18,
          55,
          27,
          85,
          4,
          5,
          92,
          117,
          36,
          74,
          32,
          89,
          38,
          78,
          29,
          12,
          30,
          6,
          28,
          27,
          12,
          32,
          94,
          29,
          2,
          34,
          15,
          39,
          87,
          9,
          18,
          4,
          37,
          25,
          21,
          10,
          60,
          45,
          24,
          7,
          96,
          50,
          10,
          10,
          24,
          35,
          11,
          83,
          12,
          18,
          117,
          2,
          6,
          79,
          2,
          10,
          7,
          26,
          25,
          31,
          95,
          75,
          63,
          2,
          46,
          23,
          39,
          25,
          96,
          2,
          9,
          1,
          65,
          17,
          120,
          1,
          4,
          12,
          26,
          19,
          52,
          4,
          11,
          7,
          14,
          12,
          105,
          5,
          57,
          200,
          46,
          68,
          147,
          37,
          8,
          16,
          6,
          40,
          4,
          47,
          120,
          98,
          71,
          31,
          168,
          156,
          139,
          82,
          46,
          63,
          17,
          59,
          46,
          20,
          8,
          6,
          3,
          7,
          5,
          2,
          4,
          2,
          6,
          4,
          1,
          5,
          9,
          2,
          9,
          3,
          8,
          5,
          2,
          4,
          5,
          2,
          2,
          2,
          1,
          4,
          2,
          3,
          3,
          2,
          1,
          8,
          4,
          1,
          6,
          2,
          2,
          6,
          7,
          8,
          1,
          3,
          2,
          2,
          2,
          2,
          21,
          6,
          6,
          11,
          9,
          12,
          2,
          10,
          8,
          4,
          8,
          10,
          12,
          8,
          16,
          10,
          14,
          16,
          2,
          36,
          39,
          21,
          299,
          18,
          245,
          198,
          179,
          238,
          147,
          2,
          24,
          40,
          279,
          165,
          227,
          26,
          161,
          26,
          127,
          17,
          30,
          6,
          59,
          73,
          109,
          60,
          255,
          121,
          6,
          2,
          25,
          16,
          8,
          8,
          2,
          2,
          2,
          21,
          5,
          1,
          1,
          2,
          3,
          2,
          2,
          4,
          6,
          23,
          2,
          2,
          5,
          2,
          10,
          1,
          2,
          2,
          1,
          2,
          4,
          2,
          5,
          6,
          6,
          6,
          6,
          10,
          19,
          1,
          4,
          314,
          20,
          126,
          238,
          51,
          80,
          26,
          17,
          10,
          146,
          2,
          3,
          30,
          13,
          32,
          5,
          7,
          225,
          4,
          6,
          158,
          4,
          43,
          31,
          2,
          282,
          216,
          6,
          4,
          2,
          40,
          345,
          4,
          59,
          6,
          6,
          123,
          32,
          143,
          2,
          111,
          33,
          467,
          18,
          155,
          8,
          2,
          2,
          284,
          28,
          255,
          2,
          173,
          1,
          2,
          7,
          21,
          36,
          288,
          252,
          3,
          26,
          72,
          16,
          11,
          168,
          12,
          12,
          19,
          388,
          2,
          56,
          112,
          280,
          10,
          2,
          2,
          6,
          2,
          122,
          20,
          2,
          124,
          218,
          127,
          78,
          147,
          22,
          329,
          187,
          7,
          39,
          60,
          30,
          66,
          33,
          21,
          16,
          44,
          84,
          42,
          19,
          4,
          10,
          73,
          41,
          6,
          94,
          3,
          105,
          102,
          115,
          57,
          96,
          308,
          91,
          397,
          237,
          320,
          232,
          86,
          36,
          75,
          282,
          127,
          43,
          8,
          6,
          4,
          12,
          5
         ]
        }
       ],
       "layout": {
        "bargap": 0.1,
        "height": 400,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 30,
         "t": 40
        },
        "title": "User Engagement",
        "titlefont": {
         "size": 13
        },
        "width": 600,
        "xaxis": {
         "title": "",
         "titlefont": {
          "size": 10
         }
        },
        "yaxis": {
         "gridwidth": null,
         "tickfont": {
          "size": 10
         },
         "title": "Frequency",
         "titlefont": {
          "size": 12
         }
        }
       }
      },
      "text/html": [
       "<div id=\"cabc7197-c2e3-477c-bc8d-b98b1e166f3a\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"cabc7197-c2e3-477c-bc8d-b98b1e166f3a\", [{\"type\": \"histogram\", \"x\": [12.0, 44.0, 13.0, 82.0, 10.0, 99.0, 89.0, 26.0, 56.0, 68.0, 187.0, 15.0, 80.0, 39.0, 41.0, 17.0, 60.0, 109.0, 86.0, 18.0, 59.0, 64.0, 299.0, 11.0, 69.0, 107.0, 93.0, 20.0, 128.0, 11.0, 13.0, 16.0, 21.0, 51.0, 26.0, 53.0, 67.0, 47.0, 11.0, 48.0, 17.0, 23.0, 12.0, 18.0, 24.0, 36.0, 7.0, 127.0, 9.0, 79.0, 29.0, 66.0, 26.0, 131.0, 161.0, 58.0, 66.0, 18.0, 26.0, 16.0, 134.0, 10.0, 109.0, 89.0, 270.0, 110.0, 50.0, 69.0, 42.0, 10.0, 35.0, 67.0, 40.0, 24.0, 20.0, 30.0, 279.0, 55.0, 70.0, 13.0, 37.0, 140.0, 180.0, 89.0, 12.0, 14.0, 9.0, 38.0, 7.0, 67.0, 33.0, 104.0, 96.0, 21.0, 83.0, 60.0, 46.0, 74.0, 19.0, 92.0, 81.0, 40.0, 31.0, 33.0, 62.0, 16.0, 20.0, 39.0, 136.0, 31.0, 37.0, 124.0, 37.0, 120.0, 26.0, 23.0, 46.0, 51.0, 10.0, 15.0, 189.0, 42.0, 17.0, 110.0, 16.0, 24.0, 13.0, 52.0, 43.0, 24.0, 36.0, 18.0, 39.0, 27.0, 18.0, 19.0, 28.0, 8.0, 77.0, 31.0, 15.0, 45.0, 54.0, 73.0, 15.0, 14.0, 18.0, 59.0, 9.0, 78.0, 34.0, 19.0, 21.0, 22.0, 23.0, 82.0, 43.0, 6.0, 19.0, 46.0, 4.0, 13.0, 31.0, 65.0, 3.0, 2.0, 5.0, 24.0, 72.0, 11.0, 8.0, 2.0, 61.0, 25.0, 44.0, 10.0, 2.0, 4.0, 211.0, 3.0, 21.0, 10.0, 10.0, 6.0, 99.0, 30.0, 11.0, 139.0, 2.0, 1.0, 4.0, 39.0, 15.0, 29.0, 6.0, 2.0, 2.0, 4.0, 36.0, 2.0, 45.0, 8.0, 34.0, 21.0, 20.0, 86.0, 9.0, 48.0, 44.0, 20.0, 53.0, 9.0, 5.0, 17.0, 68.0, 16.0, 16.0, 132.0, 46.0, 47.0, 42.0, 10.0, 44.0, 59.0, 2.0, 12.0, 6.0, 2.0, 50.0, 74.0, 8.0, 6.0, 2.0, 15.0, 20.0, 74.0, 29.0, 9.0, 6.0, 129.0, 12.0, 47.0, 4.0, 2.0, 8.0, 50.0, 26.0, 5.0, 39.0, 8.0, 18.0, 2.0, 22.0, 24.0, 2.0, 4.0, 108.0, 21.0, 159.0, 22.0, 34.0, 34.0, 4.0, 17.0, 59.0, 20.0, 19.0, 9.0, 3.0, 18.0, 35.0, 2.0, 100.0, 2.0, 81.0, 47.0, 61.0, 1.0, 6.0, 18.0, 74.0, 20.0, 1.0, 37.0, 24.0, 10.0, 71.0, 16.0, 84.0, 1.0, 2.0, 9.0, 4.0, 18.0, 174.0, 63.0, 71.0, 11.0, 59.0, 33.0, 50.0, 4.0, 24.0, 2.0, 6.0, 12.0, 18.0, 29.0, 15.0, 83.0, 1.0, 21.0, 29.0, 91.0, 114.0, 157.0, 23.0, 4.0, 44.0, 43.0, 6.0, 2.0, 2.0, 12.0, 5.0, 50.0, 6.0, 45.0, 51.0, 28.0, 2.0, 10.0, 29.0, 23.0, 18.0, 55.0, 27.0, 85.0, 4.0, 5.0, 92.0, 117.0, 36.0, 74.0, 32.0, 89.0, 38.0, 78.0, 29.0, 12.0, 30.0, 6.0, 28.0, 27.0, 12.0, 32.0, 94.0, 29.0, 2.0, 34.0, 15.0, 39.0, 87.0, 9.0, 18.0, 4.0, 37.0, 25.0, 21.0, 10.0, 60.0, 45.0, 24.0, 7.0, 96.0, 50.0, 10.0, 10.0, 24.0, 35.0, 11.0, 83.0, 12.0, 18.0, 117.0, 2.0, 6.0, 79.0, 2.0, 10.0, 7.0, 26.0, 25.0, 31.0, 95.0, 75.0, 63.0, 2.0, 46.0, 23.0, 39.0, 25.0, 96.0, 2.0, 9.0, 1.0, 65.0, 17.0, 120.0, 1.0, 4.0, 12.0, 26.0, 19.0, 52.0, 4.0, 11.0, 7.0, 14.0, 12.0, 105.0, 5.0, 57.0, 200.0, 46.0, 68.0, 147.0, 37.0, 8.0, 16.0, 6.0, 40.0, 4.0, 47.0, 120.0, 98.0, 71.0, 31.0, 168.0, 156.0, 139.0, 82.0, 46.0, 63.0, 17.0, 59.0, 46.0, 20.0, 8.0, 6.0, 3.0, 7.0, 5.0, 2.0, 4.0, 2.0, 6.0, 4.0, 1.0, 5.0, 9.0, 2.0, 9.0, 3.0, 8.0, 5.0, 2.0, 4.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 2.0, 1.0, 8.0, 4.0, 1.0, 6.0, 2.0, 2.0, 6.0, 7.0, 8.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 21.0, 6.0, 6.0, 11.0, 9.0, 12.0, 2.0, 10.0, 8.0, 4.0, 8.0, 10.0, 12.0, 8.0, 16.0, 10.0, 14.0, 16.0, 2.0, 36.0, 39.0, 21.0, 299.0, 18.0, 245.0, 198.0, 179.0, 238.0, 147.0, 2.0, 24.0, 40.0, 279.0, 165.0, 227.0, 26.0, 161.0, 26.0, 127.0, 17.0, 30.0, 6.0, 59.0, 73.0, 109.0, 60.0, 255.0, 121.0, 6.0, 2.0, 25.0, 16.0, 8.0, 8.0, 2.0, 2.0, 2.0, 21.0, 5.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 6.0, 23.0, 2.0, 2.0, 5.0, 2.0, 10.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 2.0, 5.0, 6.0, 6.0, 6.0, 6.0, 10.0, 19.0, 1.0, 4.0, 314.0, 20.0, 126.0, 238.0, 51.0, 80.0, 26.0, 17.0, 10.0, 146.0, 2.0, 3.0, 30.0, 13.0, 32.0, 5.0, 7.0, 225.0, 4.0, 6.0, 158.0, 4.0, 43.0, 31.0, 2.0, 282.0, 216.0, 6.0, 4.0, 2.0, 40.0, 345.0, 4.0, 59.0, 6.0, 6.0, 123.0, 32.0, 143.0, 2.0, 111.0, 33.0, 467.0, 18.0, 155.0, 8.0, 2.0, 2.0, 284.0, 28.0, 255.0, 2.0, 173.0, 1.0, 2.0, 7.0, 21.0, 36.0, 288.0, 252.0, 3.0, 26.0, 72.0, 16.0, 11.0, 168.0, 12.0, 12.0, 19.0, 388.0, 2.0, 56.0, 112.0, 280.0, 10.0, 2.0, 2.0, 6.0, 2.0, 122.0, 20.0, 2.0, 124.0, 218.0, 127.0, 78.0, 147.0, 22.0, 329.0, 187.0, 7.0, 39.0, 60.0, 30.0, 66.0, 33.0, 21.0, 16.0, 44.0, 84.0, 42.0, 19.0, 4.0, 10.0, 73.0, 41.0, 6.0, 94.0, 3.0, 105.0, 102.0, 115.0, 57.0, 96.0, 308.0, 91.0, 397.0, 237.0, 320.0, 232.0, 86.0, 36.0, 75.0, 282.0, 127.0, 43.0, 8.0, 6.0, 4.0, 12.0, 5.0], \"opacity\": 0.75, \"name\": \"User Views\", \"histnorm\": true, \"marker\": {\"color\": \"purple\"}}], {\"height\": 400, \"width\": 600, \"title\": \"User Engagement\", \"titlefont\": {\"size\": 13}, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"bargap\": 0.1, \"yaxis\": {\"title\": \"Frequency\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"gridwidth\": null}, \"xaxis\": {\"title\": \"\", \"titlefont\": {\"size\": 10}}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"cabc7197-c2e3-477c-bc8d-b98b1e166f3a\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"cabc7197-c2e3-477c-bc8d-b98b1e166f3a\", [{\"type\": \"histogram\", \"x\": [12.0, 44.0, 13.0, 82.0, 10.0, 99.0, 89.0, 26.0, 56.0, 68.0, 187.0, 15.0, 80.0, 39.0, 41.0, 17.0, 60.0, 109.0, 86.0, 18.0, 59.0, 64.0, 299.0, 11.0, 69.0, 107.0, 93.0, 20.0, 128.0, 11.0, 13.0, 16.0, 21.0, 51.0, 26.0, 53.0, 67.0, 47.0, 11.0, 48.0, 17.0, 23.0, 12.0, 18.0, 24.0, 36.0, 7.0, 127.0, 9.0, 79.0, 29.0, 66.0, 26.0, 131.0, 161.0, 58.0, 66.0, 18.0, 26.0, 16.0, 134.0, 10.0, 109.0, 89.0, 270.0, 110.0, 50.0, 69.0, 42.0, 10.0, 35.0, 67.0, 40.0, 24.0, 20.0, 30.0, 279.0, 55.0, 70.0, 13.0, 37.0, 140.0, 180.0, 89.0, 12.0, 14.0, 9.0, 38.0, 7.0, 67.0, 33.0, 104.0, 96.0, 21.0, 83.0, 60.0, 46.0, 74.0, 19.0, 92.0, 81.0, 40.0, 31.0, 33.0, 62.0, 16.0, 20.0, 39.0, 136.0, 31.0, 37.0, 124.0, 37.0, 120.0, 26.0, 23.0, 46.0, 51.0, 10.0, 15.0, 189.0, 42.0, 17.0, 110.0, 16.0, 24.0, 13.0, 52.0, 43.0, 24.0, 36.0, 18.0, 39.0, 27.0, 18.0, 19.0, 28.0, 8.0, 77.0, 31.0, 15.0, 45.0, 54.0, 73.0, 15.0, 14.0, 18.0, 59.0, 9.0, 78.0, 34.0, 19.0, 21.0, 22.0, 23.0, 82.0, 43.0, 6.0, 19.0, 46.0, 4.0, 13.0, 31.0, 65.0, 3.0, 2.0, 5.0, 24.0, 72.0, 11.0, 8.0, 2.0, 61.0, 25.0, 44.0, 10.0, 2.0, 4.0, 211.0, 3.0, 21.0, 10.0, 10.0, 6.0, 99.0, 30.0, 11.0, 139.0, 2.0, 1.0, 4.0, 39.0, 15.0, 29.0, 6.0, 2.0, 2.0, 4.0, 36.0, 2.0, 45.0, 8.0, 34.0, 21.0, 20.0, 86.0, 9.0, 48.0, 44.0, 20.0, 53.0, 9.0, 5.0, 17.0, 68.0, 16.0, 16.0, 132.0, 46.0, 47.0, 42.0, 10.0, 44.0, 59.0, 2.0, 12.0, 6.0, 2.0, 50.0, 74.0, 8.0, 6.0, 2.0, 15.0, 20.0, 74.0, 29.0, 9.0, 6.0, 129.0, 12.0, 47.0, 4.0, 2.0, 8.0, 50.0, 26.0, 5.0, 39.0, 8.0, 18.0, 2.0, 22.0, 24.0, 2.0, 4.0, 108.0, 21.0, 159.0, 22.0, 34.0, 34.0, 4.0, 17.0, 59.0, 20.0, 19.0, 9.0, 3.0, 18.0, 35.0, 2.0, 100.0, 2.0, 81.0, 47.0, 61.0, 1.0, 6.0, 18.0, 74.0, 20.0, 1.0, 37.0, 24.0, 10.0, 71.0, 16.0, 84.0, 1.0, 2.0, 9.0, 4.0, 18.0, 174.0, 63.0, 71.0, 11.0, 59.0, 33.0, 50.0, 4.0, 24.0, 2.0, 6.0, 12.0, 18.0, 29.0, 15.0, 83.0, 1.0, 21.0, 29.0, 91.0, 114.0, 157.0, 23.0, 4.0, 44.0, 43.0, 6.0, 2.0, 2.0, 12.0, 5.0, 50.0, 6.0, 45.0, 51.0, 28.0, 2.0, 10.0, 29.0, 23.0, 18.0, 55.0, 27.0, 85.0, 4.0, 5.0, 92.0, 117.0, 36.0, 74.0, 32.0, 89.0, 38.0, 78.0, 29.0, 12.0, 30.0, 6.0, 28.0, 27.0, 12.0, 32.0, 94.0, 29.0, 2.0, 34.0, 15.0, 39.0, 87.0, 9.0, 18.0, 4.0, 37.0, 25.0, 21.0, 10.0, 60.0, 45.0, 24.0, 7.0, 96.0, 50.0, 10.0, 10.0, 24.0, 35.0, 11.0, 83.0, 12.0, 18.0, 117.0, 2.0, 6.0, 79.0, 2.0, 10.0, 7.0, 26.0, 25.0, 31.0, 95.0, 75.0, 63.0, 2.0, 46.0, 23.0, 39.0, 25.0, 96.0, 2.0, 9.0, 1.0, 65.0, 17.0, 120.0, 1.0, 4.0, 12.0, 26.0, 19.0, 52.0, 4.0, 11.0, 7.0, 14.0, 12.0, 105.0, 5.0, 57.0, 200.0, 46.0, 68.0, 147.0, 37.0, 8.0, 16.0, 6.0, 40.0, 4.0, 47.0, 120.0, 98.0, 71.0, 31.0, 168.0, 156.0, 139.0, 82.0, 46.0, 63.0, 17.0, 59.0, 46.0, 20.0, 8.0, 6.0, 3.0, 7.0, 5.0, 2.0, 4.0, 2.0, 6.0, 4.0, 1.0, 5.0, 9.0, 2.0, 9.0, 3.0, 8.0, 5.0, 2.0, 4.0, 5.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 2.0, 1.0, 8.0, 4.0, 1.0, 6.0, 2.0, 2.0, 6.0, 7.0, 8.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 21.0, 6.0, 6.0, 11.0, 9.0, 12.0, 2.0, 10.0, 8.0, 4.0, 8.0, 10.0, 12.0, 8.0, 16.0, 10.0, 14.0, 16.0, 2.0, 36.0, 39.0, 21.0, 299.0, 18.0, 245.0, 198.0, 179.0, 238.0, 147.0, 2.0, 24.0, 40.0, 279.0, 165.0, 227.0, 26.0, 161.0, 26.0, 127.0, 17.0, 30.0, 6.0, 59.0, 73.0, 109.0, 60.0, 255.0, 121.0, 6.0, 2.0, 25.0, 16.0, 8.0, 8.0, 2.0, 2.0, 2.0, 21.0, 5.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 6.0, 23.0, 2.0, 2.0, 5.0, 2.0, 10.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 2.0, 5.0, 6.0, 6.0, 6.0, 6.0, 10.0, 19.0, 1.0, 4.0, 314.0, 20.0, 126.0, 238.0, 51.0, 80.0, 26.0, 17.0, 10.0, 146.0, 2.0, 3.0, 30.0, 13.0, 32.0, 5.0, 7.0, 225.0, 4.0, 6.0, 158.0, 4.0, 43.0, 31.0, 2.0, 282.0, 216.0, 6.0, 4.0, 2.0, 40.0, 345.0, 4.0, 59.0, 6.0, 6.0, 123.0, 32.0, 143.0, 2.0, 111.0, 33.0, 467.0, 18.0, 155.0, 8.0, 2.0, 2.0, 284.0, 28.0, 255.0, 2.0, 173.0, 1.0, 2.0, 7.0, 21.0, 36.0, 288.0, 252.0, 3.0, 26.0, 72.0, 16.0, 11.0, 168.0, 12.0, 12.0, 19.0, 388.0, 2.0, 56.0, 112.0, 280.0, 10.0, 2.0, 2.0, 6.0, 2.0, 122.0, 20.0, 2.0, 124.0, 218.0, 127.0, 78.0, 147.0, 22.0, 329.0, 187.0, 7.0, 39.0, 60.0, 30.0, 66.0, 33.0, 21.0, 16.0, 44.0, 84.0, 42.0, 19.0, 4.0, 10.0, 73.0, 41.0, 6.0, 94.0, 3.0, 105.0, 102.0, 115.0, 57.0, 96.0, 308.0, 91.0, 397.0, 237.0, 320.0, 232.0, 86.0, 36.0, 75.0, 282.0, 127.0, 43.0, 8.0, 6.0, 4.0, 12.0, 5.0], \"opacity\": 0.75, \"name\": \"User Views\", \"histnorm\": true, \"marker\": {\"color\": \"purple\"}}], {\"height\": 400, \"width\": 600, \"title\": \"User Engagement\", \"titlefont\": {\"size\": 13}, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"bargap\": 0.1, \"yaxis\": {\"title\": \"Frequency\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"gridwidth\": null}, \"xaxis\": {\"title\": \"\", \"titlefont\": {\"size\": 10}}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of user engagement scores\n",
    "\n",
    "viewed = article_meta[article_meta['viewed']==1]\n",
    "\n",
    "trace =go.Histogram(\n",
    "    x=viewed['unique_user_views'], \n",
    "    opacity=0.75,\n",
    "    name='User Views',\n",
    "    histnorm = True,\n",
    "    #xbins=dict( # bins used for histogram\n",
    "    #    start=0,\n",
    "    #    end=threshold,\n",
    "    #    size=5 ),\n",
    "    marker= dict(color='purple')\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    height = 400, \n",
    "    width = 600, \n",
    "    title ='User Engagement',\n",
    "    titlefont = dict(size=13),\n",
    "    margin=dict(l=50, r=30, t=40, b=50),    \n",
    "    bargap=0.1,\n",
    "    yaxis = {\n",
    "        'title': 'Frequency',\n",
    "        'titlefont': dict(size=12),\n",
    "        'tickfont' : dict(size=10),\n",
    "        'gridwidth': None\n",
    "        },\n",
    "    xaxis = {\n",
    "        'title': '', \n",
    "        'titlefont': dict(size=10)\n",
    "        },        \n",
    "    )              \n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "iplot(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# STEP 2:  Construct TD-IDF matrix\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "# Function to tokenize article titles \n",
    "\n",
    "def customtokenize(text):\n",
    "\n",
    "    \"\"\"\n",
    "    This function performs custom text tokenization by normalizing text, removing specified patterns,\n",
    "    removing stopwords, tokenizing, and lemmatizing the text.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "    list of str: List of tokenized and lemmatized words.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # normalize text\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text.lower())\n",
    "    text = re.sub(r'(?:\\b\\d+\\b)', ' ', text)    \n",
    "    #text = re.sub(r'\\s\\d+(\\s\\d+)*\\s', ' ', text)\n",
    "               \n",
    "    # stopword list \n",
    "    stop_words = stopwords.words(\"english\")\n",
    "        \n",
    "    # tokenize\n",
    "    words = word_tokenize(text)\n",
    "        \n",
    "    # lemmatize\n",
    "    words_lemmed = [WordNetLemmatizer().lemmatize(w).strip() for w in words if w not in stop_words]\n",
    "\n",
    "    return words_lemmed    \n",
    "\n",
    "def tfidf_similarity(df: pd.DataFrame, title):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate TF-IDF similarity matrix for a given DataFrame and text column.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame containing text data.\n",
    "    - title (str): Name of the column in df that contains the text data.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Similarity matrix representing the pairwise cosine similarity\n",
    "      between documents in the input DataFrame based on TF-IDF vectorization.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    similarity_matrix = tfidf_similarity(my_dataframe, 'title_column')\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    corpus = list(df[title].unique())\n",
    "    #print('Corpus size:', len(corpus))\n",
    "\n",
    "    vectorizer = TfidfVectorizer(tokenizer=customtokenize, ngram_range=(1, 3), min_df=3, use_idf=True )\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    #print('Number of Features:', len(vectorizer.get_feature_names()), tfidf_matrix.shape)\n",
    "\n",
    "    similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    #print('TD_IDF Similarity:', similarity.shape)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def get_article_meta(article_ids: list, df=article_meta):\n",
    "    '''\n",
    "    INPUT:\n",
    "    article_ids - (list) a list of article ids\n",
    "    df - (pandas dataframe) df as defined at the top of the notebook\n",
    "    \n",
    "    OUTPUT:\n",
    "    article_names - (list) a list of article names associated with the list of article ids \n",
    "                    (this is identified by the title column)\n",
    "    '''\n",
    "    \n",
    "    article_names = list(df[df['article_id'].isin(article_ids)]['article_title'].unique())\n",
    "    #meta = df[df['article_id'].isin(article_ids)]['doc_full_name']\n",
    "\n",
    "    return article_names # Return the article names associated with list of article ids    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.20631097, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017433266151 1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1434</th>\n",
       "      <th>1435</th>\n",
       "      <th>1436</th>\n",
       "      <th>1437</th>\n",
       "      <th>1439</th>\n",
       "      <th>1440</th>\n",
       "      <th>1441</th>\n",
       "      <th>1442</th>\n",
       "      <th>1443</th>\n",
       "      <th>1444</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03439</td>\n",
       "      <td>0.050769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063013</td>\n",
       "      <td>0.541237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069402</td>\n",
       "      <td>0.036241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02422</td>\n",
       "      <td>0.035756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044379</td>\n",
       "      <td>0.381184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048878</td>\n",
       "      <td>0.025524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034390</td>\n",
       "      <td>0.024220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049904</td>\n",
       "      <td>0.063540</td>\n",
       "      <td>0.134839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054963</td>\n",
       "      <td>0.028701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2     3        4         5     6         7     \\\n",
       "0   1.0  0.000000  0.000000   0.0  0.00000  0.000000   0.0  0.000000   \n",
       "1   0.0  1.000000  0.206311   0.0  0.03439  0.050769   0.0  0.063013   \n",
       "2   0.0  0.206311  1.000000   0.0  0.02422  0.035756   0.0  0.044379   \n",
       "3   0.0  0.000000  0.000000   1.0  0.00000  0.000000   0.0  0.000000   \n",
       "4   0.0  0.034390  0.024220   0.0  1.00000  0.040207   0.0  0.049904   \n",
       "\n",
       "       8         9     ...   1434  1435  1436  1437  1439      1440      1441  \\\n",
       "0  0.000000  0.000000  ...    0.0   0.0   0.0   0.0   0.0  0.000000  0.000000   \n",
       "1  0.541237  0.000000  ...    0.0   0.0   0.0   0.0   0.0  0.069402  0.036241   \n",
       "2  0.381184  0.000000  ...    0.0   0.0   0.0   0.0   0.0  0.048878  0.025524   \n",
       "3  0.000000  0.000000  ...    0.0   0.0   0.0   0.0   0.0  0.000000  0.000000   \n",
       "4  0.063540  0.134839  ...    0.0   0.0   0.0   0.0   0.0  0.054963  0.028701   \n",
       "\n",
       "   1442  1443  1444  \n",
       "0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1328 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# STEP 3:  Derive Cosine Similarity\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "articles_sim =  tfidf_similarity(article_meta, 'article_title')\n",
    "display(articles_sim[:2])\n",
    "\n",
    "print(np.mean(articles_sim), np.max(articles_sim), np.percentile(articles_sim,0.5))\n",
    "articles_sim_df = pd.DataFrame(articles_sim, columns = article_meta['article_id'].tolist(), index = article_meta['article_id'].tolist())\n",
    "display(articles_sim_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Being Compared: Detect Malfunctioning IoT Sensors with Streaming Analytics\n",
      "\n",
      "Similar Articles:\n",
      "Experience Iot With Coursera\n",
      "Sensor Sensibility At Hull Digital\n",
      "Data Science For Real-Time Streaming Analytics\n",
      "Building Iot Apps On Cloudant, With Kiwi Wearables\n",
      "What’S New In The Streaming Analytics Service On Bluemix\n",
      "Developing For The Ibm Streaming Analytics Service\n",
      "Build A Python App On The Streaming Analytics Service\n",
      "Data Model With Streaming Analytics And Python\n",
      "54174    Detect Potentially Malfunctioning Sensors In R...\n",
      "Name: Title, Dtype: Object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 4:  Find similar articles based on titles\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "aid = 0\n",
    "print('Article Being Compared:', get_article_meta([aid])[0])\n",
    "print()\n",
    "print('Similar Articles:')\n",
    "for id, sim in articles_sim_df.loc[aid].items():\n",
    "    if sim >= 0.25 and int(id) != aid:\n",
    "        print(get_article_meta([int(id)])[0].title())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now that you have put together your content-based recommendation system, use the cell below to write a summary explaining how your content based recommender works.  Do you see any possible improvements that could be made to your function?  Is there anything novel about your content based recommender?\n",
    "\n",
    "**This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write an explanation of your content based recommendation system here.**\n",
    "\n",
    "The content-based recommender system described here relies on the TF-IDF (Term Frequency-Inverse Document Frequency) technique applied to article titles to create a similarity matrix. Unlike collaborative filtering methods, this approach doesn't require user ratings or interaction data but instead leverages textual metadata such as article titles or descriptions, converting them into numerical data. This practical approach aligns with user behavior, as users often search for content with similar phrasing.\n",
    "\n",
    "The system's uniqueness lies in its ability to recommend articles that users have already viewed, as well as new or previously unexplored articles. By broadening recommendations to less-explored but highly similar articles, it enhances both relevance and novelty in the suggested content.\n",
    "\n",
    "However, this is a basic recommendation system, and there are opportunities for improvement. Fine-tuning the TF-IDF parameters and conducting feature engineering could enhance its performance. Incorporating additional metadata such as article genre and creation date could also improve recommendation quality. Furthermore, exploring hybrid recommendation approaches, such as combining weighted item-to-item recommendations with TF-IDF similarity matrices, may provide more robust and personalized recommendations in the future.\n",
    "\n",
    "Here are the construction steps:\n",
    "\n",
    "1. We started by creating a combined dataset that includes unique article IDs and titles from both df_content and df. This dataset also incorporates summary statistics at the article level, such as unique user views, total views, a viewed flag.\n",
    "\n",
    "2. The combined dataset was utilized to build a TD-IDF matrix, representing articles and their associated bag of words.\n",
    "\n",
    "3. With the TD-IDF matrix in place, we computed the cosine similarity matrix. This matrix quantifies the similarity between articles, with values closer to 1 indicating stronger similarity.\n",
    "\n",
    "4. Using the cosine similarity matrix, we can identify similar articles based on their similarity scores, where scores closer to 1 denote higher similarity strength.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hybrid-Based Recommendations\n",
    "\n",
    "In the demonstration below, we explore three distinct recommendation approaches: rank-based, collaborative filtering, and content-based, all designed to provide personalized recommendations. This basic recommender system addresses the following scenarios:  \n",
    "\n",
    "- New Users: Recommendations focus on popular (most viewed) articles.  \n",
    "- Less-Engaged Users (seen 5 or less): Content-based articles are recommended, sorted by popularity.  \n",
    "- Active Users: Recommendations include a mix of user-based and content-based articles, sorted by both similarity and popularity.\n",
    "\n",
    "To facilitate this process, a Python class called ArticleRecommender (recommender.py) shown below is implemented. This class serves as a central hub for processing, and it showcases how various scenarios are handled. Additional functions are imported from \"recommender_functions.py\" to support these recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lemsf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lemsf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lemsf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lemsf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import recommender_functions as rfnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing code that is in recommender.py\n",
    "\n",
    "class ArticleRecommender:\n",
    "\n",
    "    \"\"\"\n",
    "    A class for providing personalized article recommendations for users or popular recommendations for new users.\n",
    "\n",
    "    Attributes:\n",
    "        df (pd.DataFrame): The user-item interaction dataset.\n",
    "        df_content (pd.DataFrame): The article content dataset.\n",
    "        article_meta (pd.DataFrame): Metadata summary for articles.\n",
    "        user_meta (pd.DataFrame): Metadata summary for users.\n",
    "        user_item (pd.DataFrame): User-item interaction matrix.\n",
    "        tdidf (array): TD-IDF vectorization output for article titles.\n",
    "\n",
    "    Methods:\n",
    "        make_recs(user_id=None, article_id=None, m=10):\n",
    "            Generates personalized article recommendations for a user or provides popular recommendations for new users.\n",
    "\n",
    "    Example:\n",
    "        # Instantiate the ArticleRecommender class\n",
    "        recommender = ArticleRecommender()\n",
    "\n",
    "        # Generate recommendations for a specific user\n",
    "        recommender.make_recs(user_id=1, m=5)\n",
    "\n",
    "        # Generate recommendations for a specific article\n",
    "        recommender.make_recs(article_id=123, m=10)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Load datasets\n",
    "        \n",
    "        self.df = pd.read_csv('data/user-item-interactions.csv')\n",
    "        self.df_content = pd.read_csv('data/articles_community.csv')\n",
    "        del self.df['Unnamed: 0']\n",
    "        del self.df_content['Unnamed: 0']\n",
    "\n",
    "        # Convert article IDs to integer\n",
    "        self.df['article_id'] = self.df['article_id'].astype(int)\n",
    "\n",
    "        # Drop duplicates\n",
    "        self.df_content.drop_duplicates(subset='article_id', inplace=True)\n",
    "\n",
    "        # Encode email\n",
    "        email_encoded = rfnc.email_mapper(self.df)\n",
    "        del self.df['email']\n",
    "        self.df['user_id'] = email_encoded\n",
    "\n",
    "        # Create meta data summaries\n",
    "        self.article_meta, self.user_meta = rfnc.create_meta_summary(self.df, self.df_content)\n",
    "\n",
    "        # Construct user-item interaction matrix\n",
    "        self.user_item = rfnc.create_user_item_interaction(self.df)\n",
    "\n",
    "        # Construct TF-IDF matrix\n",
    "        self.tdidf = rfnc.create_tfidf(self.article_meta, 'article_title')\n",
    "\n",
    "\n",
    "    def make_recs(self, user_id=None, article_id=None, m=10):\n",
    "\n",
    "        \"\"\"\n",
    "        Generate personalized article recommendations for a user or provide popular recommendations for new users.\n",
    "\n",
    "        Args:\n",
    "            user_id (int): User ID for whom recommendations are generated (optional).\n",
    "            article_id (int): Article ID for which similar articles are recommended (optional).\n",
    "            m (int): Number of recommendations to provide (optional).\n",
    "\n",
    "        Returns:\n",
    "            None: Prints personalized recommendations or popular articles.\n",
    "        \"\"\"\n",
    "        \n",
    "        print('Welcome to the IBM Data Science Platform')\n",
    "        print('==========================================================================')\n",
    "        print()\n",
    "        \n",
    "        if article_id is not None:\n",
    "            article_name = self.article_meta[self.article_meta['article_id'] == article_id]['article_title'].iloc[0]\n",
    "            recs_ = rfnc.get_content_recs(user_id, self.tdidf, self.user_item, self.user_meta, self.article_meta, article_id)\n",
    "            content_recs = pd.merge(recs_, self.article_meta, on='article_id')\n",
    "            content_recs.sort_values(by=['similarity_score', 'rank'], inplace=True)\n",
    "            \n",
    "            if len(content_recs) > 0:\n",
    "                ctr = 0\n",
    "                print(f\"Recommendations for Article {article_id}: {article_name.title()}\")\n",
    "                print()\n",
    "                for index, row in content_recs.iterrows():\n",
    "                    print(f\"  {row['article_id']}: {row['article_title'].title()} {row['star']}\")\n",
    "                    ctr += 1\n",
    "                    if ctr > m:\n",
    "                        break\n",
    "                \n",
    "                print()\n",
    "                print('Note: articles with high user engagement are marked with asterisks')\n",
    "            else:\n",
    "                print('No similar titles found...')\n",
    "            \n",
    "            print()\n",
    "            print('==========================================================================')\n",
    "            return\n",
    "\n",
    "        user_list = self.user_meta['user_id'].unique().tolist()\n",
    "\n",
    "        if user_id not in user_list:\n",
    "            pop_recs = rfnc.get_popular_recs(self.article_meta, m=10)\n",
    "            print('If you are new, we recommend these popular articles:')\n",
    "            print()\n",
    "            \n",
    "            for index, row in pop_recs.sort_values(by=['rank'], ascending=True).iterrows():\n",
    "                if row['rank'] <= m:\n",
    "                    print(f\"  {row['article_id']}: {row['article_title'].title()} viewed by {int(row['unique_user_views'])}\")\n",
    "            \n",
    "            print()\n",
    "            print('==========================================================================')\n",
    "            return\n",
    "        \n",
    "        elif self.user_meta.loc[self.user_meta['user_id'] == user_id, 'narticles'].iloc[0] < 6:\n",
    "            user_narticles = self.user_meta.loc[self.user_meta['user_id'] == user_id, 'narticles'].iloc[0]\n",
    "            print(f\"You have viewed {user_narticles} article(s)\")\n",
    "            \n",
    "            recs_ = rfnc.get_content_recs(user_id, self.tdidf, self.user_item, self.user_meta, self.article_meta)\n",
    "            content_recs = pd.merge(recs_, self.article_meta, on='article_id')\n",
    "            content_recs.sort_values(by=['similarity_score', 'rank'], inplace=True)\n",
    "            \n",
    "            content_recs_viewed = content_recs[content_recs['viewed'] == 1]\n",
    "            content_recs_unseen = content_recs[content_recs['viewed'] == 0]\n",
    "\n",
    "            if len(content_recs_viewed) > 0:\n",
    "                ctr = 0\n",
    "                print('Check out related articles:')\n",
    "                print()\n",
    "                \n",
    "                for index, row in content_recs_viewed.iterrows():\n",
    "                    print(f\"  {row['article_id']}: {row['article_title'].title()} {row['star']}\")\n",
    "                    ctr += 1\n",
    "                    if ctr > m:\n",
    "                        break\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            if len(content_recs_unseen) > 0:\n",
    "                ctr = 0\n",
    "                print('Explore related articles not viewed yet:')\n",
    "                print()\n",
    "                \n",
    "                for index, row in content_recs_unseen.iterrows():\n",
    "                    print(f\"  {row['article_id']}: {row['article_title'].title()}\")\n",
    "                    ctr += 1\n",
    "                    if ctr > m - 5:\n",
    "                        break\n",
    "            \n",
    "            print()\n",
    "            print('Note: articles with high user engagement are marked with asterisks')\n",
    "            print()\n",
    "            print('==========================================================================')\n",
    "        \n",
    "        else:\n",
    "            user_narticles = self.user_meta.loc[self.user_meta['user_id'] == user_id, 'narticles'].iloc[0]\n",
    "            print(f\"You have viewed {user_narticles} article(s)\")\n",
    "            \n",
    "            urecs_ = rfnc.get_user_recs(user_id, self.user_item, self.user_meta, m=5)\n",
    "            user_recs = self.article_meta[self.article_meta['article_id'].isin(urecs_)]\n",
    "            user_recs = user_recs.copy()\n",
    "            user_recs.sort_values(by=['rank'], ascending=True, inplace=True)    \n",
    "\n",
    "            if len(user_recs) > 0:\n",
    "                ctr = 0\n",
    "                print('Check out articles recommended by other users:')\n",
    "                print()\n",
    "                \n",
    "                for index, row in user_recs.iterrows():\n",
    "                    print(f\"  {row['article_id']}: {row['article_title'].title()} {row['star']}\")\n",
    "                    ctr += 1\n",
    "                    if ctr > m:\n",
    "                        break\n",
    "            else:\n",
    "                print('No user recommendations at this time')\n",
    "            \n",
    "            crecs_ = rfnc.get_content_recs(user_id, self.tdidf, self.user_item, self.user_meta, self.article_meta)\n",
    "            content_recs = crecs_.copy()\n",
    "            content_recs = content_recs[~content_recs['article_id'].isin(user_recs['article_id'][:m])]\n",
    "            content_recs = pd.merge(content_recs, self.article_meta, on='article_id', how='inner')\n",
    "            content_recs.sort_values(by=['similarity_score', 'rank'], inplace=True)\n",
    "            \n",
    "            print()       \n",
    "            if len(content_recs) > 0:                \n",
    "                ctr = 0\n",
    "                \n",
    "                if len(user_recs) == 0:\n",
    "                    print('Explore related articles:')\n",
    "                else:\n",
    "                    print('Explore related articles:')\n",
    "                \n",
    "                print()\n",
    "                \n",
    "                for index, row in content_recs.iterrows():            \n",
    "                    print(f\"  {row['article_id']}: {row['article_title'].title()} {row['star']}\")\n",
    "                    ctr += 1\n",
    "                    \n",
    "                    if ctr > m - 5:\n",
    "                        break        \n",
    "\n",
    "            print()\n",
    "            print('Note: articles with high user engagement are marked with asterisks')\n",
    "            print()\n",
    "            print('==========================================================================')\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a new recommeder\n",
    "\n",
    "ibm_rec = ArticleRecommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45993, 3), (1051, 5))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibm_rec.df.shape, ibm_rec.df_content.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1328, 9)\n",
      "(5149, 2)\n",
      "(5149, 714)\n",
      "(1328, 829)\n"
     ]
    }
   ],
   "source": [
    "# Article meta summary\n",
    "print(ibm_rec.article_meta.shape)\n",
    "\n",
    "# Article user summary\n",
    "print(ibm_rec.user_meta.shape)\n",
    "\n",
    "# User x Item interaction\n",
    "print(ibm_rec.user_item.shape)\n",
    "\n",
    "# TD-IDF matrix\n",
    "print(ibm_rec.tdidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the IBM Data Science Platform\n",
      "==========================================================================\n",
      "\n",
      "If you are new, we recommend these popular articles:\n",
      "\n",
      "  1330: Insights From New York Car Accident Reports viewed by 467\n",
      "  1429: Use Deep Learning For Image Classification viewed by 397\n",
      "  1364: Predicting Churn With The Spss Random Tree Algorithm viewed by 388\n",
      "  1314: Healthcare Python Streaming Application Demo viewed by 345\n",
      "  1398: Total Population By Country viewed by 329\n",
      "  1431: Visualize Car Data With Brunel viewed by 320\n",
      "  1271: Customer Demographics And Sales viewed by 314\n",
      "  1427: Use Xgboost, Scikit-Learn & Ibm Watson Machine Learning Apis viewed by 308\n",
      "  43: Deep Learning With Tensorflow Course By Big Data University viewed by 299\n",
      "  1160: Analyze Accident Reports On Amazon Emr Spark viewed by 299\n",
      "  1351: Model Bike Sharing Data With Spss viewed by 288\n",
      "\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "# recommendations for a new user, user_id = 0 or user_id > 5149\n",
    "\n",
    "ibm_rec.make_recs(user_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the IBM Data Science Platform\n",
      "==========================================================================\n",
      "\n",
      "You have viewed 3 article(s)\n",
      "Check out related articles:\n",
      "\n",
      "  751: Build A Predictive Analytic Model \n",
      "  1274: Data Model With Streaming Analytics And Python \n",
      "  673: Predict Chronic Kidney Disease Using Spss Modeler Flows \n",
      "  759: Are Your Predictive Models Like Broken Clocks? \n",
      "  759: Are Your Predictive Models Like Broken Clocks? \n",
      "  693: Better Together: Spss And Data Science Experience \n",
      "  682: Easy Json Loading And Social Sharing In Dsx Notebooks \n",
      "  266: Developing Ibm Streams Applications With The Python Api (Version 1.6) \n",
      "  935: Making Data Cleaning Simple With The Sparkling.Data Library \n",
      "  1364: Predicting Churn With The Spss Random Tree Algorithm *****\n",
      "  39: Pulling And Displaying Etf Data \n",
      "\n",
      "Explore related articles not viewed yet:\n",
      "\n",
      "  753: Sharing Non-Public Data In Jupyter Notebooks – Ibm Watson Data Lab – Medium\n",
      "  938: Formatted Sql In Python With Psycopg’S Mogrify\n",
      "  565: How To Watch And Wait With Compose'S Bach And Api\n",
      "  837: The Center Of Your Data Universe\n",
      "  282: Customer: Drone Deploy Conquers The Data Layer\n",
      "  93: Deploy Your Php Application To Bluemix\n",
      "\n",
      "Note: articles with high user engagement are marked with asterisks\n",
      "\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "# recommendations for a less-engaged user, user_id = 5\n",
    "\n",
    "ibm_rec.make_recs(user_id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the IBM Data Science Platform\n",
      "==========================================================================\n",
      "\n",
      "You have viewed 2 article(s)\n",
      "Check out related articles:\n",
      "\n",
      "  400: Read And Write Data To And From Amazon S3 Buckets In Rstudio \n",
      "  1161: Analyze Data, Build A Dashboard With Spark And Pixiedust \n",
      "  1237: Country Statistics: Natural Gas - Consumption \n",
      "  1165: Analyze Precipitation Data ****\n",
      "  4: Analyze Ny Restaurant Data Using Spark In Dsx \n",
      "  395: Run Dsx Notebooks On Amazon Emr \n",
      "  1188: Consumption Of Ozone-Depleting Cfcs In Odp Metric Tons \n",
      "  486: Use Spark R To Load And Analyze Data \n",
      "  1317: House Building With Worker Skills \n",
      "  1208: Country Statistics: Electricity - Consumption \n",
      "  1165: Analyze Precipitation Data ****\n",
      "\n",
      "Explore related articles not viewed yet:\n",
      "\n",
      "  257: Building A Cloudant Cluster Of Raspberry Pis\n",
      "  436: Building Ohlc Data In Postgresql\n",
      "  536: Embed Rich Reports In Your Applications\n",
      "  594: Ny Motor Vehicle Accident Analysis\n",
      "  703: Building Couchapps\n",
      "\n",
      "Note: articles with high user engagement are marked with asterisks\n",
      "\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "# recommendations for a less-engaged user, user_id = 25\n",
    "\n",
    "ibm_rec.make_recs(user_id=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the IBM Data Science Platform\n",
      "==========================================================================\n",
      "\n",
      "You have viewed 72 article(s)\n",
      "Check out articles recommended by other users:\n",
      "\n",
      "  1429: Use Deep Learning For Image Classification *****\n",
      "  1431: Visualize Car Data With Brunel *****\n",
      "  1160: Analyze Accident Reports On Amazon Emr Spark *****\n",
      "  1351: Model Bike Sharing Data With Spss *****\n",
      "  1336: Learn Basics About Notebooks And Apache Spark ****\n",
      "  1436: Welcome To Pixiedust ****\n",
      "  1304: Gosales Transactions For Logistic Regression Model ****\n",
      "  1368: Putting A Human Face On Machine Learning ****\n",
      "  1170: Apache Spark Lab, Part 1: Basic Concepts ****\n",
      "  1338: Ml Optimization Using Cognitive Assistant ****\n",
      "  1185: Classify Tumors With Machine Learning ****\n",
      "\n",
      "Explore related articles:\n",
      "\n",
      "  888: Use All The Databases – Part 2 \n",
      "  346: Fighting Gerrymandering: Using Data Science To Draw Fairer Congressional Districts \n",
      "  774: Authenticating Node-Red Using Jsonwebtoken, Part 2 \n",
      "  423: Web Application State, À La Dogfight (1983) – Ibm Watson Data Lab \n",
      "  425: Turn Small Data Into Smart Data. Part 3 \n",
      "  831: Turn Small Data Into Smart Data. Part 1 \n",
      "\n",
      "Note: articles with high user engagement are marked with asterisks\n",
      "\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# recommendations for an active user, user_id = 60\n",
    "\n",
    "ibm_rec.make_recs(user_id=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use your content-recommendation system to make recommendations for the below scenarios based on the comments.  Again no tests are provided here, because there isn't one right answer that could be used to find these content based recommendations.\n",
    "\n",
    "**This part is NOT REQUIRED to pass this project.  However, you may choose to take this on as an extra way to show off your skills.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the IBM Data Science Platform\n",
      "==========================================================================\n",
      "\n",
      "If you are new, we recommend these popular articles:\n",
      "\n",
      "  1330: Insights From New York Car Accident Reports viewed by 467\n",
      "  1429: Use Deep Learning For Image Classification viewed by 397\n",
      "  1364: Predicting Churn With The Spss Random Tree Algorithm viewed by 388\n",
      "  1314: Healthcare Python Streaming Application Demo viewed by 345\n",
      "  1398: Total Population By Country viewed by 329\n",
      "  1431: Visualize Car Data With Brunel viewed by 320\n",
      "  1271: Customer Demographics And Sales viewed by 314\n",
      "  1427: Use Xgboost, Scikit-Learn & Ibm Watson Machine Learning Apis viewed by 308\n",
      "  43: Deep Learning With Tensorflow Course By Big Data University viewed by 299\n",
      "  1160: Analyze Accident Reports On Amazon Emr Spark viewed by 299\n",
      "  1351: Model Bike Sharing Data With Spss viewed by 288\n",
      "\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "# make recommendations for a brand new user\n",
    "\n",
    "ibm_rec.make_recs(user_id=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the IBM Data Science Platform\n",
      "==========================================================================\n",
      "\n",
      "Recommendations for Article 1427: Use Xgboost, Scikit-Learn & Ibm Watson Machine Learning Apis\n",
      "\n",
      "  253: Lifelong (Machine) Learning: How Automation Can Help Your Models Get Smarter Over Time \n",
      "  1175: Breast Cancer Detection With Xgboost, Wml And Scikit \n",
      "  685: Working With Data Flows Using  Watson Data Apis \n",
      "  893: Use The Machine Learning Library In Ibm Analytics For Apache Spark \n",
      "  51: Modern Machine Learning Algorithms \n",
      "  195: Artificial Intelligence, Ethically Speaking – Inside Machine Learning – Medium \n",
      "  784: 10 Data Science, Machine Learning And Ai Podcasts You Must Listen To \n",
      "  616: Three Reasons Machine Learning Models Go Out Of Sync \n",
      "  161: Use The Machine Learning Library In Spark \n",
      "  809: Use The Machine Learning Library \n",
      "  1420: Use Apache Systemml And Spark For Machine Learning \n",
      "  1368: Putting A Human Face On Machine Learning ****\n",
      "  74: The 3 Kinds Of Context: Machine Learning And The Art Of The Frame \n",
      "  250: Building Your First Machine Learning System  \n",
      "  412: Adoption Of Machine Learning To Software Failure Prediction \n",
      "  732: Rapidly Build Machine Learning Flows With Dsx ***\n",
      "\n",
      "Note: articles with high user engagement are marked with asterisks\n",
      "\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make a recommendations for any user who only has interacted with article id '1427.0'\n",
    "\n",
    "ibm_rec.make_recs(article_id=1427, m=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Matrix-Fact\">Part V: Matrix Factorization</a>\n",
    "\n",
    "In this part of the notebook, you will build use matrix factorization to make article recommendations to the users on the IBM Watson Studio platform.\n",
    "\n",
    "`1.` You should have already created a **user_item** matrix above in **question 1** of **Part III** above.  This first question here will just require that you run the cells to get things set up for the rest of **Part V** of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5149, 714)\n"
     ]
    }
   ],
   "source": [
    "# Load the matrix here\n",
    "user_item_matrix = pd.read_pickle('user_item_matrix.p')\n",
    "print(user_item_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0.0</th>\n",
       "      <th>100.0</th>\n",
       "      <th>1000.0</th>\n",
       "      <th>1004.0</th>\n",
       "      <th>1006.0</th>\n",
       "      <th>1008.0</th>\n",
       "      <th>101.0</th>\n",
       "      <th>1014.0</th>\n",
       "      <th>1015.0</th>\n",
       "      <th>1016.0</th>\n",
       "      <th>...</th>\n",
       "      <th>977.0</th>\n",
       "      <th>98.0</th>\n",
       "      <th>981.0</th>\n",
       "      <th>984.0</th>\n",
       "      <th>985.0</th>\n",
       "      <th>986.0</th>\n",
       "      <th>990.0</th>\n",
       "      <th>993.0</th>\n",
       "      <th>996.0</th>\n",
       "      <th>997.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0.0  100.0  1000.0  1004.0  1006.0  1008.0  101.0  1014.0  1015.0  \\\n",
       "user_id                                                                         \n",
       "1           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "2           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "3           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "4           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "5           0.0    0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0   \n",
       "\n",
       "article_id  1016.0  ...    977.0  98.0  981.0  984.0  985.0  986.0  990.0  \\\n",
       "user_id             ...                                                     \n",
       "1              0.0  ...      0.0   0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "2              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3              0.0  ...      1.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "5              0.0  ...      0.0   0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "article_id  993.0  996.0  997.0  \n",
       "user_id                          \n",
       "1             0.0    0.0    0.0  \n",
       "2             0.0    0.0    0.0  \n",
       "3             0.0    0.0    0.0  \n",
       "4             0.0    0.0    0.0  \n",
       "5             0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick look at the matrix\n",
    "user_item_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` In this situation, you can use Singular Value Decomposition from [numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html) on the user-item matrix.  Use the cell to perform SVD, and explain why this is different than in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular Value Decomposition:\n",
      "(5149, 5149) (714,) (714, 714)\n"
     ]
    }
   ],
   "source": [
    "# Perform SVD on the User-Item Matrix Here\n",
    "# use the built in to get the three matrices\n",
    "\n",
    "u, s, vt = np.linalg.svd(user_item_matrix)\n",
    "print('Singular Value Decomposition:')\n",
    "print(u.shape, s.shape, vt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Provide your response here.**\n",
    "\n",
    "SVD couldn't be performed in the lesson due to missing values in the ratings matrix. To work around this issue, we filled in the missing values with zeros for the articles. However, it's important to note that SVD interprets these zeros as an indication that we do not like the article, rather than simply not having read it. This use of 0,1 data simplifies the interaction matrix but may lead to less precise and diverse recommendations. In contrast, using ratings data allows for a more refined analysis of user preferences and can potentially result in better-quality recommendations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explained_variance(sigma, n_components):\n",
    "    \"\"\"\n",
    "    Computes explained variance number of components\n",
    "    \"\"\"\n",
    "\n",
    "    # explained variance    \n",
    "    total_var = np.sum(sigma**2)\n",
    "    var_exp = [np.square(i) for i in sigma[:n_components]]\n",
    "    perc_exp = (var_exp / total_var) \n",
    "\n",
    "    return perc_exp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "line": {
          "color": "Green",
          "width": 1.5
         },
         "mode": "linemarkers",
         "type": "scatter",
         "x": [
          1,
          6,
          11,
          16,
          21,
          26,
          31,
          36,
          41,
          46,
          51,
          56,
          61,
          66,
          71,
          76,
          81,
          86,
          91,
          96,
          101,
          106,
          111,
          116,
          121,
          126,
          131,
          136,
          141,
          146,
          151,
          156,
          161,
          166,
          171,
          176,
          181,
          186,
          191,
          196,
          201,
          206,
          211,
          216,
          221,
          226,
          231,
          236,
          241,
          246,
          251,
          256,
          261,
          266,
          271,
          276,
          281,
          286,
          291,
          296,
          301,
          306,
          311,
          316,
          321,
          326,
          331,
          336,
          341,
          346,
          351,
          356,
          361,
          366,
          371,
          376,
          381,
          386,
          391,
          396,
          401,
          406,
          411,
          416,
          421,
          426,
          431,
          436,
          441,
          446,
          451,
          456,
          461,
          466,
          471,
          476,
          481,
          486,
          491,
          496,
          501,
          506,
          511,
          516,
          521,
          526,
          531,
          536,
          541,
          546,
          551,
          556,
          561,
          566,
          571,
          576,
          581,
          586,
          591,
          596,
          601,
          606,
          611,
          616,
          621,
          626,
          631,
          636,
          641,
          646,
          651,
          656,
          661,
          666,
          671,
          676,
          681,
          686,
          691,
          696
         ],
         "y": [
          0.09094314238652484,
          0.15691532830053637,
          0.20713657924944054,
          0.25024867435366416,
          0.2886243749884571,
          0.3235850285101961,
          0.35569526844167654,
          0.3852423177615736,
          0.41279723279044195,
          0.43864064513313106,
          0.462908626911889,
          0.48559613113782585,
          0.5070564019263544,
          0.5273828515646636,
          0.5464796748614225,
          0.5644230017904449,
          0.5814202469248466,
          0.5975768288844696,
          0.6130006720339696,
          0.6277255729970137,
          0.6418988699566994,
          0.655369683083522,
          0.6682555712119794,
          0.6805262206070088,
          0.6922344214880157,
          0.7033785139751562,
          0.7140378192158818,
          0.7243939993987686,
          0.734325570298928,
          0.7439454442216112,
          0.7531706844866476,
          0.7620908500026421,
          0.7706788944688313,
          0.7789426728039912,
          0.7868958803455036,
          0.7945244052796425,
          0.8018892642411585,
          0.8089809725736521,
          0.8158196370101808,
          0.8224368754829718,
          0.828820823867678,
          0.8349816652875779,
          0.8408842848181614,
          0.8466101163740669,
          0.8521077838482314,
          0.8574331368462542,
          0.8625739026270838,
          0.8675223428047324,
          0.8723170464816421,
          0.8769444875643264,
          0.8814311047979764,
          0.8857397771873783,
          0.889916305275728,
          0.8939764654460632,
          0.8978798126117087,
          0.9016543375060736,
          0.905307779479557,
          0.9088414474040335,
          0.9122591617542595,
          0.9155870265117283,
          0.918789090927442,
          0.9218841852496473,
          0.9248896155095764,
          0.9277984546983757,
          0.9306033495943369,
          0.9333296002916126,
          0.9359701401222895,
          0.9385296383408425,
          0.9410128512934409,
          0.943421278977744,
          0.9457547649032442,
          0.9480085751265479,
          0.9501950789201278,
          0.9523276141222088,
          0.9543912802077602,
          0.9563836512480661,
          0.9583125796064691,
          0.9601707018727106,
          0.961973186213755,
          0.9637133366443598,
          0.9653920598023665,
          0.9670051212715383,
          0.9685670049103821,
          0.9700847101248524,
          0.9715519094699459,
          0.972961026916366,
          0.9743304906940056,
          0.9756451092899148,
          0.9769152675763815,
          0.9781460708067937,
          0.9793188885743968,
          0.9804501667904605,
          0.981536886970031,
          0.9825729323014816,
          0.9835682944040625,
          0.9845194158684688,
          0.9854212021204076,
          0.9862882352699092,
          0.9870995418792229,
          0.9878705696010504,
          0.9886105580116888,
          0.9893194960109846,
          0.9899930207039803,
          0.9906352294684143,
          0.9912453695772779,
          0.9918240216402997,
          0.9923766572751099,
          0.9929016950249884,
          0.9934006494140922,
          0.9938723492317382,
          0.9943233244505705,
          0.9947524391219456,
          0.9951572830307309,
          0.9955391588932978,
          0.995897189234057,
          0.9962330771925126,
          0.9965496282847484,
          0.9968434368482948,
          0.9971154095599722,
          0.9973713258478508,
          0.9976093306909198,
          0.9978290834840906,
          0.9980326842847055,
          0.998221808618502,
          0.9983980258730901,
          0.9985629940987847,
          0.9987176515680405,
          0.99886522109963,
          0.9990097162833519,
          0.9991502013890385,
          0.9992848048596525,
          0.9994076902607236,
          0.9995168952422224,
          0.9996144017349069,
          0.9996993823899828,
          0.9997736685225944,
          0.9998387425083681,
          0.9998942878894396,
          0.9999395889308933,
          0.999972489837867
         ]
        }
       ],
       "layout": {
        "height": 400,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 30,
         "t": 40
        },
        "title": "% Cumulative Variance Explained",
        "titlefont": {
         "size": 12
        },
        "width": 600,
        "xaxis": {
         "range": [
          0,
          750
         ],
         "title": "K Latent Features",
         "titlefont": {
          "size": 10
         }
        },
        "yaxis": {
         "gridwidth": null,
         "range": [
          0,
          1
         ],
         "tickfont": {
          "size": 10
         },
         "tickformat": ".0%",
         "title": "% Variance Explained",
         "titlefont": {
          "size": 12
         }
        }
       }
      },
      "text/html": [
       "<div id=\"1797bc3f-9a9b-4d82-8a13-eb90aac18968\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1797bc3f-9a9b-4d82-8a13-eb90aac18968\", [{\"type\": \"scatter\", \"x\": [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 106, 111, 116, 121, 126, 131, 136, 141, 146, 151, 156, 161, 166, 171, 176, 181, 186, 191, 196, 201, 206, 211, 216, 221, 226, 231, 236, 241, 246, 251, 256, 261, 266, 271, 276, 281, 286, 291, 296, 301, 306, 311, 316, 321, 326, 331, 336, 341, 346, 351, 356, 361, 366, 371, 376, 381, 386, 391, 396, 401, 406, 411, 416, 421, 426, 431, 436, 441, 446, 451, 456, 461, 466, 471, 476, 481, 486, 491, 496, 501, 506, 511, 516, 521, 526, 531, 536, 541, 546, 551, 556, 561, 566, 571, 576, 581, 586, 591, 596, 601, 606, 611, 616, 621, 626, 631, 636, 641, 646, 651, 656, 661, 666, 671, 676, 681, 686, 691, 696], \"y\": [0.09094314238652484, 0.15691532830053637, 0.20713657924944054, 0.25024867435366416, 0.2886243749884571, 0.3235850285101961, 0.35569526844167654, 0.3852423177615736, 0.41279723279044195, 0.43864064513313106, 0.462908626911889, 0.48559613113782585, 0.5070564019263544, 0.5273828515646636, 0.5464796748614225, 0.5644230017904449, 0.5814202469248466, 0.5975768288844696, 0.6130006720339696, 0.6277255729970137, 0.6418988699566994, 0.655369683083522, 0.6682555712119794, 0.6805262206070088, 0.6922344214880157, 0.7033785139751562, 0.7140378192158818, 0.7243939993987686, 0.734325570298928, 0.7439454442216112, 0.7531706844866476, 0.7620908500026421, 0.7706788944688313, 0.7789426728039912, 0.7868958803455036, 0.7945244052796425, 0.8018892642411585, 0.8089809725736521, 0.8158196370101808, 0.8224368754829718, 0.828820823867678, 0.8349816652875779, 0.8408842848181614, 0.8466101163740669, 0.8521077838482314, 0.8574331368462542, 0.8625739026270838, 0.8675223428047324, 0.8723170464816421, 0.8769444875643264, 0.8814311047979764, 0.8857397771873783, 0.889916305275728, 0.8939764654460632, 0.8978798126117087, 0.9016543375060736, 0.905307779479557, 0.9088414474040335, 0.9122591617542595, 0.9155870265117283, 0.918789090927442, 0.9218841852496473, 0.9248896155095764, 0.9277984546983757, 0.9306033495943369, 0.9333296002916126, 0.9359701401222895, 0.9385296383408425, 0.9410128512934409, 0.943421278977744, 0.9457547649032442, 0.9480085751265479, 0.9501950789201278, 0.9523276141222088, 0.9543912802077602, 0.9563836512480661, 0.9583125796064691, 0.9601707018727106, 0.961973186213755, 0.9637133366443598, 0.9653920598023665, 0.9670051212715383, 0.9685670049103821, 0.9700847101248524, 0.9715519094699459, 0.972961026916366, 0.9743304906940056, 0.9756451092899148, 0.9769152675763815, 0.9781460708067937, 0.9793188885743968, 0.9804501667904605, 0.981536886970031, 0.9825729323014816, 0.9835682944040625, 0.9845194158684688, 0.9854212021204076, 0.9862882352699092, 0.9870995418792229, 0.9878705696010504, 0.9886105580116888, 0.9893194960109846, 0.9899930207039803, 0.9906352294684143, 0.9912453695772779, 0.9918240216402997, 0.9923766572751099, 0.9929016950249884, 0.9934006494140922, 0.9938723492317382, 0.9943233244505705, 0.9947524391219456, 0.9951572830307309, 0.9955391588932978, 0.995897189234057, 0.9962330771925126, 0.9965496282847484, 0.9968434368482948, 0.9971154095599722, 0.9973713258478508, 0.9976093306909198, 0.9978290834840906, 0.9980326842847055, 0.998221808618502, 0.9983980258730901, 0.9985629940987847, 0.9987176515680405, 0.99886522109963, 0.9990097162833519, 0.9991502013890385, 0.9992848048596525, 0.9994076902607236, 0.9995168952422224, 0.9996144017349069, 0.9996993823899828, 0.9997736685225944, 0.9998387425083681, 0.9998942878894396, 0.9999395889308933, 0.999972489837867], \"mode\": \"linemarkers\", \"line\": {\"color\": \"Green\", \"width\": 1.5}}], {\"width\": 600, \"height\": 400, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"title\": \"% Cumulative Variance Explained\", \"titlefont\": {\"size\": 12}, \"yaxis\": {\"title\": \"% Variance Explained\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"tickformat\": \".0%\", \"gridwidth\": null, \"range\": [0, 1]}, \"xaxis\": {\"title\": \"K Latent Features\", \"titlefont\": {\"size\": 10}, \"range\": [0, 750]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"1797bc3f-9a9b-4d82-8a13-eb90aac18968\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1797bc3f-9a9b-4d82-8a13-eb90aac18968\", [{\"type\": \"scatter\", \"x\": [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101, 106, 111, 116, 121, 126, 131, 136, 141, 146, 151, 156, 161, 166, 171, 176, 181, 186, 191, 196, 201, 206, 211, 216, 221, 226, 231, 236, 241, 246, 251, 256, 261, 266, 271, 276, 281, 286, 291, 296, 301, 306, 311, 316, 321, 326, 331, 336, 341, 346, 351, 356, 361, 366, 371, 376, 381, 386, 391, 396, 401, 406, 411, 416, 421, 426, 431, 436, 441, 446, 451, 456, 461, 466, 471, 476, 481, 486, 491, 496, 501, 506, 511, 516, 521, 526, 531, 536, 541, 546, 551, 556, 561, 566, 571, 576, 581, 586, 591, 596, 601, 606, 611, 616, 621, 626, 631, 636, 641, 646, 651, 656, 661, 666, 671, 676, 681, 686, 691, 696], \"y\": [0.09094314238652484, 0.15691532830053637, 0.20713657924944054, 0.25024867435366416, 0.2886243749884571, 0.3235850285101961, 0.35569526844167654, 0.3852423177615736, 0.41279723279044195, 0.43864064513313106, 0.462908626911889, 0.48559613113782585, 0.5070564019263544, 0.5273828515646636, 0.5464796748614225, 0.5644230017904449, 0.5814202469248466, 0.5975768288844696, 0.6130006720339696, 0.6277255729970137, 0.6418988699566994, 0.655369683083522, 0.6682555712119794, 0.6805262206070088, 0.6922344214880157, 0.7033785139751562, 0.7140378192158818, 0.7243939993987686, 0.734325570298928, 0.7439454442216112, 0.7531706844866476, 0.7620908500026421, 0.7706788944688313, 0.7789426728039912, 0.7868958803455036, 0.7945244052796425, 0.8018892642411585, 0.8089809725736521, 0.8158196370101808, 0.8224368754829718, 0.828820823867678, 0.8349816652875779, 0.8408842848181614, 0.8466101163740669, 0.8521077838482314, 0.8574331368462542, 0.8625739026270838, 0.8675223428047324, 0.8723170464816421, 0.8769444875643264, 0.8814311047979764, 0.8857397771873783, 0.889916305275728, 0.8939764654460632, 0.8978798126117087, 0.9016543375060736, 0.905307779479557, 0.9088414474040335, 0.9122591617542595, 0.9155870265117283, 0.918789090927442, 0.9218841852496473, 0.9248896155095764, 0.9277984546983757, 0.9306033495943369, 0.9333296002916126, 0.9359701401222895, 0.9385296383408425, 0.9410128512934409, 0.943421278977744, 0.9457547649032442, 0.9480085751265479, 0.9501950789201278, 0.9523276141222088, 0.9543912802077602, 0.9563836512480661, 0.9583125796064691, 0.9601707018727106, 0.961973186213755, 0.9637133366443598, 0.9653920598023665, 0.9670051212715383, 0.9685670049103821, 0.9700847101248524, 0.9715519094699459, 0.972961026916366, 0.9743304906940056, 0.9756451092899148, 0.9769152675763815, 0.9781460708067937, 0.9793188885743968, 0.9804501667904605, 0.981536886970031, 0.9825729323014816, 0.9835682944040625, 0.9845194158684688, 0.9854212021204076, 0.9862882352699092, 0.9870995418792229, 0.9878705696010504, 0.9886105580116888, 0.9893194960109846, 0.9899930207039803, 0.9906352294684143, 0.9912453695772779, 0.9918240216402997, 0.9923766572751099, 0.9929016950249884, 0.9934006494140922, 0.9938723492317382, 0.9943233244505705, 0.9947524391219456, 0.9951572830307309, 0.9955391588932978, 0.995897189234057, 0.9962330771925126, 0.9965496282847484, 0.9968434368482948, 0.9971154095599722, 0.9973713258478508, 0.9976093306909198, 0.9978290834840906, 0.9980326842847055, 0.998221808618502, 0.9983980258730901, 0.9985629940987847, 0.9987176515680405, 0.99886522109963, 0.9990097162833519, 0.9991502013890385, 0.9992848048596525, 0.9994076902607236, 0.9995168952422224, 0.9996144017349069, 0.9996993823899828, 0.9997736685225944, 0.9998387425083681, 0.9998942878894396, 0.9999395889308933, 0.999972489837867], \"mode\": \"linemarkers\", \"line\": {\"color\": \"Green\", \"width\": 1.5}}], {\"width\": 600, \"height\": 400, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"title\": \"% Cumulative Variance Explained\", \"titlefont\": {\"size\": 12}, \"yaxis\": {\"title\": \"% Variance Explained\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"tickformat\": \".0%\", \"gridwidth\": null, \"range\": [0, 1]}, \"xaxis\": {\"title\": \"K Latent Features\", \"titlefont\": {\"size\": 10}, \"range\": [0, 750]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# How much each K latent factor explains variability in the data\n",
    "\n",
    "klatent = []\n",
    "cumvar = []\n",
    "for k in range(1,700,5):\n",
    "    klatent.append(k)\n",
    "    cumvar.append(np.sum(explained_variance(s,k)))\n",
    "\n",
    "trace = go.Scatter(\n",
    "        x= klatent,\n",
    "        y= cumvar,            \n",
    "        mode='linemarkers',\n",
    "        line=dict(color='Green', width=1.5)\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "        width = 600,\n",
    "        height = 400,\n",
    "        margin = dict(l=50, r=30, t=40, b=50), \n",
    "        title = '% Cumulative Variance Explained',    \n",
    "        titlefont = dict(size=12),    \n",
    "        yaxis = {\n",
    "                'title': '% Variance Explained',\n",
    "                'titlefont': dict(size=12),\n",
    "                'tickfont' : dict(size=10),\n",
    "                'tickformat': '.0%',\n",
    "                'gridwidth': None,\n",
    "                'range': [0,1]\n",
    "        },\n",
    "        xaxis = {\n",
    "                'title': 'K Latent Features', \n",
    "                'titlefont': dict(size=10),\n",
    "                'range': [0,750]\n",
    "        }\n",
    "    )   \n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now for the tricky part, how do we choose the number of latent features to use?  Running the below cell, you can see that as the number of latent features increases, we obtain a lower error rate on making predictions for the 1 and 0 values in the user-item matrix.  Run the cell below to get an idea of how the accuracy improves as we increase the number of latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "line": {
          "color": "Orange",
          "width": 1.5
         },
         "mode": "linemarkers",
         "name": "Training Error",
         "type": "scatter",
         "x": [
          10,
          30,
          50,
          70,
          90,
          110,
          130,
          150,
          170,
          190,
          210,
          230,
          250,
          270,
          290,
          310,
          330,
          350,
          370,
          390,
          410,
          430,
          450,
          470,
          490,
          510,
          530,
          550,
          570,
          590,
          610,
          630,
          650,
          670,
          690
         ],
         "y": [
          0.33492053138521083,
          0.47518100580523126,
          0.5620420498771552,
          0.6413584675928945,
          0.7043897984475899,
          0.7508968756115061,
          0.7925553888635227,
          0.829321853325506,
          0.8561520231339552,
          0.8770682495162307,
          0.8967668993107647,
          0.9142260778814167,
          0.9276194203465745,
          0.9400126106146588,
          0.9493836018524558,
          0.9579936077229143,
          0.9645815667601592,
          0.9711477833583372,
          0.976322483856239,
          0.9812797599634727,
          0.9843671863109603,
          0.9877372643663166,
          0.9901071902245994,
          0.992498858521949,
          0.994368708281695,
          0.9959993912117061,
          0.9967821190181114,
          0.997890983410519,
          0.9986084838997239,
          0.9991085599982606,
          0.9995868936577306,
          0.9996738634139978,
          0.9999565151218663,
          1,
          1
         ]
        }
       ],
       "layout": {
        "height": 400,
        "margin": {
         "b": 50,
         "l": 50,
         "r": 30,
         "t": 40
        },
        "title": "Accuracy vs Number of SVD Latent Features",
        "titlefont": {
         "size": 12
        },
        "width": 600,
        "xaxis": {
         "range": [
          0,
          750
         ],
         "title": "K Latent Features",
         "titlefont": {
          "size": 10
         }
        },
        "yaxis": {
         "gridwidth": null,
         "range": [
          0,
          1
         ],
         "tickfont": {
          "size": 10
         },
         "tickformat": ".0%",
         "title": "% Accuracy",
         "titlefont": {
          "size": 12
         }
        }
       }
      },
      "text/html": [
       "<div id=\"b6891cbe-7633-464f-ab38-26323ab42960\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"b6891cbe-7633-464f-ab38-26323ab42960\", [{\"type\": \"scatter\", \"x\": [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470, 490, 510, 530, 550, 570, 590, 610, 630, 650, 670, 690], \"y\": [0.33492053138521083, 0.47518100580523126, 0.5620420498771552, 0.6413584675928945, 0.7043897984475899, 0.7508968756115061, 0.7925553888635227, 0.829321853325506, 0.8561520231339552, 0.8770682495162307, 0.8967668993107647, 0.9142260778814167, 0.9276194203465745, 0.9400126106146588, 0.9493836018524558, 0.9579936077229143, 0.9645815667601592, 0.9711477833583372, 0.976322483856239, 0.9812797599634727, 0.9843671863109603, 0.9877372643663166, 0.9901071902245994, 0.992498858521949, 0.994368708281695, 0.9959993912117061, 0.9967821190181114, 0.997890983410519, 0.9986084838997239, 0.9991085599982606, 0.9995868936577306, 0.9996738634139978, 0.9999565151218663, 1.0, 1.0], \"mode\": \"linemarkers\", \"line\": {\"color\": \"Orange\", \"width\": 1.5}, \"name\": \"Training Error\"}], {\"width\": 600, \"height\": 400, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"title\": \"Accuracy vs Number of SVD Latent Features\", \"titlefont\": {\"size\": 12}, \"yaxis\": {\"title\": \"% Accuracy\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"tickformat\": \".0%\", \"gridwidth\": null, \"range\": [0, 1]}, \"xaxis\": {\"title\": \"K Latent Features\", \"titlefont\": {\"size\": 10}, \"range\": [0, 750]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"b6891cbe-7633-464f-ab38-26323ab42960\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"b6891cbe-7633-464f-ab38-26323ab42960\", [{\"type\": \"scatter\", \"x\": [10, 30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250, 270, 290, 310, 330, 350, 370, 390, 410, 430, 450, 470, 490, 510, 530, 550, 570, 590, 610, 630, 650, 670, 690], \"y\": [0.33492053138521083, 0.47518100580523126, 0.5620420498771552, 0.6413584675928945, 0.7043897984475899, 0.7508968756115061, 0.7925553888635227, 0.829321853325506, 0.8561520231339552, 0.8770682495162307, 0.8967668993107647, 0.9142260778814167, 0.9276194203465745, 0.9400126106146588, 0.9493836018524558, 0.9579936077229143, 0.9645815667601592, 0.9711477833583372, 0.976322483856239, 0.9812797599634727, 0.9843671863109603, 0.9877372643663166, 0.9901071902245994, 0.992498858521949, 0.994368708281695, 0.9959993912117061, 0.9967821190181114, 0.997890983410519, 0.9986084838997239, 0.9991085599982606, 0.9995868936577306, 0.9996738634139978, 0.9999565151218663, 1.0, 1.0], \"mode\": \"linemarkers\", \"line\": {\"color\": \"Orange\", \"width\": 1.5}, \"name\": \"Training Error\"}], {\"width\": 600, \"height\": 400, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"title\": \"Accuracy vs Number of SVD Latent Features\", \"titlefont\": {\"size\": 12}, \"yaxis\": {\"title\": \"% Accuracy\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"tickformat\": \".0%\", \"gridwidth\": null, \"range\": [0, 1]}, \"xaxis\": {\"title\": \"K Latent Features\", \"titlefont\": {\"size\": 10}, \"range\": [0, 750]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_latent_feats = np.arange(10,700+10,20)\n",
    "sum_errs = []\n",
    "\n",
    "for k in num_latent_feats:\n",
    "    # restructure with k latent features\n",
    "    s_new, u_new, vt_new = np.diag(s[:k]), u[:, :k], vt[:k, :]\n",
    "    \n",
    "    # take dot product\n",
    "    user_item_est = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    # compute error for each prediction to actual value\n",
    "    diffs = np.subtract(user_item_matrix, user_item_est)\n",
    "    \n",
    "    # total errors and keep track of them\n",
    "    err = np.sum(np.sum(np.abs(diffs)))\n",
    "    sum_errs.append(err)\n",
    "\n",
    "trace = go.Scatter(\n",
    "        x=num_latent_feats,\n",
    "        y= 1 - (np.array(sum_errs)/df.shape[0]),            \n",
    "        mode='linemarkers',\n",
    "        line=dict(color='Orange', width=1.5),\n",
    "        name='Training Error'\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "        width = 600,\n",
    "        height = 400,\n",
    "        margin = dict(l=50, r=30, t=40, b=50), \n",
    "        title = 'Accuracy vs Number of SVD Latent Features',    \n",
    "        titlefont = dict(size=12),    \n",
    "        yaxis = {\n",
    "                'title': '% Accuracy',\n",
    "                'titlefont': dict(size=12),\n",
    "                'tickfont' : dict(size=10),\n",
    "                'tickformat': '.0%',\n",
    "                'gridwidth': None,\n",
    "                'range': [0,1]\n",
    "        },\n",
    "        xaxis = {\n",
    "                'title': 'K Latent Features', \n",
    "                'titlefont': dict(size=10),\n",
    "                'range': [0,750]\n",
    "        }\n",
    "    )   \n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note: There is a clear correlation between the graph of cumulative explained variance and the percentage accuracy of SVD predictions. As the number of latent factors (k) increases, it leads to a better explanation of the data, which, in turn, translates to higher accuracy in predictions. The two metrics show a parallel improvement trend, highlighting the importance of selecting an optimal number of latent factors to balance model complexity and predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` From the above, we can't really be sure how many features to use, because simply having a better way to predict the 1's and 0's of the matrix doesn't exactly give us an indication of if we are able to make good recommendations.  Instead, we might split our dataset into a training and test set of data, as shown in the cell below.  \n",
    "\n",
    "Use the code from question 3 to understand the impact on accuracy of the training and test sets of data with different numbers of latent features. Using the split below: \n",
    "\n",
    "* How many users can we make predictions for in the test set?  \n",
    "* How many users are we not able to make predictions for because of the cold start problem?\n",
    "* How many articles can we make predictions for in the test set?  \n",
    "* How many articles are we not able to make predictions for because of the cold start problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df.head(40000)\n",
    "df_test = df.tail(5993)\n",
    "\n",
    "def create_test_and_train_user_item(df_train, df_test):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df_train - training dataframe\n",
    "    df_test - test dataframe\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_item_train - a user-item matrix of the training dataframe \n",
    "                      (unique users for each row and unique articles for each column)\n",
    "    user_item_test - a user-item matrix of the testing dataframe \n",
    "                    (unique users for each row and unique articles for each column)\n",
    "    test_idx - all of the test user ids\n",
    "    test_arts - all of the test article ids\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    user_item_train = df_train.groupby(['user_id', 'article_id'])['user_id'].nunique().unstack().fillna(0)\n",
    "    user_item_test = df_test.groupby(['user_id', 'article_id'])['user_id'].nunique().unstack().fillna(0)\n",
    "\n",
    "    test_idx = list(df_test.user_id.unique())\n",
    "    test_arts = list(df_test.article_id.unique())\n",
    "        \n",
    "    return user_item_train, user_item_test, test_idx, test_arts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training User-Item: (4487, 714)\n",
      "Test User-Item: (682, 574)\n"
     ]
    }
   ],
   "source": [
    "user_item_train, user_item_test, test_idx, test_arts = create_test_and_train_user_item(df_train, df_test)\n",
    "print('Training User-Item:',  user_item_train.shape)\n",
    "print('Test User-Item:', user_item_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Users in Test data: 682\n",
      "Unseen Users in Test data: 662\n",
      "Unique Articles in Test data: 574\n",
      "Overlaps in Training and Test: 20\n"
     ]
    }
   ],
   "source": [
    "# total test users\n",
    "print('Unique Users in Test data:', user_item_test.shape[0])\n",
    "\n",
    "# articles not present in training dataset - new users\n",
    "print('Unseen Users in Test data:', len(np.setdiff1d(user_item_test.index, user_item_train.index)))\n",
    "\n",
    "# unique articles\n",
    "print('Unique Articles in Test data:', len(test_arts))\n",
    "\n",
    "# overlaps in training and test datasets\n",
    "print('Overlaps in Training and Test:', len(np.intersect1d(user_item_test.index, user_item_train.index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome job!  That's right!  All of the test articles are in the training data, but there are only 20 test users that were also in the training set.  All of the other users that are in the test set we have no data on.  Therefore, we cannot make predictions for these users using SVD.\n"
     ]
    }
   ],
   "source": [
    "# Replace the values in the dictionary below\n",
    "a = 662 \n",
    "b = 574 \n",
    "c = 20 \n",
    "d = 0 \n",
    "\n",
    "sol_4_dict = {\n",
    "    'How many users can we make predictions for in the test set?': c, \n",
    "    'How many users in the test set are we not able to make predictions for because of the cold start problem?': a, \n",
    "    'How many articles can we make predictions for in the test set?': b,\n",
    "    'How many articles in the test set are we not able to make predictions for because of the cold start problem?':d \n",
    "}\n",
    "\n",
    "t.sol_4_test(sol_4_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` Now use the **user_item_train** dataset from above to find U, S, and V transpose using SVD. Then find the subset of rows in the **user_item_test** dataset that you can predict using this matrix decomposition with different numbers of latent features to see how many features makes sense to keep based on the accuracy on the test data. This will require combining what was done in questions `2` - `4`.\n",
    "\n",
    "Use the cells below to explore how well SVD works towards making predictions for recommendations on the test data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following exercise focuses on evaluating a recommendation system that employs Singular Value Decomposition (SVD) on both training and test datasets. SVD is used to create a model capable of predicting user-article interactions. Here's how it operates:\n",
    "\n",
    "First, the SVD model is constructed using the training dataset. The objective is to uncover underlying patterns in user behavior, with the aim of predicting which articles users are likely to interact with.\n",
    "\n",
    "Next, the code applies these predictions to both the full training dataset and a subset of the training dataset that exclusively includes users common to both the training and test datasets. These predictions serve as the test predictions and will be compared against a subset of the test dataset containing common users.\n",
    "\n",
    "Therefore, this code is responsible for identifying these common users and forming two subsets: one for the test dataset and another for the U, S, and V decompositions of the training dataset, all based on the common elements shared between the datasets.\n",
    "\n",
    "Finally, the code calculates the error by comparing the predictions with the actual user-interactions. This process is iterated for various levels of k latent factors. In this context, k represents the number of latent factors used in the dot product multiplication of U, S, and Vt, but it's important to note that this multiplication is performed for only a subset of k factors.\n",
    "\n",
    "The purpose of this iteration is to assess how the choice of k influences the accuracy of the predictions. By varying the number of latent factors, the code evaluates the impact on prediction quality and helps determine the optimal value of k for the recommendation system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train U: (4487, 4487) Train S: (714,) Train VT: (714, 714) \n",
      "\n",
      "Common Users: 20 Common Articles: 574\n",
      "Int64Index([2917, 3024, 3093, 3193, 3527, 3532, 3684, 3740, 3777, 3801, 3968,\n",
      "            3989, 3990, 3998, 4002, 4204, 4231, 4274, 4293, 4487],\n",
      "           dtype='int64') \n",
      "\n",
      "Test Common Subset: (20, 574)\n",
      "Common User Index: 4487 Common Article Index: 714\n",
      "[False False False ..., False False  True] \n",
      "\n",
      "Train U Subset: (20, 4487) Train VT Subset: (714, 574) \n",
      "\n",
      "No Latent Features: 71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit SVD on the user_item_train matrix\n",
    "# fit svd similar to above then use the cells below\n",
    "\n",
    "def svd_get(user_item):\n",
    "    \"\"\"\n",
    "    Perform Singular Value Decomposition (SVD) on a user-item matrix.\n",
    "\n",
    "    INPUT:\n",
    "    user_item - (pandas DataFrame) A user-item matrix with users as rows and items as columns\n",
    "\n",
    "    OUTPUT:\n",
    "    u - (numpy array) Left singular vectors of the decomposition\n",
    "    s - (numpy array) Singular values\n",
    "    vt - (numpy array) Right singular vectors (transposed)\n",
    "    \"\"\"\n",
    "\n",
    "    u, s, vt = np.linalg.svd(user_item, full_matrices=True)    \n",
    "    \n",
    "    return u, s, vt\n",
    "\n",
    "    \n",
    "# Use these cells to see how well you can use the training \n",
    "# decomposition to predict on test data\n",
    "\n",
    "# Fit SVD decomposition for Train\n",
    "u_train, s_train, vt_train =  svd_get(user_item_train)\n",
    "print('Train U:', u_train.shape, 'Train S:', s_train.shape, 'Train VT:',vt_train.shape,'\\n')\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Identify common users and articles\n",
    "common_users = user_item_train.index.intersection(test_idx)\n",
    "common_articles = user_item_train.columns.intersection(test_arts)\n",
    "print('Common Users:', len(common_users), 'Common Articles:', len(common_articles))\n",
    "print(common_users, '\\n')\n",
    "\n",
    "# Reshape test set to keep only users that we can make predictions for\n",
    "# We will then compare the test predictions with this actual test subset\n",
    "user_item_test_subset = user_item_test.loc[common_users, common_articles]\n",
    "print('Test Common Subset:', user_item_test_subset.shape)\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Identify commonn user and column indices in Train\n",
    "train_row_idx = user_item_train.index.isin(test_idx)\n",
    "train_col_idx = user_item_train.columns.isin(test_arts)\n",
    "print('Common User Index:', len(train_row_idx), 'Common Article Index:', len(train_col_idx))\n",
    "print(train_row_idx, '\\n')\n",
    "\n",
    "# Create u_test to have only users and articles that we can make predictions for\n",
    "u_test = u_train[train_row_idx, :]\n",
    "vt_test = vt_train[:, train_col_idx]\n",
    "print('Train U Subset:', u_test.shape, 'Train VT Subset:', vt_test.shape,'\\n')\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "num_latent_feats = np.arange(5,710,10)\n",
    "print('No Latent Features:', len(num_latent_feats))\n",
    "\n",
    "\n",
    "def svd_kpredict(u, s, vt, k):\n",
    "    \"\"\"\n",
    "    Generate predictions using SVD matrices with a specified number of latent features.\n",
    "\n",
    "    INPUT:\n",
    "    u - (numpy array) Left singular vectors of the decomposition\n",
    "    s - (numpy array) Singular values\n",
    "    vt - (numpy array) Right singular vectors (transposed)\n",
    "    k - (int) Number of latent features to use\n",
    "\n",
    "    OUTPUT:\n",
    "    svd_predict - (numpy array) Predicted ratings/interactions matrix\n",
    "    \"\"\"\n",
    "\n",
    "    u_new, s_new, vt_new = u[:, :k], np.diag(s[:k]), vt[:k, :]\n",
    "    svd_predict = np.around(np.dot(np.dot(u_new, s_new), vt_new))\n",
    "    \n",
    "    return svd_predict\n",
    "\n",
    "\n",
    "def svd_error(user_item, user_item_predict):\n",
    "    \"\"\"\n",
    "    Calculate the sum of absolute errors between the actual and predicted user-item matrices.\n",
    "\n",
    "    INPUT:\n",
    "    user_item - (pandas DataFrame/numpy array) Actual user-item matrix\n",
    "    user_item_predict - (numpy array) Predicted user-item matrix\n",
    "\n",
    "    OUTPUT:\n",
    "    svd_error - (float) Total sum of absolute errors\n",
    "    \"\"\"\n",
    "\n",
    "    error = np.subtract(user_item, user_item_predict).sum()\n",
    "    svd_error = np.sum(np.abs(error))\n",
    "\n",
    "    return np.sum(svd_error)\n",
    "\n",
    "\n",
    "def svd_performance(u_train, s_train, vt_train, u_test, vt_test, user_item_train, user_item_subset, num_latent_feats):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of SVD predictions for a range of latent features on both training and test datasets.\n",
    "\n",
    "    INPUT:\n",
    "    u_train - (numpy array) U matrix from SVD (training data)\n",
    "    s_train - (numpy array) Sigma matrix from SVD (training data)\n",
    "    vt_train - (numpy array) VT matrix from SVD (training data)\n",
    "    u_test - (numpy array) U matrix for subset of training users\n",
    "    vt_test - (numpy array) VT matrix for subset of training articles\n",
    "    user_item_train - (pandas DataFrame) Training user-item matrix\n",
    "    user_item_subset - (pandas DataFrame) Subset of the user-item matrix for test prediction\n",
    "    #users_to_predict - (list) List of users to make predictions for\n",
    "    num_latent_feats - (numpy array) Range of latent feature numbers to evaluate\n",
    "\n",
    "    OUTPUT:\n",
    "    k_train_error - (list) List of total prediction errors for each number of latent features (training set)\n",
    "    k_test_error - (list) List of total prediction errors for each number of latent features (test set)\n",
    "    \"\"\"\n",
    "    \n",
    "    k_train_error = []\n",
    "    k_test_error = []\n",
    "\n",
    "    for k in num_latent_feats: \n",
    "        # Make predictions by taking the dot product\n",
    "        user_item_train_preds = svd_kpredict(u_train, s_train, vt_train, k)\n",
    "        user_item_test_preds = svd_kpredict(u_test, s_train, vt_test, k)\n",
    "\n",
    "        # Compute prediction errors\n",
    "        train_error = svd_error(user_item_train, user_item_train_preds)\n",
    "        test_error = svd_error(user_item_subset, user_item_test_preds)        \n",
    "\n",
    "        k_train_error.append(train_error)\n",
    "        k_test_error.append(test_error)\n",
    "\n",
    "    return k_train_error, k_test_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "line": {
          "color": "DarkSlateGrey",
          "width": 1.5
         },
         "mode": "linemarkers",
         "name": "Training Accuracy",
         "type": "scatter",
         "x": [
          5,
          15,
          25,
          35,
          45,
          55,
          65,
          75,
          85,
          95,
          105,
          115,
          125,
          135,
          145,
          155,
          165,
          175,
          185,
          195,
          205,
          215,
          225,
          235,
          245,
          255,
          265,
          275,
          285,
          295,
          305,
          315,
          325,
          335,
          345,
          355,
          365,
          375,
          385,
          395,
          405,
          415,
          425,
          435,
          445,
          455,
          465,
          475,
          485,
          495,
          505,
          515,
          525,
          535,
          545,
          555,
          565,
          575,
          585,
          595,
          605,
          615,
          625,
          635,
          645,
          655,
          665,
          675,
          685,
          695,
          705
         ],
         "y": [
          0.327325,
          0.406975,
          0.46482500000000004,
          0.515425,
          0.5514749999999999,
          0.5937,
          0.631325,
          0.6644749999999999,
          0.695025,
          0.72235,
          0.746975,
          0.768325,
          0.78935,
          0.807975,
          0.82495,
          0.8383,
          0.85245,
          0.8634999999999999,
          0.874825,
          0.88565,
          0.8958,
          0.90445,
          0.912675,
          0.920425,
          0.92815,
          0.933975,
          0.94065,
          0.94545,
          0.9499,
          0.95475,
          0.958575,
          0.9615,
          0.965025,
          0.968,
          0.97075,
          0.972675,
          0.9753000000000001,
          0.978625,
          0.98135,
          0.983225,
          0.984475,
          0.98585,
          0.9874,
          0.988675,
          0.9899249999999999,
          0.991,
          0.991925,
          0.9929,
          0.99385,
          0.994625,
          0.99505,
          0.99585,
          0.996725,
          0.99725,
          0.997825,
          0.998325,
          0.998675,
          0.9989,
          0.99915,
          0.9994,
          0.99945,
          0.999475,
          0.999575,
          0.9998,
          0.999875,
          0.999975,
          1,
          1,
          1,
          1,
          1
         ]
        },
        {
         "line": {
          "color": "Red",
          "width": 1.5
         },
         "mode": "linemarkers",
         "name": "Test Accuracy",
         "type": "scatter",
         "x": [
          5,
          15,
          25,
          35,
          45,
          55,
          65,
          75,
          85,
          95,
          105,
          115,
          125,
          135,
          145,
          155,
          165,
          175,
          185,
          195,
          205,
          215,
          225,
          235,
          245,
          255,
          265,
          275,
          285,
          295,
          305,
          315,
          325,
          335,
          345,
          355,
          365,
          375,
          385,
          395,
          405,
          415,
          425,
          435,
          445,
          455,
          465,
          475,
          485,
          495,
          505,
          515,
          525,
          535,
          545,
          555,
          565,
          575,
          585,
          595,
          605,
          615,
          625,
          635,
          645,
          655,
          665,
          675,
          685,
          695,
          705
         ],
         "y": [
          0.3457943925233645,
          0.37071651090342683,
          0.36760124610591904,
          0.37071651090342683,
          0.36448598130841126,
          0.36448598130841126,
          0.3520249221183801,
          0.3302180685358256,
          0.33333333333333337,
          0.32398753894081,
          0.2990654205607477,
          0.28660436137071654,
          0.2928348909657321,
          0.28971962616822433,
          0.28037383177570097,
          0.2710280373831776,
          0.26168224299065423,
          0.25545171339563866,
          0.23676012461059193,
          0.22741433021806856,
          0.2180685358255452,
          0.20249221183800625,
          0.20249221183800625,
          0.19937694704049846,
          0.1931464174454829,
          0.1869158878504673,
          0.18380062305295952,
          0.17757009345794394,
          0.17757009345794394,
          0.17133956386292837,
          0.1651090342679128,
          0.1651090342679128,
          0.1651090342679128,
          0.1651090342679128,
          0.15887850467289721,
          0.15887850467289721,
          0.15887850467289721,
          0.15576323987538943,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164,
          0.15264797507788164
         ]
        }
       ],
       "layout": {
        "height": 400,
        "legend": {
         "font": {
          "size": 10
         },
         "x": 0.8,
         "xanchor": "center",
         "y": 0.8,
         "yanchor": "middle"
        },
        "margin": {
         "b": 50,
         "l": 50,
         "r": 30,
         "t": 40
        },
        "title": "Accuracy vs Number of SVD Latent Features",
        "titlefont": {
         "size": 12
        },
        "width": 600,
        "xaxis": {
         "range": [
          0,
          750
         ],
         "title": "K Latent Features",
         "titlefont": {
          "size": 10
         }
        },
        "yaxis": {
         "gridwidth": null,
         "range": [
          0,
          1
         ],
         "tickfont": {
          "size": 10
         },
         "tickformat": ".0%",
         "title": "% Accuracy",
         "titlefont": {
          "size": 12
         }
        }
       }
      },
      "text/html": [
       "<div id=\"806ad64f-afc5-4b8e-8fd6-17b722d3717f\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"806ad64f-afc5-4b8e-8fd6-17b722d3717f\", [{\"type\": \"scatter\", \"x\": [5, 15, 25, 35, 45, 55, 65, 75, 85, 95, 105, 115, 125, 135, 145, 155, 165, 175, 185, 195, 205, 215, 225, 235, 245, 255, 265, 275, 285, 295, 305, 315, 325, 335, 345, 355, 365, 375, 385, 395, 405, 415, 425, 435, 445, 455, 465, 475, 485, 495, 505, 515, 525, 535, 545, 555, 565, 575, 585, 595, 605, 615, 625, 635, 645, 655, 665, 675, 685, 695, 705], \"y\": [0.327325, 0.406975, 0.46482500000000004, 0.515425, 0.5514749999999999, 0.5937, 0.631325, 0.6644749999999999, 0.695025, 0.72235, 0.746975, 0.768325, 0.78935, 0.807975, 0.82495, 0.8383, 0.85245, 0.8634999999999999, 0.874825, 0.88565, 0.8958, 0.90445, 0.912675, 0.920425, 0.92815, 0.933975, 0.94065, 0.94545, 0.9499, 0.95475, 0.958575, 0.9615, 0.965025, 0.968, 0.97075, 0.972675, 0.9753000000000001, 0.978625, 0.98135, 0.983225, 0.984475, 0.98585, 0.9874, 0.988675, 0.9899249999999999, 0.991, 0.991925, 0.9929, 0.99385, 0.994625, 0.99505, 0.99585, 0.996725, 0.99725, 0.997825, 0.998325, 0.998675, 0.9989, 0.99915, 0.9994, 0.99945, 0.999475, 0.999575, 0.9998, 0.999875, 0.999975, 1.0, 1.0, 1.0, 1.0, 1.0], \"mode\": \"linemarkers\", \"line\": {\"color\": \"DarkSlateGrey\", \"width\": 1.5}, \"name\": \"Training Accuracy\"}, {\"type\": \"scatter\", \"x\": [5, 15, 25, 35, 45, 55, 65, 75, 85, 95, 105, 115, 125, 135, 145, 155, 165, 175, 185, 195, 205, 215, 225, 235, 245, 255, 265, 275, 285, 295, 305, 315, 325, 335, 345, 355, 365, 375, 385, 395, 405, 415, 425, 435, 445, 455, 465, 475, 485, 495, 505, 515, 525, 535, 545, 555, 565, 575, 585, 595, 605, 615, 625, 635, 645, 655, 665, 675, 685, 695, 705], \"y\": [0.3457943925233645, 0.37071651090342683, 0.36760124610591904, 0.37071651090342683, 0.36448598130841126, 0.36448598130841126, 0.3520249221183801, 0.3302180685358256, 0.33333333333333337, 0.32398753894081, 0.2990654205607477, 0.28660436137071654, 0.2928348909657321, 0.28971962616822433, 0.28037383177570097, 0.2710280373831776, 0.26168224299065423, 0.25545171339563866, 0.23676012461059193, 0.22741433021806856, 0.2180685358255452, 0.20249221183800625, 0.20249221183800625, 0.19937694704049846, 0.1931464174454829, 0.1869158878504673, 0.18380062305295952, 0.17757009345794394, 0.17757009345794394, 0.17133956386292837, 0.1651090342679128, 0.1651090342679128, 0.1651090342679128, 0.1651090342679128, 0.15887850467289721, 0.15887850467289721, 0.15887850467289721, 0.15576323987538943, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164], \"mode\": \"linemarkers\", \"line\": {\"color\": \"Red\", \"width\": 1.5}, \"name\": \"Test Accuracy\"}], {\"width\": 600, \"height\": 400, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"title\": \"Accuracy vs Number of SVD Latent Features\", \"titlefont\": {\"size\": 12}, \"yaxis\": {\"title\": \"% Accuracy\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"tickformat\": \".0%\", \"gridwidth\": null, \"range\": [0, 1]}, \"xaxis\": {\"title\": \"K Latent Features\", \"titlefont\": {\"size\": 10}, \"range\": [0, 750]}, \"legend\": {\"font\": {\"size\": 10}, \"x\": 0.8, \"y\": 0.8, \"xanchor\": \"center\", \"yanchor\": \"middle\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"806ad64f-afc5-4b8e-8fd6-17b722d3717f\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"806ad64f-afc5-4b8e-8fd6-17b722d3717f\", [{\"type\": \"scatter\", \"x\": [5, 15, 25, 35, 45, 55, 65, 75, 85, 95, 105, 115, 125, 135, 145, 155, 165, 175, 185, 195, 205, 215, 225, 235, 245, 255, 265, 275, 285, 295, 305, 315, 325, 335, 345, 355, 365, 375, 385, 395, 405, 415, 425, 435, 445, 455, 465, 475, 485, 495, 505, 515, 525, 535, 545, 555, 565, 575, 585, 595, 605, 615, 625, 635, 645, 655, 665, 675, 685, 695, 705], \"y\": [0.327325, 0.406975, 0.46482500000000004, 0.515425, 0.5514749999999999, 0.5937, 0.631325, 0.6644749999999999, 0.695025, 0.72235, 0.746975, 0.768325, 0.78935, 0.807975, 0.82495, 0.8383, 0.85245, 0.8634999999999999, 0.874825, 0.88565, 0.8958, 0.90445, 0.912675, 0.920425, 0.92815, 0.933975, 0.94065, 0.94545, 0.9499, 0.95475, 0.958575, 0.9615, 0.965025, 0.968, 0.97075, 0.972675, 0.9753000000000001, 0.978625, 0.98135, 0.983225, 0.984475, 0.98585, 0.9874, 0.988675, 0.9899249999999999, 0.991, 0.991925, 0.9929, 0.99385, 0.994625, 0.99505, 0.99585, 0.996725, 0.99725, 0.997825, 0.998325, 0.998675, 0.9989, 0.99915, 0.9994, 0.99945, 0.999475, 0.999575, 0.9998, 0.999875, 0.999975, 1.0, 1.0, 1.0, 1.0, 1.0], \"mode\": \"linemarkers\", \"line\": {\"color\": \"DarkSlateGrey\", \"width\": 1.5}, \"name\": \"Training Accuracy\"}, {\"type\": \"scatter\", \"x\": [5, 15, 25, 35, 45, 55, 65, 75, 85, 95, 105, 115, 125, 135, 145, 155, 165, 175, 185, 195, 205, 215, 225, 235, 245, 255, 265, 275, 285, 295, 305, 315, 325, 335, 345, 355, 365, 375, 385, 395, 405, 415, 425, 435, 445, 455, 465, 475, 485, 495, 505, 515, 525, 535, 545, 555, 565, 575, 585, 595, 605, 615, 625, 635, 645, 655, 665, 675, 685, 695, 705], \"y\": [0.3457943925233645, 0.37071651090342683, 0.36760124610591904, 0.37071651090342683, 0.36448598130841126, 0.36448598130841126, 0.3520249221183801, 0.3302180685358256, 0.33333333333333337, 0.32398753894081, 0.2990654205607477, 0.28660436137071654, 0.2928348909657321, 0.28971962616822433, 0.28037383177570097, 0.2710280373831776, 0.26168224299065423, 0.25545171339563866, 0.23676012461059193, 0.22741433021806856, 0.2180685358255452, 0.20249221183800625, 0.20249221183800625, 0.19937694704049846, 0.1931464174454829, 0.1869158878504673, 0.18380062305295952, 0.17757009345794394, 0.17757009345794394, 0.17133956386292837, 0.1651090342679128, 0.1651090342679128, 0.1651090342679128, 0.1651090342679128, 0.15887850467289721, 0.15887850467289721, 0.15887850467289721, 0.15576323987538943, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164, 0.15264797507788164], \"mode\": \"linemarkers\", \"line\": {\"color\": \"Red\", \"width\": 1.5}, \"name\": \"Test Accuracy\"}], {\"width\": 600, \"height\": 400, \"margin\": {\"l\": 50, \"r\": 30, \"t\": 40, \"b\": 50}, \"title\": \"Accuracy vs Number of SVD Latent Features\", \"titlefont\": {\"size\": 12}, \"yaxis\": {\"title\": \"% Accuracy\", \"titlefont\": {\"size\": 12}, \"tickfont\": {\"size\": 10}, \"tickformat\": \".0%\", \"gridwidth\": null, \"range\": [0, 1]}, \"xaxis\": {\"title\": \"K Latent Features\", \"titlefont\": {\"size\": 10}, \"range\": [0, 750]}, \"legend\": {\"font\": {\"size\": 10}, \"x\": 0.8, \"y\": 0.8, \"xanchor\": \"center\", \"yanchor\": \"middle\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Perform evaluation at different K\n",
    "\n",
    "k_train_error, k_test_error = svd_performance(u_train, s_train, vt_train, u_test, vt_test, user_item_train, \n",
    "    user_item_test_subset, num_latent_feats)\n",
    "#print('No of errors:', len(k_train_error), len(k_test_error))\n",
    "\n",
    "# Calculate the % accuracy of predictions\n",
    "# Note: the denominiator represents total number of interactions \n",
    "\n",
    "acc_train = 1 - (np.array(k_train_error) /df_train.shape[0])\n",
    "acc_test = 1 - (np.array(k_test_error)/ df_test.loc[df_test['user_id'].isin(list(common_users)),:].shape[0])\n",
    "\n",
    "# Plot the Test and Training accuracy for different K\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "        x=num_latent_feats,\n",
    "        y=acc_train,            \n",
    "        mode='linemarkers',\n",
    "        line=dict(color='DarkSlateGrey', width=1.5),\n",
    "        name='Training Accuracy'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "        x=num_latent_feats,\n",
    "        y=acc_test,            \n",
    "        mode='linemarkers',\n",
    "        line=dict(color='Red', width=1.5),\n",
    "        name='Test Accuracy'\n",
    ")\n",
    "layout = go.Layout(\n",
    "        width = 600,\n",
    "        height = 400,\n",
    "        margin = dict(l=50, r=30, t=40, b=50), \n",
    "        title = 'Accuracy vs Number of SVD Latent Features',    \n",
    "        titlefont = dict(size=12),    \n",
    "        yaxis = {\n",
    "                'title': '% Accuracy',\n",
    "                'titlefont': dict(size=12),\n",
    "                'tickfont' : dict(size=10),\n",
    "                'tickformat': '.0%',\n",
    "                'gridwidth': None,\n",
    "                'range': [0,1]\n",
    "        },\n",
    "        xaxis = {\n",
    "                'title': 'K Latent Features', \n",
    "                'titlefont': dict(size=10),\n",
    "                'range': [0,750]\n",
    "        },        \n",
    "        legend = {\n",
    "                'font': dict(size=10),\n",
    "                'x': 0.8,  # Horizontally center the legend\n",
    "                'y': 0.8,  # Adjust vertical position as needed\n",
    "                'xanchor': 'center',  # Ensure that x=0.5 is the center of the legend\n",
    "                'yanchor': 'middle'   # Ensure that y=0.5 is the middle of the legend\n",
    "        }\n",
    "    )   \n",
    "\n",
    "fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "\n",
    "iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`6.` Use the cell below to comment on the results you found in the previous question. Given the circumstances of your results, discuss what you might do to determine if the recommendations you make with any of the above recommendation systems are an improvement to how users currently find articles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here.**\n",
    "\n",
    "Singular Value Decomposition (SVD) predictions were made using the training dataset, focusing on common users shared between the training and test datasets. These predictions were then evaluated on the test dataset, targeting common users and items present in both datasets.  \n",
    "\n",
    "Increasing the number of latent features (k) in the training dataset improved prediction accuracy by capturing intricate patterns and closely matching training data interactions up to a certain point. However, when evaluating SVD predictions on the test dataset, accuracy decreased even with larger k values. This decline was attributed to overfitting in the training dataset, where the model became too tailored to training data interactions, limiting its ability to generalize effectively.\n",
    "\n",
    "To address these challenges, consider:\n",
    "\n",
    "- Regularization: Use ridge or Lasso regression to prevent overfitting by penalizing noisy patterns in training data.\n",
    "- Feature Engineering: Create meaningful features or latent factors to enhance model generalization.\n",
    "- Data Splitting: Reevaluate training-test data splitting to ensure real-world representation.\n",
    "\n",
    "In general cases, also consider:\n",
    "\n",
    "- Cross-Validation: Implement techniques like k-fold cross-validation for better generalization and performance estimation.\n",
    "- Metric Choice: Explore alternative metrics, like standardized view counts or weighted repeated counts, for interaction strength.\n",
    "- Dimensionality Reduction: Assess how reducing the number of latent features (k) impacts generalization, finding the right balance between underfitting and overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='conclusions'></a>\n",
    "### Extras\n",
    "Using your workbook, you could now save your recommendations for each user, develop a class to make new predictions and update your results, and make a flask app to deploy your results.  These tasks are beyond what is required for this project.  However, from what you learned in the lessons, you certainly capable of taking these tasks on to improve upon your work here!\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "> Congratulations!  You have reached the end of the Recommendations with IBM project! \n",
    "\n",
    "\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Recommendations_with_IBM.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
